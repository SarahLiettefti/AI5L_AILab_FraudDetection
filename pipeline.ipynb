{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_feature = pd.read_csv(\"input/Xente_Variable_Definitions.csv\")\n",
    "df = pd.read_csv(\"input/training.csv\")\n",
    "data = df.copy()\n",
    "X_test = pd.read_csv(\"input/test.csv\")\n",
    "sample_submission = pd.read_csv(\"input/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateExpenseFeature(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X[\"Expense\"] = X[\"Amount\"] < 0\n",
    "        return X.drop(\"Amount\", axis=1)\n",
    "\n",
    "\n",
    "class OneHotEncoderWrapper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return pd.get_dummies(X, columns=self.columns)\n",
    "\n",
    "\n",
    "class DropUniqueColumns(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        unique_counts = X.nunique()\n",
    "        self.drop_cols = unique_counts[unique_counts == 1].index.tolist()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        print(\"Dropping columns with one unique value:\", self.drop_cols)\n",
    "        return X.drop(columns=self.drop_cols)\n",
    "\n",
    "\n",
    "class ConvertIdColumns(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        id_cols = X.filter(like=\"Id\").columns.tolist()\n",
    "        X[id_cols] = (\n",
    "            X[id_cols]\n",
    "            .astype(str)\n",
    "            .apply(lambda x: x.str.replace(x.name + \"_\", \"\"))\n",
    "            .astype(int)\n",
    "        )\n",
    "        return X\n",
    "\n",
    "\n",
    "class ExtractDateTimeFeatures(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X[\"TransactionStartTime\"] = pd.to_datetime(\n",
    "            X[\"TransactionStartTime\"], format=\"%Y-%m-%dT%H:%M:%SZ\"\n",
    "        )\n",
    "        X[\"TransactionDayOfWeek\"] = X[\"TransactionStartTime\"].dt.dayofweek\n",
    "        X[\"TransactionDayOfMonth\"] = X[\"TransactionStartTime\"].dt.day\n",
    "        X[\"TransactionHour\"] = X[\"TransactionStartTime\"].dt.hour\n",
    "        X[\"TransactionMinute\"] = X[\"TransactionStartTime\"].dt.minute\n",
    "        return X.drop(\"TransactionStartTime\", axis=1)\n",
    "\n",
    "\n",
    "class ComputeMeanStdAmount(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, mean_amount_features, std_amount_features):\n",
    "        self.mean_amount_features = mean_amount_features\n",
    "        self.std_amount_features = std_amount_features\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        for feature in self.mean_amount_features:\n",
    "            X[f\"{feature}_mean_amount\"] = X.groupby(feature)[\"Value\"].transform(\"mean\")\n",
    "        for feature in self.std_amount_features:\n",
    "            X[f\"{feature}_std_amount\"] = X.groupby(feature)[\"Value\"].transform(\"std\")\n",
    "        return X\n",
    "\n",
    "\n",
    "class ColumnNormalizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.scaler.fit(X[[self.column]])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        X[self.column] = self.scaler.transform(X[[self.column]])\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing steps\n",
    "preprocessing_steps = [\n",
    "    (\"create_expense_feature\", CreateExpenseFeature()),\n",
    "    (\"drop_unique_columns\", DropUniqueColumns()),\n",
    "    (\"convert_id_columns\", ConvertIdColumns()),\n",
    "    (\"extract_datetime_features\", ExtractDateTimeFeatures()),\n",
    "]\n",
    "\n",
    "# Column transformations\n",
    "normalize_columns = ColumnNormalizer(\"Value\")\n",
    "\n",
    "categorical_columns = [\"ProductCategory\", \"ChannelId\", \"ProviderId\", \"PricingStrategy\"]\n",
    "one_hot_encoder = ColumnTransformer(\n",
    "    [\n",
    "        (\n",
    "            \"one_hot_encoder\",\n",
    "            OneHotEncoderWrapper(categorical_columns),\n",
    "            categorical_columns,\n",
    "        )\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    ")\n",
    "\n",
    "mean_amount_features = [\n",
    "    \"AccountId\",\n",
    "    \"SubscriptionId\",\n",
    "]\n",
    "std_amount_features = [\n",
    "    # The list of std_amount_features\n",
    "]\n",
    "\n",
    "# Compute mean and standard deviation of transactions for each feature\n",
    "compute_mean_std_amount = ComputeMeanStdAmount(\n",
    "    mean_amount_features=mean_amount_features,\n",
    "    std_amount_features=std_amount_features,\n",
    ")\n",
    "\n",
    "# Combine preprocessing steps, column transformations, and feature computations\n",
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessing\", Pipeline(preprocessing_steps)),\n",
    "        (\"normalize_columns\", normalize_columns),\n",
    "        (\"one_hot_encoder\", OneHotEncoderWrapper(categorical_columns)),\n",
    "        (\"compute_mean_std_amount\", compute_mean_std_amount),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping columns with one unique value: ['CurrencyCode', 'CountryCode']\n"
     ]
    }
   ],
   "source": [
    "processed_data = pipeline.fit_transform(data)\n",
    "\n",
    "# Get the transformed column names\n",
    "transformed_columns = (\n",
    "    data.columns.tolist()\n",
    "    + pipeline.named_steps[\"one_hot_encoder\"]\n",
    "    .transform(pd.DataFrame(columns=categorical_columns))\n",
    "    .columns.tolist()\n",
    "    + pipeline.named_steps[\"compute_mean_std_amount\"].mean_amount_features\n",
    "    + pipeline.named_steps[\"compute_mean_std_amount\"].std_amount_features\n",
    ")\n",
    "\n",
    "# Convert the result back to a DataFrame with updated column names\n",
    "processed_data = pd.DataFrame(processed_data, columns=transformed_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TransactionId', 'BatchId', 'AccountId', 'SubscriptionId', 'CustomerId',\n",
       "       'CurrencyCode', 'CountryCode', 'ProviderId', 'ProductId',\n",
       "       'ProductCategory', 'ChannelId', 'Amount', 'Value',\n",
       "       'TransactionStartTime', 'PricingStrategy', 'FraudResult', 'Expense',\n",
       "       'AccountId', 'SubscriptionId'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI5L",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
