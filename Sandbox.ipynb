{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X\u001b[39m.\u001b[39mgroupby(\u001b[39m'\u001b[39m\u001b[39mBatchId\u001b[39m\u001b[39m'\u001b[39m)[[\u001b[39m\"\u001b[39m\u001b[39mAmount\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mValue\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDay\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mHour\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mweek_day\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mweeks\u001b[39m\u001b[39m\"\u001b[39m]]\u001b[39m.\u001b[39magg([\u001b[39m'\u001b[39m\u001b[39mcount\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmin\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m df\u001b[39m.\u001b[39mgroupby(\u001b[39m'\u001b[39m\u001b[39mA\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39magg({\u001b[39m'\u001b[39m\u001b[39mB\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m'\u001b[39m\u001b[39mmin\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mC\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39msum\u001b[39m\u001b[39m'\u001b[39m})\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X.groupby(\"BatchId\")[[\"Amount\", \"Value\", \"Day\", \"Hour\", \"week_day\", \"weeks\"]].agg(\n",
    "    [\"count\", \"min\", \"max\", \"mean\"]\n",
    ")\n",
    "\n",
    "df.groupby(\"A\").agg({\"B\": [\"min\", \"max\"], \"C\": \"sum\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf6450c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y1 = train_y.copy()\n",
    "train_X1 = train_X.copy()\n",
    "val_y1 = val_y.copy()\n",
    "val_X1 = val_X.copy()\n",
    "train_X1.drop(cols_cat, axis=1, inplace=True)  # Delete categorical data\n",
    "val_X1.drop(cols_cat, axis=1, inplace=True)  # Delete categorical data\n",
    "# train_X1 = train_X.select_dtypes(exclude=['object'])\n",
    "# val_X1 = val_X.select_dtypes(exclude=['object'])\n",
    "train_X1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaaefb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n",
    "    model = DecisionTreeClassifier(max_leaf_nodes=max_leaf_nodes, random_state=1)\n",
    "    model.fit(train_X, train_y)\n",
    "    preds_val = model.predict(val_X)\n",
    "    mae = mean_absolute_error(val_y, preds_val)\n",
    "    return mae\n",
    "\n",
    "\n",
    "for max_leaf_nodes in [5, 50, 500, 5000]:\n",
    "    my_mae = get_mae(max_leaf_nodes, train_X1, val_X1, train_y1, val_y1)\n",
    "    print(\n",
    "        \"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %d\" % (max_leaf_nodes, my_mae)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e0613e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706bc5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = RandomForestClassifier(n_estimators=50, random_state=0)\n",
    "model_2 = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "model_3 = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "model_4 = RandomForestClassifier(n_estimators=200, min_samples_split=20, random_state=0)\n",
    "model_5 = RandomForestClassifier(n_estimators=100, max_depth=7, random_state=0)\n",
    "\n",
    "models = [model_1, model_2, model_3, model_4, model_5]\n",
    "\n",
    "\n",
    "# Function for comparing different models\n",
    "def score_model(model, X_t=train_X1, X_v=val_X1, y_t=train_y1, y_v=val_y1):\n",
    "    model.fit(X_t, y_t)\n",
    "    preds = model.predict(X_v)\n",
    "    return mean_absolute_error(y_v, preds)\n",
    "\n",
    "\n",
    "for i in range(0, len(models)):\n",
    "    mae = score_model(models[i])\n",
    "    print(\"Model %d MAE: %d\" % (i + 1, mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a22af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_model_decision_tree = DecisionTreeClassifier(random_state=1)\n",
    "first_model_decision_tree.fit(train_X, train_y)\n",
    "first_model_decision_tree_predicted = first_model_decision_tree.predict(val_X)\n",
    "\n",
    "df_with_res = val_X.copy()\n",
    "df_with_res = df_with_res.join(val_y.copy())\n",
    "df_with_res[\"Predictions\"] = list(first_model_decision_tree_predicted)\n",
    "print(\n",
    "    f'Nombre de prédictions correcte : {df_with_res.Predictions[(df_with_res[\"Predictions\"] == df_with_res[\"FraudResult\"] )].count()}'\n",
    ")\n",
    "print(\n",
    "    f'Nombre de prédictions incorrecte : {df_with_res.Predictions[(df_with_res[\"Predictions\"] != df_with_res[\"FraudResult\"] )].count()}'\n",
    ")\n",
    "print(\n",
    "    f'Nombre de fraude non prédites : {df_with_res.Predictions[(df_with_res[\"Predictions\"] != df_with_res[\"FraudResult\"] )&(df_with_res[\"FraudResult\"]==1)].count()}'\n",
    ")\n",
    "print(\n",
    "    f'Nombre de pas fraude prédite en fraude : {df_with_res.Predictions[(df_with_res[\"Predictions\"] != df_with_res[\"FraudResult\"] )&(df_with_res[\"FraudResult\"]==0)].count()}'\n",
    ")\n",
    "print(\n",
    "    f'Nombre de fraude bien prédite : {df_with_res.Predictions[(df_with_res[\"Predictions\"] == df_with_res[\"FraudResult\"] )&(df_with_res[\"FraudResult\"]==1)].count()}'\n",
    ")\n",
    "print(\n",
    "    f'Nombre de pas fraude bien prédite : {df_with_res.Predictions[(df_with_res[\"Predictions\"] == df_with_res[\"FraudResult\"] )&(df_with_res[\"FraudResult\"]==0)].count()}'\n",
    ")\n",
    "print(f\"Nombre de Fraude dans le dataset : {val_y.value_counts()[1]}\")\n",
    "print(f\"Nombre total : {df_with_res.Predictions.count()}\")\n",
    "print(\n",
    "    df_with_res[[\"FraudResult\", \"Predictions\"]][\n",
    "        (df_with_res[\"Predictions\"] != df_with_res[\"FraudResult\"])\n",
    "    ]\n",
    ")\n",
    "df_with_res.head(10)\n",
    "report(\n",
    "    val_y,\n",
    "    first_model_decision_tree_predicted,\n",
    "    \"Decision Tree Classifier\",\n",
    "    \"first simple model\",\n",
    "    csvw=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AILab-ECAM3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
