{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efcbf836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import resample\n",
    "import datetime as dt\n",
    "from math import ceil, sqrt\n",
    "from Utils import *\n",
    "pd.set_option('max_colwidth', None)\n",
    "from EvaluationMetric import *\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bae6abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparemodels(train_X, train_y, val_X, test_X, generaldescription, unbalanced = True):\n",
    "    res = []\n",
    "\n",
    "    model1 = DecisionTreeClassifier(max_leaf_nodes= 6, random_state=1)\n",
    "    model1.fit(train_X, train_y)\n",
    "    preds_val1 = model1.predict(val_X)\n",
    "    model_test1 = model1.predict(test_X)\n",
    "    description = generaldescription+\"max_leaf_nodes : 6 + with date columns\"\n",
    "    metrics1 = listmetrics(val_y, preds_val1, \"DecisionTreeClassifier\", description)\n",
    "    m1Public = [0.666666666, 0.666666666]\n",
    "    m1Private = [0.661016949, 0.661016949]\n",
    "    res.append(metrics1)\n",
    "    df1 = getscoreforcsv(index_val, model_test1, name_file = \"TreeClass5leaf.csv\")\n",
    "\n",
    "\n",
    "    model2 = RandomForestClassifier(n_estimators=36, criterion = 'entropy', random_state=1)\n",
    "    model2.fit(train_X, train_y)\n",
    "    preds_val2 = model2.predict(val_X)\n",
    "    model_test2 = model2.predict(test_X)\n",
    "    description = generaldescription+\"n_estimators : 36 + Entropy\"\n",
    "    metrics2 = listmetrics(val_y, preds_val2, \"Random Forest Classifier\", description)\n",
    "    m2Public = [0.690909090, 0.666666666]\n",
    "    m2Private = [0.649122807, 0.649122807]\n",
    "    res.append(metrics2)\n",
    "    df2 = getscoreforcsv(index_val, model_test2, name_file = \"RandomForestN36Entropy.csv\")\n",
    "\n",
    "\n",
    "    ##################ICi donne un 0.71 de scrore !!! mtn comprendre pq en diminuant les feature si bon score mais que pour lui !############\n",
    "    #Ne fonctionne pas bien quadn le training set est entier. \n",
    "    model2 = XGBClassifier(scale_pos_weight=22, random_state=1)\n",
    "    model2.fit(train_X, train_y)\n",
    "    preds_val2 = model2.predict(val_X)\n",
    "    model_test2 = model2.predict(test_X)\n",
    "    description = generaldescription+\"scale_pos_weight = 22\"\n",
    "    metrics2 = listmetrics(val_y, preds_val2, \"XGBClassifier\", description)\n",
    "    m3Public = [0.677419354, 0.711864406]\n",
    "    m3Private = [0.676923076,  0.715447154]\n",
    "    res.append(metrics2)\n",
    "    df2 = getscoreforcsv(index_val, model_test2, name_file = \"XGBClassifierW22.csv\")\n",
    "\n",
    "    #oversamplesimple\n",
    "    X_con = pd.concat([train_X, train_y], axis=1) \n",
    "    not_fraud = X_con[X_con.FraudResult==0]\n",
    "    fraud = X_con[X_con.FraudResult==1]\n",
    "    fraud_upsampled = resample(fraud, replace=True, n_samples=len(not_fraud), # match number in majority class\n",
    "                            random_state=1) # reproducible results\n",
    "    upsampled = pd.concat([not_fraud, fraud_upsampled])\n",
    "    train_y_over_sampled = upsampled.FraudResult\n",
    "    train_X_over_sampled = upsampled.drop('FraudResult', axis=1)\n",
    "    upsampledmodel = RandomForestClassifier(n_estimators=36, criterion = 'entropy', random_state=1)\n",
    "    upsampledmodel.fit(train_X_over_sampled, train_y_over_sampled)\n",
    "    upsampled_pred = upsampledmodel.predict(val_X)\n",
    "    model_test = upsampledmodel.predict(OH_X_test)\n",
    "    description = generaldescription+\"upsampled, n_estimators=36, criterion = entropy\"\n",
    "    metrics = listmetrics(val_y, upsampled_pred, \"RandomForestClassifierUpperSampling\", description)\n",
    "    m4Public = [0.678571428, 0.642857142]\n",
    "    m4Private = [0.637168141, 0.620689655]\n",
    "    res.append(metrics)\n",
    "    df = getscoreforcsv(index_val, model_test, name_file = \"RandomForestClassifierUpSample.csv\")\n",
    "\n",
    "    #Undersampling\n",
    "    not_fraud_downsampled  = resample(not_fraud, replace=False, n_samples=len(fraud), # match number in minority  class\n",
    "                            random_state=1) # reproducible results\n",
    "    downsampled  = pd.concat([not_fraud_downsampled , fraud])\n",
    "    train_y_undersampled = downsampled.FraudResult\n",
    "    train_X_undersampled = downsampled.drop('FraudResult', axis=1)\n",
    "    undersampled = RandomForestClassifier(n_estimators=36, criterion = 'entropy', random_state=1)\n",
    "    undersampled.fit(train_X_over_sampled, train_y_over_sampled)\n",
    "    undersampled_pred = undersampled.predict(val_X)\n",
    "    model_test = undersampled.predict(OH_X_test)\n",
    "    description = generaldescription+\"undersampled, n_estimators=36, criterion = entropy\"\n",
    "    metrics = listmetrics(val_y, undersampled_pred, \"RandomForestClassifierUnderSampling\", description)\n",
    "    m5Public = [0.549019607, 0.642857142]\n",
    "    m5Private = [0.480769230, 0.620689655]\n",
    "    res.append(metrics)\n",
    "    df = getscoreforcsv(index_val, model_test, name_file = \"RandomForestClassifierUndersampled.csv\")\n",
    "\n",
    "\n",
    "    dfres = listmetricsintodf(res)\n",
    "    dfres[\"OldPublicScore\"] = [m1Public, m2Public, m3Public, m4Public, m5Public]\n",
    "    dfres[\"OldPrivateScore\"] = [m1Private, m2Private, m3Private, m4Private, m5Private]\n",
    "    dfres[\"MeanOurMetrics\"] = dfres[['Precision', 'Recall','F1-score','Mcc']].mean(axis=1)\n",
    "    dfres.to_csv('output/resultatsTestEverything.csv', mode='a',index=False,header = False) \n",
    "    return dfres"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5eab429b",
   "metadata": {},
   "source": [
    "# Test de different model with different Data Here\n",
    "## 1. The reference model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73a9d70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>The referencemax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 12:06:12.077756</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>0.857566</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.661017</td>\n",
       "      <td>[0.666666666, 0.666666666]</td>\n",
       "      <td>[0.661016949, 0.661016949]</td>\n",
       "      <td>0.857900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>The referencen_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 12:06:13.810833</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.843373</td>\n",
       "      <td>0.019592</td>\n",
       "      <td>0.843655</td>\n",
       "      <td>0.690909</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>[0.69090909, 0.666666666]</td>\n",
       "      <td>[0.649122807, 0.649122807]</td>\n",
       "      <td>0.843995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>The referencescale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 12:06:16.406438</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>0.871874</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.676923</td>\n",
       "      <td>[0.677419354, 0.711864406]</td>\n",
       "      <td>[0.676923076, 0.715447154]</td>\n",
       "      <td>0.872421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>The referenceupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 12:06:20.249096</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.022606</td>\n",
       "      <td>0.824649</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.637168</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.825239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>The referenceundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 12:06:23.944705</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.022606</td>\n",
       "      <td>0.824649</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.825239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Model  \\\n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  RandomForestClassifierUpperSampling   \n",
       "4  RandomForestClassifierUnderSampling   \n",
       "\n",
       "                                                       Description  \\\n",
       "0              The referencemax_leaf_nodes : 6 + with date columns   \n",
       "1                         The referencen_estimators : 36 + Entropy   \n",
       "2                               The referencescale_pos_weight = 22   \n",
       "3     The referenceupsampled, n_estimators=36, criterion = entropy   \n",
       "4  The referenceundersampled, n_estimators=36, criterion = entropy   \n",
       "\n",
       "                        Date  Precision  Recall  F1-score   LogLoss       Mcc  \\\n",
       "0 2023-05-07 12:06:12.077756   0.891892   0.825  0.857143  0.016578  0.857566   \n",
       "1 2023-05-07 12:06:13.810833   0.813953   0.875  0.843373  0.019592  0.843655   \n",
       "2 2023-05-07 12:06:16.406438   0.822222   0.925  0.870588  0.016578  0.871874   \n",
       "3 2023-05-07 12:06:20.249096   0.777778   0.875  0.823529  0.022606  0.824649   \n",
       "4 2023-05-07 12:06:23.944705   0.777778   0.875  0.823529  0.022606  0.824649   \n",
       "\n",
       "   PublicScore  PrivateScore              OldPublicScore  \\\n",
       "0     0.666667      0.661017  [0.666666666, 0.666666666]   \n",
       "1     0.690909      0.649123   [0.69090909, 0.666666666]   \n",
       "2     0.677419      0.676923  [0.677419354, 0.711864406]   \n",
       "3     0.678571      0.637168  [0.678571428, 0.642857142]   \n",
       "4     0.549020      0.480769  [0.549019607, 0.642857142]   \n",
       "\n",
       "              OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949]        0.857900  \n",
       "1  [0.649122807, 0.649122807]        0.843995  \n",
       "2  [0.676923076, 0.715447154]        0.872421  \n",
       "3  [0.637168141, 0.620689655]        0.825239  \n",
       "4   [0.48076923, 0.620689655]        0.825239  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def_feature = pd.read_csv(\"input/Xente_Variable_Definitions.csv\")\n",
    "raw_data = pd.read_csv(\"input/training.csv\")\n",
    "X_test = pd.read_csv(\"input/test.csv\")\n",
    "sample_submission = pd.read_csv(\"input/sample_submission.csv\")\n",
    "\n",
    "#attribut initialization\n",
    "cols_unique_value = [] #Will be droped\n",
    "for col in raw_data.columns : \n",
    "    if len(raw_data[col].unique()) == 1 :\n",
    "        cols_unique_value.append(col)\n",
    "\n",
    "medium_cardianlity_cols = [\"ProductId\"]\n",
    "\n",
    "#Data transformation\n",
    "raw_data['TransactionStartTime'] = pd.to_datetime(raw_data['TransactionStartTime'])\n",
    "X_test['TransactionStartTime'] = pd.to_datetime(X_test['TransactionStartTime'])\n",
    "\n",
    "#Data cleaning\n",
    "data = raw_data.copy()\n",
    "data = data.dropna(axis=0) #Drop observations/rows with missing values\n",
    "X_test=X_test.dropna(axis=0)\n",
    "data.drop(cols_unique_value, axis=1, inplace=True)\n",
    "X_test.drop(cols_unique_value, axis=1, inplace=True)\n",
    "\n",
    "#Prepare index for the submission\n",
    "index_val = list(X_test.TransactionId.values.tolist())\n",
    "\n",
    "#Set the df index to the Transction Id\n",
    "data = transactioId_to_index(data)\n",
    "X_test = transactioId_to_index(X_test)\n",
    "\n",
    "#Adding data\n",
    "data = adding_date_col(data, 'TransactionStartTime')\n",
    "X_test = adding_date_col(X_test, 'TransactionStartTime')\n",
    "\n",
    "\n",
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "low_cardinality_cols = [cname for cname in data.columns if data[cname].nunique() < 15 and \n",
    "                        data[cname].dtype == \"object\"]\n",
    "low_cardinality_cols.append('PricingStrategy')\n",
    "\n",
    "#transform columns BatchId_54 to number\n",
    "    #transform columns BatchId_54 to number\n",
    "id_cols = data.filter(like=\"Id\").columns.tolist()\n",
    "data[id_cols] = data[id_cols].astype(str).apply(lambda x: x.str.replace(x.name + \"_\", \"\")).astype(int)\n",
    "X_test[id_cols] = X_test[id_cols].astype(str).apply(lambda x: x.str.replace(x.name + \"_\", \"\")).astype(int)\n",
    "\n",
    "data['PricingStrategy'] = data['PricingStrategy'].astype('int')\n",
    "X_test['PricingStrategy'] = X_test['PricingStrategy'].astype('int')\n",
    "data['Value'] = data['Value'].astype('float')\n",
    "X_test['Value'] = X_test['Value'].astype('float')\n",
    "\n",
    "X_test['PricingStrategy'] = X_test['PricingStrategy'].astype('str')\n",
    "data['PricingStrategy'] = data['PricingStrategy'].astype('str')\n",
    "\n",
    "#Data splitting\n",
    "y = data.FraudResult #The target label\n",
    "X = data.copy()\n",
    "X.drop(['FraudResult'], axis=1, inplace=True) #Only the features data\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "cat_cols = [col for col in X.columns if X[col].dtype == \"object\"]#liste of obejct columns\n",
    "cat_cols.append(\"PricingStrategy\")#pcq mm si c'est un chiffre il faut le considérer comme une catégorie\n",
    "\n",
    "\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(train_X[low_cardinality_cols]))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(val_X[low_cardinality_cols]))\n",
    "OH_cols_test = pd.DataFrame(OH_encoder.transform(X_test[low_cardinality_cols]))\n",
    "OH_cols_train.columns = OH_encoder.get_feature_names_out()\n",
    "OH_cols_valid.columns = OH_encoder.get_feature_names_out()\n",
    "OH_cols_test.columns = OH_encoder.get_feature_names_out()\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_train.index = train_X.index\n",
    "OH_cols_valid.index = val_X.index\n",
    "OH_cols_test.index = X_test.index\n",
    "\n",
    "OH_cols_train[list(OH_cols_train.columns)] = OH_cols_train[list(OH_cols_train.columns)].astype(int)\n",
    "OH_cols_valid[list(OH_cols_valid.columns)] = OH_cols_valid[list(OH_cols_valid.columns)].astype(int)\n",
    "OH_cols_test[list(OH_cols_test.columns)] = OH_cols_test[list(OH_cols_test.columns)].astype(int)\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train = train_X.drop(low_cardinality_cols, axis=1)\n",
    "num_X_valid = val_X.drop(low_cardinality_cols, axis=1)\n",
    "num_X_test = X_test.drop(low_cardinality_cols, axis=1)\n",
    "\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
    "OH_X_test = pd.concat([num_X_test, OH_cols_test], axis=1)\n",
    "\n",
    "# Problème de string\n",
    "OH_X_train.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_valid.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_test.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_train.columns = OH_X_train.columns.astype(str)\n",
    "OH_X_valid.columns = OH_X_valid.columns.astype(str)\n",
    "OH_X_test.columns = OH_X_test.columns.astype(str)\n",
    "\n",
    "train_X = OH_X_train\n",
    "val_X = OH_X_valid\n",
    "test_X = OH_X_test\n",
    "X_entier = pd.concat([train_X, val_X])\n",
    "\n",
    "referenceresult = comparemodels(train_X, train_y, val_X, test_X, \"The reference\")\n",
    "referenceresult[\"PublicScore\"] = [0.666666666, 0.690909090, 0.677419354, 0.678571428, 0.549019607]\n",
    "referenceresult[\"PrivateScore\"] = [0.661016949, 0.649122807, 0.676923076, 0.637168141, 0.480769230]\n",
    "referenceresult"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "418bccbc",
   "metadata": {},
   "source": [
    "## 2. Play with deleting the low MI columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46c1db32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supprimer les MI trop faible\n",
    "def_feature = pd.read_csv(\"input/Xente_Variable_Definitions.csv\")\n",
    "raw_data = pd.read_csv(\"input/training.csv\")\n",
    "X_test = pd.read_csv(\"input/test.csv\")\n",
    "sample_submission = pd.read_csv(\"input/sample_submission.csv\")\n",
    "\n",
    "#attribut initialization\n",
    "cols_unique_value = [] #Will be droped\n",
    "for col in raw_data.columns : \n",
    "    if len(raw_data[col].unique()) == 1 :\n",
    "        cols_unique_value.append(col)\n",
    "\n",
    "medium_cardianlity_cols = [\"ProductId\"]\n",
    "\n",
    "#Data transformation\n",
    "raw_data['TransactionStartTime'] = pd.to_datetime(raw_data['TransactionStartTime'])\n",
    "X_test['TransactionStartTime'] = pd.to_datetime(X_test['TransactionStartTime'])\n",
    "\n",
    "#Data cleaning\n",
    "data = raw_data.copy()\n",
    "data = data.dropna(axis=0) #Drop observations/rows with missing values\n",
    "X_test=X_test.dropna(axis=0)\n",
    "data.drop(cols_unique_value, axis=1, inplace=True)\n",
    "X_test.drop(cols_unique_value, axis=1, inplace=True)\n",
    "\n",
    "#Prepare index for the submission\n",
    "index_val = list(X_test.TransactionId.values.tolist())\n",
    "\n",
    "#Set the df index to the Transction Id\n",
    "data = transactioId_to_index(data)\n",
    "X_test = transactioId_to_index(X_test)\n",
    "\n",
    "#Adding data\n",
    "data = adding_date_col(data, 'TransactionStartTime')\n",
    "X_test = adding_date_col(X_test, 'TransactionStartTime')\n",
    "\n",
    "\n",
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "low_cardinality_cols = [cname for cname in data.columns if data[cname].nunique() < 15 and \n",
    "                        data[cname].dtype == \"object\"]\n",
    "low_cardinality_cols.append('PricingStrategy')\n",
    "\n",
    "#transform columns BatchId_54 to number\n",
    "    #transform columns BatchId_54 to number\n",
    "id_cols = data.filter(like=\"Id\").columns.tolist()\n",
    "data[id_cols] = data[id_cols].astype(str).apply(lambda x: x.str.replace(x.name + \"_\", \"\")).astype(int)\n",
    "X_test[id_cols] = X_test[id_cols].astype(str).apply(lambda x: x.str.replace(x.name + \"_\", \"\")).astype(int)\n",
    "\n",
    "data['PricingStrategy'] = data['PricingStrategy'].astype('int')\n",
    "X_test['PricingStrategy'] = X_test['PricingStrategy'].astype('int')\n",
    "data['Value'] = data['Value'].astype('float')\n",
    "X_test['Value'] = X_test['Value'].astype('float')\n",
    "\n",
    "X_test['PricingStrategy'] = X_test['PricingStrategy'].astype('str')\n",
    "data['PricingStrategy'] = data['PricingStrategy'].astype('str')\n",
    "\n",
    "#Data splitting\n",
    "y = data.FraudResult #The target label\n",
    "X = data.copy()\n",
    "X.drop(['FraudResult'], axis=1, inplace=True) #Only the features data\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "cat_cols = [col for col in X.columns if X[col].dtype == \"object\"]#liste of obejct columns\n",
    "cat_cols.append(\"PricingStrategy\")#pcq mm si c'est un chiffre il faut le considérer comme une catégorie\n",
    "\n",
    "\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(train_X[low_cardinality_cols]))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(val_X[low_cardinality_cols]))\n",
    "OH_cols_test = pd.DataFrame(OH_encoder.transform(X_test[low_cardinality_cols]))\n",
    "OH_cols_train.columns = OH_encoder.get_feature_names_out()\n",
    "OH_cols_valid.columns = OH_encoder.get_feature_names_out()\n",
    "OH_cols_test.columns = OH_encoder.get_feature_names_out()\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_train.index = train_X.index\n",
    "OH_cols_valid.index = val_X.index\n",
    "OH_cols_test.index = X_test.index\n",
    "\n",
    "OH_cols_train[list(OH_cols_train.columns)] = OH_cols_train[list(OH_cols_train.columns)].astype(int)\n",
    "OH_cols_valid[list(OH_cols_valid.columns)] = OH_cols_valid[list(OH_cols_valid.columns)].astype(int)\n",
    "OH_cols_test[list(OH_cols_test.columns)] = OH_cols_test[list(OH_cols_test.columns)].astype(int)\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train = train_X.drop(low_cardinality_cols, axis=1)\n",
    "num_X_valid = val_X.drop(low_cardinality_cols, axis=1)\n",
    "num_X_test = X_test.drop(low_cardinality_cols, axis=1)\n",
    "\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
    "OH_X_test = pd.concat([num_X_test, OH_cols_test], axis=1)\n",
    "\n",
    "# Problème de string\n",
    "OH_X_train.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_valid.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_test.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_train.columns = OH_X_train.columns.astype(str)\n",
    "OH_X_valid.columns = OH_X_valid.columns.astype(str)\n",
    "OH_X_test.columns = OH_X_test.columns.astype(str)\n",
    "\n",
    "train_X = OH_X_train\n",
    "val_X = OH_X_valid\n",
    "test_X = OH_X_test\n",
    "X_entier = pd.concat([train_X, val_X])\n",
    "\n",
    "mi_scores = make_mi_scores(X_entier , y)\n",
    "\n",
    "verylowMI = list(mi_scores[mi_scores<0.0001].index)\n",
    "lowMI = list(mi_scores[(mi_scores>=0.0001)&(mi_scores<0.001)].index)\n",
    "mediumMI = list(mi_scores[(mi_scores>=0.001)&(mi_scores<0.01)].index)\n",
    "highMI = list(mi_scores[mi_scores>=0.01].index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6da4602e",
   "metadata": {},
   "source": [
    "### 2.1 Delecte the very low MI columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df174abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Delete very low MImax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 12:15:59.362979</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.057270</td>\n",
       "      <td>0.257799</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.661017</td>\n",
       "      <td>[0.666666666, 0.666666666]</td>\n",
       "      <td>[0.661016949, 0.661016949]</td>\n",
       "      <td>0.299595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Delete very low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 12:16:01.466270</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.507937</td>\n",
       "      <td>0.046720</td>\n",
       "      <td>0.526930</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>[0.69090909, 0.666666666]</td>\n",
       "      <td>[0.649122807, 0.649122807]</td>\n",
       "      <td>0.532630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Delete very low MIscale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 12:16:05.133214</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.494118</td>\n",
       "      <td>0.064805</td>\n",
       "      <td>0.494079</td>\n",
       "      <td>0.711864</td>\n",
       "      <td>0.715447</td>\n",
       "      <td>[0.677419354, 0.711864406]</td>\n",
       "      <td>[0.676923076, 0.715447154]</td>\n",
       "      <td>0.494966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>Delete very low MIupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 12:16:10.263521</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.438356</td>\n",
       "      <td>0.061791</td>\n",
       "      <td>0.439537</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.440685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>Delete very low MIundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 12:16:16.094689</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.438356</td>\n",
       "      <td>0.061791</td>\n",
       "      <td>0.439537</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.440685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Model  \\\n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  RandomForestClassifierUpperSampling   \n",
       "4  RandomForestClassifierUnderSampling   \n",
       "\n",
       "                                                            Description  \\\n",
       "0              Delete very low MImax_leaf_nodes : 6 + with date columns   \n",
       "1                         Delete very low MIn_estimators : 36 + Entropy   \n",
       "2                               Delete very low MIscale_pos_weight = 22   \n",
       "3     Delete very low MIupsampled, n_estimators=36, criterion = entropy   \n",
       "4  Delete very low MIundersampled, n_estimators=36, criterion = entropy   \n",
       "\n",
       "                        Date  Precision  Recall  F1-score   LogLoss       Mcc  \\\n",
       "0 2023-05-07 12:15:59.362979   0.666667   0.100  0.173913  0.057270  0.257799   \n",
       "1 2023-05-07 12:16:01.466270   0.695652   0.400  0.507937  0.046720  0.526930   \n",
       "2 2023-05-07 12:16:05.133214   0.466667   0.525  0.494118  0.064805  0.494079   \n",
       "3 2023-05-07 12:16:10.263521   0.484848   0.400  0.438356  0.061791  0.439537   \n",
       "4 2023-05-07 12:16:16.094689   0.484848   0.400  0.438356  0.061791  0.439537   \n",
       "\n",
       "   PublicScore  PrivateScore              OldPublicScore  \\\n",
       "0     0.666667      0.661017  [0.666666666, 0.666666666]   \n",
       "1     0.666667      0.649123   [0.69090909, 0.666666666]   \n",
       "2     0.711864      0.715447  [0.677419354, 0.711864406]   \n",
       "3     0.642857      0.620690  [0.678571428, 0.642857142]   \n",
       "4     0.642857      0.620690  [0.549019607, 0.642857142]   \n",
       "\n",
       "              OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949]        0.299595  \n",
       "1  [0.649122807, 0.649122807]        0.532630  \n",
       "2  [0.676923076, 0.715447154]        0.494966  \n",
       "3  [0.637168141, 0.620689655]        0.440685  \n",
       "4   [0.48076923, 0.620689655]        0.440685  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "val_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "test_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "X_entier.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "\n",
    "withoutverylowMI = comparemodels(train_X, train_y, val_X, test_X, \"Delete very low MI\")\n",
    "withoutverylowMI[\"PublicScore\"] = [0.666666666, 0.666666666, 0.711864406, 0.642857142, 0.642857142]\n",
    "withoutverylowMI[\"PrivateScore\"] = [0.661016949, 0.649122807, 0.715447154, 0.620689655, 0.620689655]\n",
    "withoutverylowMI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "073967ea",
   "metadata": {},
   "source": [
    "### 2.2 Delete low MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0235a795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Delete low MImax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 12:21:00.573581</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.157730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666, 0.666666666]</td>\n",
       "      <td>[0.661016949, 0.661016949]</td>\n",
       "      <td>0.199660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Delete low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 12:21:01.947710</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.051241</td>\n",
       "      <td>0.495474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909, 0.666666666]</td>\n",
       "      <td>[0.649122807, 0.649122807]</td>\n",
       "      <td>0.498927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Delete low MIscale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 12:21:04.540179</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.495413</td>\n",
       "      <td>0.082890</td>\n",
       "      <td>0.512908</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354, 0.711864406]</td>\n",
       "      <td>[0.676923076, 0.715447154]</td>\n",
       "      <td>0.518656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>Delete low MIupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 12:21:08.307593</td>\n",
       "      <td>0.358209</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.448598</td>\n",
       "      <td>0.088919</td>\n",
       "      <td>0.462470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.467319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>Delete low MIundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 12:21:12.017581</td>\n",
       "      <td>0.358209</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.448598</td>\n",
       "      <td>0.088919</td>\n",
       "      <td>0.462470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.467319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Model  \\\n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  RandomForestClassifierUpperSampling   \n",
       "4  RandomForestClassifierUnderSampling   \n",
       "\n",
       "                                                       Description  \\\n",
       "0              Delete low MImax_leaf_nodes : 6 + with date columns   \n",
       "1                         Delete low MIn_estimators : 36 + Entropy   \n",
       "2                               Delete low MIscale_pos_weight = 22   \n",
       "3     Delete low MIupsampled, n_estimators=36, criterion = entropy   \n",
       "4  Delete low MIundersampled, n_estimators=36, criterion = entropy   \n",
       "\n",
       "                        Date  Precision  Recall  F1-score   LogLoss       Mcc  \\\n",
       "0 2023-05-07 12:21:00.573581   0.500000   0.050  0.090909  0.060284  0.157730   \n",
       "1 2023-05-07 12:21:01.947710   0.615385   0.400  0.484848  0.051241  0.495474   \n",
       "2 2023-05-07 12:21:04.540179   0.391304   0.675  0.495413  0.082890  0.512908   \n",
       "3 2023-05-07 12:21:08.307593   0.358209   0.600  0.448598  0.088919  0.462470   \n",
       "4 2023-05-07 12:21:12.017581   0.358209   0.600  0.448598  0.088919  0.462470   \n",
       "\n",
       "   PublicScore  PrivateScore              OldPublicScore  \\\n",
       "0          NaN           NaN  [0.666666666, 0.666666666]   \n",
       "1          NaN           NaN   [0.69090909, 0.666666666]   \n",
       "2          NaN           NaN  [0.677419354, 0.711864406]   \n",
       "3          NaN           NaN  [0.678571428, 0.642857142]   \n",
       "4          NaN           NaN  [0.549019607, 0.642857142]   \n",
       "\n",
       "              OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949]        0.199660  \n",
       "1  [0.649122807, 0.649122807]        0.498927  \n",
       "2  [0.676923076, 0.715447154]        0.518656  \n",
       "3  [0.637168141, 0.620689655]        0.467319  \n",
       "4   [0.48076923, 0.620689655]        0.467319  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "val_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "test_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "X_entier.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "train_X.drop(lowMI, inplace=True, axis=1, errors='ignore')\n",
    "val_X.drop(lowMI, inplace=True, axis=1, errors='ignore')\n",
    "test_X.drop(lowMI, inplace=True, axis=1, errors='ignore')\n",
    "X_entier.drop(lowMI, inplace=True, axis=1, errors='ignore')\n",
    "\n",
    "withoutlowMI = comparemodels(train_X, train_y, val_X, test_X, \"Delete low MI\")\n",
    "withoutlowMI[\"PublicScore\"] = [np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "withoutlowMI[\"PrivateScore\"] = [np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "withoutlowMI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "47fb5923",
   "metadata": {},
   "source": [
    "### 2.3 Delete medium MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "463dd25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sarah\\Documents\\ECAM_non_One_Drive\\Interligence artificiel\\Projet Niko\\AI5L_AILab_FraudDetection\\EvaluationMetric.py:8: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  metric = tp / (tp+fp)\n",
      "c:\\Users\\sarah\\Documents\\ECAM_non_One_Drive\\Interligence artificiel\\Projet Niko\\AI5L_AILab_FraudDetection\\EvaluationMetric.py:20: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = tp / (tp+fp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sarah\\Documents\\ECAM_non_One_Drive\\Interligence artificiel\\Projet Niko\\AI5L_AILab_FraudDetection\\EvaluationMetric.py:8: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  metric = tp / (tp+fp)\n",
      "c:\\Users\\sarah\\Documents\\ECAM_non_One_Drive\\Interligence artificiel\\Projet Niko\\AI5L_AILab_FraudDetection\\EvaluationMetric.py:20: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = tp / (tp+fp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Delete medium MImax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 12:22:06.938129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666, 0.666666666]</td>\n",
       "      <td>[0.661016949, 0.661016949]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Delete medium MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 12:22:07.463399</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909, 0.666666666]</td>\n",
       "      <td>[0.649122807, 0.649122807]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Delete medium MIscale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 12:22:08.621075</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.162791</td>\n",
       "      <td>0.108511</td>\n",
       "      <td>0.161685</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354, 0.711864406]</td>\n",
       "      <td>[0.676923076, 0.715447154]</td>\n",
       "      <td>0.162913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>Delete medium MIupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 12:22:09.770741</td>\n",
       "      <td>0.010398</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.020544</td>\n",
       "      <td>4.885998</td>\n",
       "      <td>0.084977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.241480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>Delete medium MIundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 12:22:10.889597</td>\n",
       "      <td>0.010398</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.020544</td>\n",
       "      <td>4.885998</td>\n",
       "      <td>0.084977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.241480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Model  \\\n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  RandomForestClassifierUpperSampling   \n",
       "4  RandomForestClassifierUnderSampling   \n",
       "\n",
       "                                                          Description  \\\n",
       "0              Delete medium MImax_leaf_nodes : 6 + with date columns   \n",
       "1                         Delete medium MIn_estimators : 36 + Entropy   \n",
       "2                               Delete medium MIscale_pos_weight = 22   \n",
       "3     Delete medium MIupsampled, n_estimators=36, criterion = entropy   \n",
       "4  Delete medium MIundersampled, n_estimators=36, criterion = entropy   \n",
       "\n",
       "                        Date  Precision  Recall  F1-score   LogLoss       Mcc  \\\n",
       "0 2023-05-07 12:22:06.938129        NaN   0.000       NaN  0.060284  0.000000   \n",
       "1 2023-05-07 12:22:07.463399        NaN   0.000       NaN  0.060284  0.000000   \n",
       "2 2023-05-07 12:22:08.621075   0.152174   0.175  0.162791  0.108511  0.161685   \n",
       "3 2023-05-07 12:22:09.770741   0.010398   0.850  0.020544  4.885998  0.084977   \n",
       "4 2023-05-07 12:22:10.889597   0.010398   0.850  0.020544  4.885998  0.084977   \n",
       "\n",
       "   PublicScore  PrivateScore              OldPublicScore  \\\n",
       "0          NaN           NaN  [0.666666666, 0.666666666]   \n",
       "1          NaN           NaN   [0.69090909, 0.666666666]   \n",
       "2          NaN           NaN  [0.677419354, 0.711864406]   \n",
       "3          NaN           NaN  [0.678571428, 0.642857142]   \n",
       "4          NaN           NaN  [0.549019607, 0.642857142]   \n",
       "\n",
       "              OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949]        0.000000  \n",
       "1  [0.649122807, 0.649122807]        0.000000  \n",
       "2  [0.676923076, 0.715447154]        0.162913  \n",
       "3  [0.637168141, 0.620689655]        0.241480  \n",
       "4   [0.48076923, 0.620689655]        0.241480  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "val_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "test_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "X_entier.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "train_X.drop(lowMI, inplace=True, axis=1, errors='ignore')\n",
    "val_X.drop(lowMI, inplace=True, axis=1, errors='ignore')\n",
    "test_X.drop(lowMI, inplace=True, axis=1, errors='ignore')\n",
    "X_entier.drop(lowMI, inplace=True, axis=1, errors='ignore')\n",
    "\n",
    "train_X.drop(mediumMI, inplace=True, axis=1, errors='ignore')\n",
    "val_X.drop(mediumMI, inplace=True, axis=1, errors='ignore')\n",
    "test_X.drop(mediumMI, inplace=True, axis=1, errors='ignore')\n",
    "X_entier.drop(mediumMI, inplace=True, axis=1, errors='ignore')\n",
    "\n",
    "withoutmediumMI = comparemodels(train_X, train_y, val_X, test_X, \"Delete medium MI\")\n",
    "withoutmediumMI[\"PublicScore\"] = [np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "withoutmediumMI[\"PrivateScore\"] = [np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "withoutmediumMI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb6650c6",
   "metadata": {},
   "source": [
    "# Compare result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78eddab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>The referencemax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 12:06:12.077756</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>0.857566</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.661017</td>\n",
       "      <td>[0.666666666, 0.666666666]</td>\n",
       "      <td>[0.661016949, 0.661016949]</td>\n",
       "      <td>0.857900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>The referencen_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 12:06:13.810833</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.843373</td>\n",
       "      <td>0.019592</td>\n",
       "      <td>0.843655</td>\n",
       "      <td>0.690909</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>[0.69090909, 0.666666666]</td>\n",
       "      <td>[0.649122807, 0.649122807]</td>\n",
       "      <td>0.843995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>The referencescale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 12:06:16.406438</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>0.871874</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.676923</td>\n",
       "      <td>[0.677419354, 0.711864406]</td>\n",
       "      <td>[0.676923076, 0.715447154]</td>\n",
       "      <td>0.872421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>The referenceupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 12:06:20.249096</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.022606</td>\n",
       "      <td>0.824649</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.637168</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.825239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>The referenceundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 12:06:23.944705</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.022606</td>\n",
       "      <td>0.824649</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.825239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Delete very low MImax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 12:15:59.362979</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.057270</td>\n",
       "      <td>0.257799</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.661017</td>\n",
       "      <td>[0.666666666, 0.666666666]</td>\n",
       "      <td>[0.661016949, 0.661016949]</td>\n",
       "      <td>0.299595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Delete very low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 12:16:01.466270</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.507937</td>\n",
       "      <td>0.046720</td>\n",
       "      <td>0.526930</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>[0.69090909, 0.666666666]</td>\n",
       "      <td>[0.649122807, 0.649122807]</td>\n",
       "      <td>0.532630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Delete very low MIscale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 12:16:05.133214</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.494118</td>\n",
       "      <td>0.064805</td>\n",
       "      <td>0.494079</td>\n",
       "      <td>0.711864</td>\n",
       "      <td>0.715447</td>\n",
       "      <td>[0.677419354, 0.711864406]</td>\n",
       "      <td>[0.676923076, 0.715447154]</td>\n",
       "      <td>0.494966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>Delete very low MIupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 12:16:10.263521</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.438356</td>\n",
       "      <td>0.061791</td>\n",
       "      <td>0.439537</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.440685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>Delete very low MIundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 12:16:16.094689</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.438356</td>\n",
       "      <td>0.061791</td>\n",
       "      <td>0.439537</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.440685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Delete low MImax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 12:21:00.573581</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.157730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666, 0.666666666]</td>\n",
       "      <td>[0.661016949, 0.661016949]</td>\n",
       "      <td>0.199660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Delete low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 12:21:01.947710</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.051241</td>\n",
       "      <td>0.495474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909, 0.666666666]</td>\n",
       "      <td>[0.649122807, 0.649122807]</td>\n",
       "      <td>0.498927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Delete low MIscale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 12:21:04.540179</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.495413</td>\n",
       "      <td>0.082890</td>\n",
       "      <td>0.512908</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354, 0.711864406]</td>\n",
       "      <td>[0.676923076, 0.715447154]</td>\n",
       "      <td>0.518656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>Delete low MIupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 12:21:08.307593</td>\n",
       "      <td>0.358209</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.448598</td>\n",
       "      <td>0.088919</td>\n",
       "      <td>0.462470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.467319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>Delete low MIundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 12:21:12.017581</td>\n",
       "      <td>0.358209</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.448598</td>\n",
       "      <td>0.088919</td>\n",
       "      <td>0.462470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.467319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Delete medium MImax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 12:22:06.938129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666, 0.666666666]</td>\n",
       "      <td>[0.661016949, 0.661016949]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Delete medium MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 12:22:07.463399</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909, 0.666666666]</td>\n",
       "      <td>[0.649122807, 0.649122807]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Delete medium MIscale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 12:22:08.621075</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.162791</td>\n",
       "      <td>0.108511</td>\n",
       "      <td>0.161685</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354, 0.711864406]</td>\n",
       "      <td>[0.676923076, 0.715447154]</td>\n",
       "      <td>0.162913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>Delete medium MIupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 12:22:09.770741</td>\n",
       "      <td>0.010398</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.020544</td>\n",
       "      <td>4.885998</td>\n",
       "      <td>0.084977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.241480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>Delete medium MIundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 12:22:10.889597</td>\n",
       "      <td>0.010398</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.020544</td>\n",
       "      <td>4.885998</td>\n",
       "      <td>0.084977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.241480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Model  \\\n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  RandomForestClassifierUpperSampling   \n",
       "4  RandomForestClassifierUnderSampling   \n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  RandomForestClassifierUpperSampling   \n",
       "4  RandomForestClassifierUnderSampling   \n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  RandomForestClassifierUpperSampling   \n",
       "4  RandomForestClassifierUnderSampling   \n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  RandomForestClassifierUpperSampling   \n",
       "4  RandomForestClassifierUnderSampling   \n",
       "\n",
       "                                                            Description  \\\n",
       "0                   The referencemax_leaf_nodes : 6 + with date columns   \n",
       "1                              The referencen_estimators : 36 + Entropy   \n",
       "2                                    The referencescale_pos_weight = 22   \n",
       "3          The referenceupsampled, n_estimators=36, criterion = entropy   \n",
       "4       The referenceundersampled, n_estimators=36, criterion = entropy   \n",
       "0              Delete very low MImax_leaf_nodes : 6 + with date columns   \n",
       "1                         Delete very low MIn_estimators : 36 + Entropy   \n",
       "2                               Delete very low MIscale_pos_weight = 22   \n",
       "3     Delete very low MIupsampled, n_estimators=36, criterion = entropy   \n",
       "4  Delete very low MIundersampled, n_estimators=36, criterion = entropy   \n",
       "0                   Delete low MImax_leaf_nodes : 6 + with date columns   \n",
       "1                              Delete low MIn_estimators : 36 + Entropy   \n",
       "2                                    Delete low MIscale_pos_weight = 22   \n",
       "3          Delete low MIupsampled, n_estimators=36, criterion = entropy   \n",
       "4       Delete low MIundersampled, n_estimators=36, criterion = entropy   \n",
       "0                Delete medium MImax_leaf_nodes : 6 + with date columns   \n",
       "1                           Delete medium MIn_estimators : 36 + Entropy   \n",
       "2                                 Delete medium MIscale_pos_weight = 22   \n",
       "3       Delete medium MIupsampled, n_estimators=36, criterion = entropy   \n",
       "4    Delete medium MIundersampled, n_estimators=36, criterion = entropy   \n",
       "\n",
       "                        Date  Precision  Recall  F1-score   LogLoss       Mcc  \\\n",
       "0 2023-05-07 12:06:12.077756   0.891892   0.825  0.857143  0.016578  0.857566   \n",
       "1 2023-05-07 12:06:13.810833   0.813953   0.875  0.843373  0.019592  0.843655   \n",
       "2 2023-05-07 12:06:16.406438   0.822222   0.925  0.870588  0.016578  0.871874   \n",
       "3 2023-05-07 12:06:20.249096   0.777778   0.875  0.823529  0.022606  0.824649   \n",
       "4 2023-05-07 12:06:23.944705   0.777778   0.875  0.823529  0.022606  0.824649   \n",
       "0 2023-05-07 12:15:59.362979   0.666667   0.100  0.173913  0.057270  0.257799   \n",
       "1 2023-05-07 12:16:01.466270   0.695652   0.400  0.507937  0.046720  0.526930   \n",
       "2 2023-05-07 12:16:05.133214   0.466667   0.525  0.494118  0.064805  0.494079   \n",
       "3 2023-05-07 12:16:10.263521   0.484848   0.400  0.438356  0.061791  0.439537   \n",
       "4 2023-05-07 12:16:16.094689   0.484848   0.400  0.438356  0.061791  0.439537   \n",
       "0 2023-05-07 12:21:00.573581   0.500000   0.050  0.090909  0.060284  0.157730   \n",
       "1 2023-05-07 12:21:01.947710   0.615385   0.400  0.484848  0.051241  0.495474   \n",
       "2 2023-05-07 12:21:04.540179   0.391304   0.675  0.495413  0.082890  0.512908   \n",
       "3 2023-05-07 12:21:08.307593   0.358209   0.600  0.448598  0.088919  0.462470   \n",
       "4 2023-05-07 12:21:12.017581   0.358209   0.600  0.448598  0.088919  0.462470   \n",
       "0 2023-05-07 12:22:06.938129        NaN   0.000       NaN  0.060284  0.000000   \n",
       "1 2023-05-07 12:22:07.463399        NaN   0.000       NaN  0.060284  0.000000   \n",
       "2 2023-05-07 12:22:08.621075   0.152174   0.175  0.162791  0.108511  0.161685   \n",
       "3 2023-05-07 12:22:09.770741   0.010398   0.850  0.020544  4.885998  0.084977   \n",
       "4 2023-05-07 12:22:10.889597   0.010398   0.850  0.020544  4.885998  0.084977   \n",
       "\n",
       "   PublicScore  PrivateScore              OldPublicScore  \\\n",
       "0     0.666667      0.661017  [0.666666666, 0.666666666]   \n",
       "1     0.690909      0.649123   [0.69090909, 0.666666666]   \n",
       "2     0.677419      0.676923  [0.677419354, 0.711864406]   \n",
       "3     0.678571      0.637168  [0.678571428, 0.642857142]   \n",
       "4     0.549020      0.480769  [0.549019607, 0.642857142]   \n",
       "0     0.666667      0.661017  [0.666666666, 0.666666666]   \n",
       "1     0.666667      0.649123   [0.69090909, 0.666666666]   \n",
       "2     0.711864      0.715447  [0.677419354, 0.711864406]   \n",
       "3     0.642857      0.620690  [0.678571428, 0.642857142]   \n",
       "4     0.642857      0.620690  [0.549019607, 0.642857142]   \n",
       "0          NaN           NaN  [0.666666666, 0.666666666]   \n",
       "1          NaN           NaN   [0.69090909, 0.666666666]   \n",
       "2          NaN           NaN  [0.677419354, 0.711864406]   \n",
       "3          NaN           NaN  [0.678571428, 0.642857142]   \n",
       "4          NaN           NaN  [0.549019607, 0.642857142]   \n",
       "0          NaN           NaN  [0.666666666, 0.666666666]   \n",
       "1          NaN           NaN   [0.69090909, 0.666666666]   \n",
       "2          NaN           NaN  [0.677419354, 0.711864406]   \n",
       "3          NaN           NaN  [0.678571428, 0.642857142]   \n",
       "4          NaN           NaN  [0.549019607, 0.642857142]   \n",
       "\n",
       "              OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949]        0.857900  \n",
       "1  [0.649122807, 0.649122807]        0.843995  \n",
       "2  [0.676923076, 0.715447154]        0.872421  \n",
       "3  [0.637168141, 0.620689655]        0.825239  \n",
       "4   [0.48076923, 0.620689655]        0.825239  \n",
       "0  [0.661016949, 0.661016949]        0.299595  \n",
       "1  [0.649122807, 0.649122807]        0.532630  \n",
       "2  [0.676923076, 0.715447154]        0.494966  \n",
       "3  [0.637168141, 0.620689655]        0.440685  \n",
       "4   [0.48076923, 0.620689655]        0.440685  \n",
       "0  [0.661016949, 0.661016949]        0.199660  \n",
       "1  [0.649122807, 0.649122807]        0.498927  \n",
       "2  [0.676923076, 0.715447154]        0.518656  \n",
       "3  [0.637168141, 0.620689655]        0.467319  \n",
       "4   [0.48076923, 0.620689655]        0.467319  \n",
       "0  [0.661016949, 0.661016949]        0.000000  \n",
       "1  [0.649122807, 0.649122807]        0.000000  \n",
       "2  [0.676923076, 0.715447154]        0.162913  \n",
       "3  [0.637168141, 0.620689655]        0.241480  \n",
       "4   [0.48076923, 0.620689655]        0.241480  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfResult = pd.concat([referenceresult, withoutverylowMI, withoutlowMI, withoutmediumMI])\n",
    "dfResult"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f71d0234",
   "metadata": {},
   "source": [
    "# Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ba35bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>La basemax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-06 20:37:01.701978</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>0.857566</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>[0.661016949]</td>\n",
       "      <td>0.857900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>La basen_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-06 20:37:02.891559</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.019592</td>\n",
       "      <td>0.848262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909]</td>\n",
       "      <td>[0.649122807]</td>\n",
       "      <td>0.848830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>La basescale_pos_weight = 22</td>\n",
       "      <td>2023-05-06 20:37:04.316049</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.881747</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354]</td>\n",
       "      <td>[0.676923076]</td>\n",
       "      <td>0.882152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>La baseupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-06 20:37:06.774426</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.022606</td>\n",
       "      <td>0.829975</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.637168141]</td>\n",
       "      <td>0.830880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>La baseundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-06 20:37:09.025865</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.022606</td>\n",
       "      <td>0.829975</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.549019607]</td>\n",
       "      <td>[0.48076923]</td>\n",
       "      <td>0.830880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>Sans veryLow MImax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-06 20:51:15.706650</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.013564</td>\n",
       "      <td>0.881780</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>[0.661016949]</td>\n",
       "      <td>0.882409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Sans veryLow MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-06 20:51:16.916077</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.025621</td>\n",
       "      <td>0.801037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909]</td>\n",
       "      <td>[0.649122807]</td>\n",
       "      <td>0.801648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Sans veryLow MIscale_pos_weight = 22</td>\n",
       "      <td>2023-05-06 20:51:18.180099</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.891566</td>\n",
       "      <td>0.013564</td>\n",
       "      <td>0.891963</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354]</td>\n",
       "      <td>[0.676923076]</td>\n",
       "      <td>0.892249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>Sans veryLow MIupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-06 20:51:20.658177</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.021099</td>\n",
       "      <td>0.838969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.637168141]</td>\n",
       "      <td>0.839697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>Sans veryLow MIundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-06 20:51:22.937609</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.021099</td>\n",
       "      <td>0.838969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.549019607]</td>\n",
       "      <td>[0.48076923]</td>\n",
       "      <td>0.839697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>Sans Low MImax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-06 20:51:23.078874</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.157730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>[0.661016949]</td>\n",
       "      <td>0.199660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Sans Low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-06 20:51:24.053805</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>0.054255</td>\n",
       "      <td>0.490016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909]</td>\n",
       "      <td>[0.649122807]</td>\n",
       "      <td>0.491849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Sans Low MIscale_pos_weight = 22</td>\n",
       "      <td>2023-05-06 20:51:24.981709</td>\n",
       "      <td>0.397059</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.081383</td>\n",
       "      <td>0.516687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354]</td>\n",
       "      <td>[0.676923076]</td>\n",
       "      <td>0.522187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>Sans Low MIupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-06 20:51:27.254243</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.436364</td>\n",
       "      <td>0.093440</td>\n",
       "      <td>0.452385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.637168141]</td>\n",
       "      <td>0.457902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>Sans Low MIundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-06 20:51:29.419018</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.436364</td>\n",
       "      <td>0.093440</td>\n",
       "      <td>0.452385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.549019607]</td>\n",
       "      <td>[0.48076923]</td>\n",
       "      <td>0.457902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>Sans mediumMI MImax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-06 20:51:29.534162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>[0.661016949]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Sans mediumMI MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-06 20:51:29.969941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909]</td>\n",
       "      <td>[0.649122807]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Sans mediumMI MIscale_pos_weight = 22</td>\n",
       "      <td>2023-05-06 20:51:30.439168</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.162791</td>\n",
       "      <td>0.108511</td>\n",
       "      <td>0.161685</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354]</td>\n",
       "      <td>[0.676923076]</td>\n",
       "      <td>0.162913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>Sans mediumMI MIupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-06 20:51:31.381130</td>\n",
       "      <td>0.010616</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.020977</td>\n",
       "      <td>4.923675</td>\n",
       "      <td>0.087518</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.637168141]</td>\n",
       "      <td>0.248528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>Sans mediumMI MIundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-06 20:51:32.149516</td>\n",
       "      <td>0.010616</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.020977</td>\n",
       "      <td>4.923675</td>\n",
       "      <td>0.087518</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.549019607]</td>\n",
       "      <td>[0.48076923]</td>\n",
       "      <td>0.248528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Model  \\\n",
       "0              Decision Tree Classifier   \n",
       "1              Random Forest Classifier   \n",
       "2                         XGBClassifier   \n",
       "3   RandomForestClassifierUpperSampling   \n",
       "4   RandomForestClassifierUnderSampling   \n",
       "5              Decision Tree Classifier   \n",
       "6              Random Forest Classifier   \n",
       "7                         XGBClassifier   \n",
       "8   RandomForestClassifierUpperSampling   \n",
       "9   RandomForestClassifierUnderSampling   \n",
       "10             Decision Tree Classifier   \n",
       "11             Random Forest Classifier   \n",
       "12                        XGBClassifier   \n",
       "13  RandomForestClassifierUpperSampling   \n",
       "14  RandomForestClassifierUnderSampling   \n",
       "15             Decision Tree Classifier   \n",
       "16             Random Forest Classifier   \n",
       "17                        XGBClassifier   \n",
       "18  RandomForestClassifierUpperSampling   \n",
       "19  RandomForestClassifierUnderSampling   \n",
       "\n",
       "                                                           Description  \\\n",
       "0                        La basemax_leaf_nodes : 6 + with date columns   \n",
       "1                                   La basen_estimators : 36 + Entropy   \n",
       "2                                         La basescale_pos_weight = 22   \n",
       "3               La baseupsampled, n_estimators=36, criterion = entropy   \n",
       "4            La baseundersampled, n_estimators=36, criterion = entropy   \n",
       "5                Sans veryLow MImax_leaf_nodes : 6 + with date columns   \n",
       "6                           Sans veryLow MIn_estimators : 36 + Entropy   \n",
       "7                                 Sans veryLow MIscale_pos_weight = 22   \n",
       "8       Sans veryLow MIupsampled, n_estimators=36, criterion = entropy   \n",
       "9    Sans veryLow MIundersampled, n_estimators=36, criterion = entropy   \n",
       "10                   Sans Low MImax_leaf_nodes : 6 + with date columns   \n",
       "11                              Sans Low MIn_estimators : 36 + Entropy   \n",
       "12                                    Sans Low MIscale_pos_weight = 22   \n",
       "13          Sans Low MIupsampled, n_estimators=36, criterion = entropy   \n",
       "14       Sans Low MIundersampled, n_estimators=36, criterion = entropy   \n",
       "15              Sans mediumMI MImax_leaf_nodes : 6 + with date columns   \n",
       "16                         Sans mediumMI MIn_estimators : 36 + Entropy   \n",
       "17                               Sans mediumMI MIscale_pos_weight = 22   \n",
       "18     Sans mediumMI MIupsampled, n_estimators=36, criterion = entropy   \n",
       "19  Sans mediumMI MIundersampled, n_estimators=36, criterion = entropy   \n",
       "\n",
       "                          Date  Precision  Recall  F1-score   LogLoss  \\\n",
       "0   2023-05-06 20:37:01.701978   0.891892   0.825  0.857143  0.016578   \n",
       "1   2023-05-06 20:37:02.891559   0.800000   0.900  0.847059  0.019592   \n",
       "2   2023-05-06 20:37:04.316049   0.840909   0.925  0.880952  0.015071   \n",
       "3   2023-05-06 20:37:06.774426   0.765957   0.900  0.827586  0.022606   \n",
       "4   2023-05-06 20:37:09.025865   0.765957   0.900  0.827586  0.022606   \n",
       "5   2023-05-06 20:51:15.706650   0.942857   0.825  0.880000  0.013564   \n",
       "6   2023-05-06 20:51:16.916077   0.755556   0.850  0.800000  0.025621   \n",
       "7   2023-05-06 20:51:18.180099   0.860465   0.925  0.891566  0.013564   \n",
       "8   2023-05-06 20:51:20.658177   0.782609   0.900  0.837209  0.021099   \n",
       "9   2023-05-06 20:51:22.937609   0.782609   0.900  0.837209  0.021099   \n",
       "10  2023-05-06 20:51:23.078874   0.500000   0.050  0.090909  0.060284   \n",
       "11  2023-05-06 20:51:24.053805   0.566667   0.425  0.485714  0.054255   \n",
       "12  2023-05-06 20:51:24.981709   0.397059   0.675  0.500000  0.081383   \n",
       "13  2023-05-06 20:51:27.254243   0.342857   0.600  0.436364  0.093440   \n",
       "14  2023-05-06 20:51:29.419018   0.342857   0.600  0.436364  0.093440   \n",
       "15  2023-05-06 20:51:29.534162        NaN   0.000       NaN  0.060284   \n",
       "16  2023-05-06 20:51:29.969941        NaN   0.000       NaN  0.060284   \n",
       "17  2023-05-06 20:51:30.439168   0.152174   0.175  0.162791  0.108511   \n",
       "18  2023-05-06 20:51:31.381130   0.010616   0.875  0.020977  4.923675   \n",
       "19  2023-05-06 20:51:32.149516   0.010616   0.875  0.020977  4.923675   \n",
       "\n",
       "         Mcc  PublicScore  PrivateScore OldPublicScore OldPrivateScore  \\\n",
       "0   0.857566          NaN           NaN  [0.666666666]   [0.661016949]   \n",
       "1   0.848262          NaN           NaN   [0.69090909]   [0.649122807]   \n",
       "2   0.881747          NaN           NaN  [0.677419354]   [0.676923076]   \n",
       "3   0.829975          NaN           NaN  [0.678571428]   [0.637168141]   \n",
       "4   0.829975          NaN           NaN  [0.549019607]    [0.48076923]   \n",
       "5   0.881780          NaN           NaN  [0.666666666]   [0.661016949]   \n",
       "6   0.801037          NaN           NaN   [0.69090909]   [0.649122807]   \n",
       "7   0.891963          NaN           NaN  [0.677419354]   [0.676923076]   \n",
       "8   0.838969          NaN           NaN  [0.678571428]   [0.637168141]   \n",
       "9   0.838969          NaN           NaN  [0.549019607]    [0.48076923]   \n",
       "10  0.157730          NaN           NaN  [0.666666666]   [0.661016949]   \n",
       "11  0.490016          NaN           NaN   [0.69090909]   [0.649122807]   \n",
       "12  0.516687          NaN           NaN  [0.677419354]   [0.676923076]   \n",
       "13  0.452385          NaN           NaN  [0.678571428]   [0.637168141]   \n",
       "14  0.452385          NaN           NaN  [0.549019607]    [0.48076923]   \n",
       "15  0.000000          NaN           NaN  [0.666666666]   [0.661016949]   \n",
       "16  0.000000          NaN           NaN   [0.69090909]   [0.649122807]   \n",
       "17  0.161685          NaN           NaN  [0.677419354]   [0.676923076]   \n",
       "18  0.087518          NaN           NaN  [0.678571428]   [0.637168141]   \n",
       "19  0.087518          NaN           NaN  [0.549019607]    [0.48076923]   \n",
       "\n",
       "    MeanOurMetrics  \n",
       "0         0.857900  \n",
       "1         0.848830  \n",
       "2         0.882152  \n",
       "3         0.830880  \n",
       "4         0.830880  \n",
       "5         0.882409  \n",
       "6         0.801648  \n",
       "7         0.892249  \n",
       "8         0.839697  \n",
       "9         0.839697  \n",
       "10        0.199660  \n",
       "11        0.491849  \n",
       "12        0.522187  \n",
       "13        0.457902  \n",
       "14        0.457902  \n",
       "15        0.000000  \n",
       "16        0.000000  \n",
       "17        0.162913  \n",
       "18        0.248528  \n",
       "19        0.248528  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfresult  = pd.read_csv(\"output/resultatsTestEverything.csv\")\n",
    "dfresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b9a49624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les meilleurs résultat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarah\\AppData\\Local\\Temp\\ipykernel_18636\\2367281751.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  dfresult.groupby(['Model'])['Precision','Recall','F1-score','LogLoss','MeanOurMetrics'].max()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classifier</th>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.882409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.848830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifierUnderSampling</th>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>4.923675</td>\n",
       "      <td>0.839697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifierUpperSampling</th>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>4.923675</td>\n",
       "      <td>0.839697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.891566</td>\n",
       "      <td>0.108511</td>\n",
       "      <td>0.892249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Precision  Recall  F1-score   LogLoss  \\\n",
       "Model                                                                        \n",
       "Decision Tree Classifier              0.942857   0.825  0.880000  0.060284   \n",
       "Random Forest Classifier              0.800000   0.900  0.847059  0.060284   \n",
       "RandomForestClassifierUnderSampling   0.782609   0.900  0.837209  4.923675   \n",
       "RandomForestClassifierUpperSampling   0.782609   0.900  0.837209  4.923675   \n",
       "XGBClassifier                         0.860465   0.925  0.891566  0.108511   \n",
       "\n",
       "                                     MeanOurMetrics  \n",
       "Model                                                \n",
       "Decision Tree Classifier                   0.882409  \n",
       "Random Forest Classifier                   0.848830  \n",
       "RandomForestClassifierUnderSampling        0.839697  \n",
       "RandomForestClassifierUpperSampling        0.839697  \n",
       "XGBClassifier                              0.892249  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Les meilleurs résultat\")\n",
    "dfresult.groupby(['Model'])['Precision','Recall','F1-score','LogLoss','MeanOurMetrics'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e794338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les pire résultat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarah\\AppData\\Local\\Temp\\ipykernel_18636\\2101499374.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  dfresult.groupby(['Model'])['Precision','Recall','F1-score','LogLoss','MeanOurMetrics'].min()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classifier</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.013564</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>0.019592</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifierUnderSampling</th>\n",
       "      <td>0.010616</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.020977</td>\n",
       "      <td>0.021099</td>\n",
       "      <td>0.248528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifierUpperSampling</th>\n",
       "      <td>0.010616</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.020977</td>\n",
       "      <td>0.021099</td>\n",
       "      <td>0.248528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.162791</td>\n",
       "      <td>0.013564</td>\n",
       "      <td>0.162913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Precision  Recall  F1-score   LogLoss  \\\n",
       "Model                                                                        \n",
       "Decision Tree Classifier              0.500000   0.000  0.090909  0.013564   \n",
       "Random Forest Classifier              0.566667   0.000  0.485714  0.019592   \n",
       "RandomForestClassifierUnderSampling   0.010616   0.600  0.020977  0.021099   \n",
       "RandomForestClassifierUpperSampling   0.010616   0.600  0.020977  0.021099   \n",
       "XGBClassifier                         0.152174   0.175  0.162791  0.013564   \n",
       "\n",
       "                                     MeanOurMetrics  \n",
       "Model                                                \n",
       "Decision Tree Classifier                   0.000000  \n",
       "Random Forest Classifier                   0.000000  \n",
       "RandomForestClassifierUnderSampling        0.248528  \n",
       "RandomForestClassifierUpperSampling        0.248528  \n",
       "XGBClassifier                              0.162913  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Les pire résultat\")\n",
    "dfresult.groupby(['Model'])['Precision','Recall','F1-score','LogLoss','MeanOurMetrics'].min()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b1929d5d",
   "metadata": {},
   "source": [
    "## Test cluster Kmeans en plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f58714f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'airtime'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 77\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# Créer des \"centres\" pour KMeans\u001b[39;00m\n\u001b[0;32m     76\u001b[0m n_clusters \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m193\u001b[39m\n\u001b[1;32m---> 77\u001b[0m kmeans \u001b[38;5;241m=\u001b[39m \u001b[43mKMeans\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_clusters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_clusters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m centers \u001b[38;5;241m=\u001b[39m kmeans\u001b[38;5;241m.\u001b[39mcluster_centers_\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# Trouver les indices des instances à garder dans la classe FraudResult=0\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\AILab-ECAM4\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1417\u001b[0m, in \u001b[0;36mKMeans.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;124;03m\"\"\"Compute k-means clustering.\u001b[39;00m\n\u001b[0;32m   1391\u001b[0m \n\u001b[0;32m   1392\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1413\u001b[0m \u001b[38;5;124;03m    Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1414\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1415\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m-> 1417\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1418\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1419\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1420\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1421\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1423\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1424\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params_vs_input(X)\n\u001b[0;32m   1428\u001b[0m random_state \u001b[38;5;241m=\u001b[39m check_random_state(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\AILab-ECAM4\\lib\\site-packages\\sklearn\\base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    563\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 565\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    566\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\AILab-ECAM4\\lib\\site-packages\\sklearn\\utils\\validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    877\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    878\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 879\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    882\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    883\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\AILab-ECAM4\\lib\\site-packages\\sklearn\\utils\\_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    182\u001b[0m     xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(array)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy.array_api\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\AILab-ECAM4\\lib\\site-packages\\pandas\\core\\generic.py:2070\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2069\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m-> 2070\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'airtime'"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans \n",
    "\n",
    "# Supprimer les MI trop faible et K-means fait sur training set entier (et ensuite sur seuelement le train_X)\n",
    "def_feature = pd.read_csv(\"input/Xente_Variable_Definitions.csv\")\n",
    "raw_data = pd.read_csv(\"input/training.csv\")\n",
    "X_test = pd.read_csv(\"input/test.csv\")\n",
    "sample_submission = pd.read_csv(\"input/sample_submission.csv\")\n",
    "\n",
    "#attribut initialization\n",
    "cols_unique_value = [] #Will be droped\n",
    "for col in raw_data.columns : \n",
    "    if len(raw_data[col].unique()) == 1 :\n",
    "        cols_unique_value.append(col)\n",
    "\n",
    "medium_cardianlity_cols = [\"ProductId\"]\n",
    "\n",
    "#Data transformation\n",
    "raw_data['TransactionStartTime'] = pd.to_datetime(raw_data['TransactionStartTime'])\n",
    "X_test['TransactionStartTime'] = pd.to_datetime(X_test['TransactionStartTime'])\n",
    "\n",
    "#Data cleaning\n",
    "data = raw_data.copy()\n",
    "data = data.dropna(axis=0) #Drop observations/rows with missing values\n",
    "X_test=X_test.dropna(axis=0)\n",
    "data.drop(cols_unique_value, axis=1, inplace=True)\n",
    "X_test.drop(cols_unique_value, axis=1, inplace=True)\n",
    "\n",
    "#Prepare index for the submission\n",
    "index_val = list(X_test.TransactionId.values.tolist())\n",
    "\n",
    "#Set the df index to the Transction Id\n",
    "data = transactioId_to_index(data)\n",
    "X_test = transactioId_to_index(X_test)\n",
    "\n",
    "#Adding data\n",
    "data = adding_date_col(data, 'TransactionStartTime')\n",
    "X_test = adding_date_col(X_test, 'TransactionStartTime')\n",
    "\n",
    "\n",
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "low_cardinality_cols = [cname for cname in data.columns if data[cname].nunique() < 15 and \n",
    "                        data[cname].dtype == \"object\"]\n",
    "low_cardinality_cols.append('PricingStrategy')\n",
    "\n",
    "#transform columns BatchId_54 to number\n",
    "\n",
    "l_col_str = [\"BatchId\", \"AccountId\", \"SubscriptionId\", \"CustomerId\", \"ProviderId\", \"ProductId\", \"ChannelId\"]\n",
    "for col in l_col_str:\n",
    "    data[['dc', 'new_col']] = data[col].str.split(\"_\", expand = True)\n",
    "    data.drop(['dc',col], inplace=True, axis=1)\n",
    "    data.rename(columns={\"new_col\": col}, inplace=True)\n",
    "    data[col] = data[col].astype('int')\n",
    "    X_test[['dc', 'new_col']] = X_test[col].str.split(\"_\", expand = True)\n",
    "    X_test.drop(['dc',col], inplace=True, axis=1)\n",
    "    X_test.rename(columns={\"new_col\": col}, inplace=True)\n",
    "    X_test[col] = X_test[col].astype('int')\n",
    "data['PricingStrategy'] = data['PricingStrategy'].astype('int')\n",
    "X_test['PricingStrategy'] = X_test['PricingStrategy'].astype('int')\n",
    "data['Value'] = data['Value'].astype('float')\n",
    "X_test['Value'] = X_test['Value'].astype('float')\n",
    "\n",
    "X_test['PricingStrategy'] = X_test['PricingStrategy'].astype('str')\n",
    "data['PricingStrategy'] = data['PricingStrategy'].astype('str')\n",
    "\n",
    "#Data splitting\n",
    "y = data.FraudResult #The target label\n",
    "X = data.copy()\n",
    "X.drop(['FraudResult'], axis=1, inplace=True) #Only the features data\n",
    "\n",
    "#####K-Means\n",
    "X_0 = X[y == 0] # instances avec FraudResult=0\n",
    "X_1 = X[y == 1] # instances avec FraudResult=1\n",
    "\n",
    "# Créer des \"centres\" pour KMeans\n",
    "n_clusters = 193\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(X_0)\n",
    "centers = kmeans.cluster_centers_\n",
    "\n",
    "# Trouver les indices des instances à garder dans la classe FraudResult=0\n",
    "labels = kmeans.predict(X_0)\n",
    "distances = np.sum((X_0 - centers[labels]) ** 2, axis=1)\n",
    "keep_indices = np.argsort(distances)[:n_clusters]\n",
    "\n",
    "# Combiner les instances sous-échantillonnées\n",
    "X_undersampled = np.concatenate((X_0[keep_indices], X_1), axis=0)\n",
    "y_undersampled = np.concatenate((np.zeros(n_clusters), np.ones(len(X_1))), axis=0)\n",
    "\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(X_undersampled, y_undersampled, random_state = 0)\n",
    "\n",
    "cat_cols = [col for col in X.columns if X[col].dtype == \"object\"]#liste of obejct columns\n",
    "cat_cols.append(\"PricingStrategy\")#pcq mm si c'est un chiffre il faut le considérer comme une catégorie\n",
    "\n",
    "#print(describe)\n",
    "\n",
    "\n",
    "#low_cardinality_cols=[\"ProviderId\", \"ProductCategory\", \"ChannelId\", \"PricingStrategy\"] \n",
    "#train_X[low_cardinality_cols] = train_X[low_cardinality_cols].astype(str) \n",
    "#val_X[low_cardinality_cols] = val_X[low_cardinality_cols].astype(str) \n",
    "\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(train_X[low_cardinality_cols]))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(val_X[low_cardinality_cols]))\n",
    "OH_cols_test = pd.DataFrame(OH_encoder.transform(X_test[low_cardinality_cols]))\n",
    "OH_cols_train.columns = OH_encoder.get_feature_names_out()\n",
    "OH_cols_valid.columns = OH_encoder.get_feature_names_out()\n",
    "OH_cols_test.columns = OH_encoder.get_feature_names_out()\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_train.index = train_X.index\n",
    "OH_cols_valid.index = val_X.index\n",
    "OH_cols_test.index = X_test.index\n",
    "\n",
    "\n",
    "OH_cols_train[list(OH_cols_train.columns)] = OH_cols_train[list(OH_cols_train.columns)].astype(int)\n",
    "OH_cols_valid[list(OH_cols_valid.columns)] = OH_cols_valid[list(OH_cols_valid.columns)].astype(int)\n",
    "OH_cols_test[list(OH_cols_test.columns)] = OH_cols_test[list(OH_cols_test.columns)].astype(int)\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train = train_X.drop(low_cardinality_cols, axis=1)\n",
    "num_X_valid = val_X.drop(low_cardinality_cols, axis=1)\n",
    "num_X_test = X_test.drop(low_cardinality_cols, axis=1)\n",
    "\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
    "OH_X_test = pd.concat([num_X_test, OH_cols_test], axis=1)\n",
    "\n",
    "# Problème de string\n",
    "OH_X_train.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_valid.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_test.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_train.columns = OH_X_train.columns.astype(str)\n",
    "OH_X_valid.columns = OH_X_valid.columns.astype(str)\n",
    "OH_X_test.columns = OH_X_test.columns.astype(str)\n",
    "\n",
    "train_X = OH_X_train\n",
    "val_X = OH_X_valid\n",
    "test_X = OH_X_test\n",
    "X_entier = pd.concat([train_X, val_X])\n",
    "\n",
    "mi_scores = make_mi_scores(X_entier , y)\n",
    "\n",
    "verylowMI = list(mi_scores[mi_scores<0.0001].index)\n",
    "\n",
    "train_X.drop(verylowMI, inplace=True, axis=1)\n",
    "val_X.drop(verylowMI, inplace=True, axis=1)\n",
    "test_X.drop(verylowMI, inplace=True, axis=1)\n",
    "X_entier.drop(verylowMI, inplace=True, axis=1)\n",
    "\n",
    "\n",
    "res = []\n",
    "\n",
    "model1 = DecisionTreeClassifier(max_leaf_nodes= 6, random_state=1)\n",
    "model1.fit(train_X, train_y)\n",
    "preds_val1 = model1.predict(val_X)\n",
    "model_test1 = model1.predict(test_X)\n",
    "description = descriptiontous+\"max_leaf_nodes : 6 + with date columns\"\n",
    "metrics1 = listmetrics(val_y, preds_val1, \"Decision Tree Classifier\", description)\n",
    "m1Public = [0.666666666]\n",
    "m1Private = [0.661016949]\n",
    "res.append(metrics1)\n",
    "df1 = getscoreforcsv(index_val, model_test1, name_file = \"TreeClass5leaf.csv\")\n",
    "\n",
    "\n",
    "model2 = RandomForestClassifier(n_estimators=36, criterion = 'entropy', random_state=1)\n",
    "model2.fit(train_X, train_y)\n",
    "preds_val2 = model2.predict(val_X)\n",
    "model_test2 = model2.predict(test_X)\n",
    "description = descriptiontous+\"n_estimators : 36 + Entropy\"\n",
    "metrics2 = listmetrics(val_y, preds_val2, \"Random Forest Classifier\", description)\n",
    "m2Public = [0.690909090]\n",
    "m2Private = [0.649122807]\n",
    "res.append(metrics2)\n",
    "df2 = getscoreforcsv(index_val, model_test2, name_file = \"RandomForestN36Entropy.csv\")\n",
    "\n",
    "model2 = XGBClassifier(scale_pos_weight=22, random_state=1)\n",
    "model2.fit(train_X, train_y)\n",
    "preds_val2 = model2.predict(val_X)\n",
    "model_test2 = model2.predict(test_X)\n",
    "description = descriptiontous+\"scale_pos_weight = 22\"\n",
    "metrics2 = listmetrics(val_y, preds_val2, \"XGBClassifier\", description)\n",
    "m3Public = [0.677419354]\n",
    "m3Private = [0.676923076]\n",
    "res.append(metrics2)\n",
    "df2 = getscoreforcsv(index_val, model_test2, name_file = \"XGBClassifierW22.csv\")\n",
    "\n",
    "#oversamplesimple\n",
    "X_con = pd.concat([train_X, train_y], axis=1) \n",
    "not_fraud = X_con[X_con.FraudResult==0]\n",
    "fraud = X_con[X_con.FraudResult==1]\n",
    "fraud_upsampled = resample(fraud, replace=True, n_samples=len(not_fraud), # match number in majority class\n",
    "                          random_state=1) # reproducible results\n",
    "upsampled = pd.concat([not_fraud, fraud_upsampled])\n",
    "train_y_over_sampled = upsampled.FraudResult\n",
    "train_X_over_sampled = upsampled.drop('FraudResult', axis=1)\n",
    "upsampledmodel = RandomForestClassifier(n_estimators=36, criterion = 'entropy', random_state=1)\n",
    "upsampledmodel.fit(train_X_over_sampled, train_y_over_sampled)\n",
    "upsampled_pred = upsampledmodel.predict(val_X)\n",
    "model_test = upsampledmodel.predict(OH_X_test)\n",
    "description = descriptiontous+\"upsampled, n_estimators=36, criterion = entropy\"\n",
    "metrics = listmetrics(val_y, upsampled_pred, \"RandomForestClassifierUpperSampling\", description)\n",
    "m4Public = [0.678571428]\n",
    "m4Private = [0.637168141]\n",
    "res.append(metrics)\n",
    "df = getscoreforcsv(index_val, model_test, name_file = \"RandomForestClassifierUpSample.csv\")\n",
    "\n",
    "#Undersampling\n",
    "not_fraud_downsampled  = resample(not_fraud, replace=False, n_samples=len(fraud), # match number in minority  class\n",
    "                          random_state=1) # reproducible results\n",
    "downsampled  = pd.concat([not_fraud_downsampled , fraud])\n",
    "train_y_undersampled = downsampled.FraudResult\n",
    "train_X_undersampled = downsampled.drop('FraudResult', axis=1)\n",
    "undersampled = RandomForestClassifier(n_estimators=36, criterion = 'entropy', random_state=1)\n",
    "undersampled.fit(train_X_over_sampled, train_y_over_sampled)\n",
    "undersampled_pred = undersampled.predict(val_X)\n",
    "model_test = undersampled.predict(OH_X_test)\n",
    "description = descriptiontous+\"undersampled, n_estimators=36, criterion = entropy\"\n",
    "metrics = listmetrics(val_y, undersampled_pred, \"RandomForestClassifierUnderSampling\", description)\n",
    "m5Public = [0.549019607]\n",
    "m5Private = [0.480769230]\n",
    "res.append(metrics)\n",
    "df = getscoreforcsv(index_val, model_test, name_file = \"RandomForestClassifierUndersampled.csv\")\n",
    "\n",
    "\n",
    "dfres = listmetricsintodf(res)\n",
    "dfres[\"OldPublicScore\"] = [m1Public, m2Public, m3Public, m4Public, m5Public]\n",
    "dfres[\"OldPrivateScore\"] = [m1Private, m2Private, m3Private, m4Private, m5Private]\n",
    "dfres[\"MeanOurMetrics\"] = dfres[['Precision', 'Recall','F1-score','Mcc']].mean(axis=1)\n",
    "dfres.to_csv('output/resultatsTestEverything.csv', mode='a',index=False,header = False) \n",
    "dfres"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
