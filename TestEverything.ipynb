{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efcbf836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import resample\n",
    "from sklearn.cluster import KMeans \n",
    "import datetime as dt\n",
    "from math import ceil, sqrt\n",
    "from Utils import *\n",
    "pd.set_option('max_colwidth', None)\n",
    "from EvaluationMetric import *\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bae6abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparemodels(train_X, train_y, val_X, test_X, generaldescription, unbalanced = True):\n",
    "    res = []\n",
    "\n",
    "    model1 = DecisionTreeClassifier(max_leaf_nodes= 6, random_state=1)\n",
    "    model1.fit(train_X, train_y)\n",
    "    preds_val1 = model1.predict(val_X)\n",
    "    model_test1 = model1.predict(test_X)\n",
    "    description = generaldescription+\"max_leaf_nodes : 6 + with date columns\"\n",
    "    metrics1 = listmetrics(val_y, preds_val1, \"DecisionTreeClassifier\", description)\n",
    "    m1Public = [0.666666666, 0.666666666, 0.006575486]\n",
    "    m1Private = [0.661016949, 0.661016949, 0.006863327]\n",
    "    res.append(metrics1)\n",
    "    df1 = getscoreforcsv(index_val, model_test1, name_file = \"TreeClass5leaf.csv\")\n",
    "\n",
    "\n",
    "    model2 = RandomForestClassifier(n_estimators=36, criterion = 'entropy', random_state=1)\n",
    "    model2.fit(train_X, train_y)\n",
    "    preds_val2 = model2.predict(val_X)\n",
    "    model_test2 = model2.predict(test_X)\n",
    "    description = generaldescription+\"n_estimators : 36 + Entropy\"\n",
    "    metrics2 = listmetrics(val_y, preds_val2, \"Random Forest Classifier\", description)\n",
    "    m2Public = [0.690909090, 0.666666666, 0.007513148]\n",
    "    m2Private = [0.649122807, 0.649122807, 0.007794933]\n",
    "    res.append(metrics2)\n",
    "    df2 = getscoreforcsv(index_val, model_test2, name_file = \"RandomForestN36Entropy.csv\")\n",
    "\n",
    "\n",
    "    ##################ICi donne un 0.71 de scrore !!! mtn comprendre pq en diminuant les feature si bon score mais que pour lui !############\n",
    "    #Ne fonctionne pas bien quadn le training set est entier. \n",
    "    if (unbalanced) : \n",
    "        model2 = XGBClassifier(scale_pos_weight=22, random_state=1)\n",
    "        description = generaldescription+\"scale_pos_weight = 22\"\n",
    "    else : \n",
    "        model2 = XGBClassifier(random_state=1)\n",
    "        description = generaldescription+\"on balanced data\"\n",
    "    model2.fit(train_X, train_y)\n",
    "    preds_val2 = model2.predict(val_X)\n",
    "    model_test2 = model2.predict(test_X)\n",
    "    metrics2 = listmetrics(val_y, preds_val2, \"XGBClassifier\", description)\n",
    "    m3Public = [0.677419354, 0.711864406, 0.092764378]\n",
    "    m3Private = [0.676923076,  0.715447154, 0.096564531]\n",
    "    res.append(metrics2)\n",
    "    df2 = getscoreforcsv(index_val, model_test2, name_file = \"XGBClassifierW22.csv\")\n",
    "    \n",
    "    if (unbalanced) :\n",
    "        \n",
    "        model2 = RandomForestClassifier(n_estimators=36, criterion = 'entropy', class_weight = {0: 95469, 1 : 193}, random_state=1)\n",
    "        model2.fit(train_X, train_y)\n",
    "        preds_val2 = model2.predict(val_X)\n",
    "        model_test2 = model2.predict(test_X)\n",
    "        description = generaldescription+\"n_estimators : 36 + Entropy\"\n",
    "        metrics2 = listmetrics(val_y, preds_val2, \"Random Forest ClassifierWeighted500\", description)\n",
    "        m500Public = [0.678571428]\n",
    "        m500Private = [0.666666666]\n",
    "        res.append(metrics2)\n",
    "        df2 = getscoreforcsv(index_val, model_test2, name_file = \"RandomForestWeigthed500.csv\")\n",
    "\n",
    "        model2 = RandomForestClassifier(n_estimators=36, criterion = 'entropy', class_weight = {0: 22, 1 : 1}, random_state=1)\n",
    "        model2.fit(train_X, train_y)\n",
    "        preds_val2 = model2.predict(val_X)\n",
    "        model_test2 = model2.predict(test_X)\n",
    "        description = generaldescription+\"n_estimators : 36 + Entropy\"\n",
    "        metrics2 = listmetrics(val_y, preds_val2, \"Random Forest ClassifierWeighted22\", description)\n",
    "        m22Public = [0.703703703]\n",
    "        m22Private = [0.654867256]\n",
    "        res.append(metrics2)\n",
    "        df2 = getscoreforcsv(index_val, model_test2, name_file = \"RandomForestWeigthed22.csv\")\n",
    "\n",
    "        #oversamplesimple\n",
    "        X_con = pd.concat([train_X, train_y], axis=1) \n",
    "        not_fraud = X_con[X_con.FraudResult==0]\n",
    "        fraud = X_con[X_con.FraudResult==1]\n",
    "        fraud_upsampled = resample(fraud, replace=True, n_samples=len(not_fraud), # match number in majority class\n",
    "                                random_state=1) # reproducible results\n",
    "        upsampled = pd.concat([not_fraud, fraud_upsampled])\n",
    "        train_y_over_sampled = upsampled.FraudResult\n",
    "        train_X_over_sampled = upsampled.drop('FraudResult', axis=1)\n",
    "        upsampledmodel = RandomForestClassifier(n_estimators=36, criterion = 'entropy', random_state=1)\n",
    "        upsampledmodel.fit(train_X_over_sampled, train_y_over_sampled)\n",
    "        upsampled_pred = upsampledmodel.predict(val_X)\n",
    "        model_test = upsampledmodel.predict(test_X)\n",
    "        description = generaldescription+\"upsampled, n_estimators=36, criterion = entropy\"\n",
    "        metrics = listmetrics(val_y, upsampled_pred, \"RandomForestClassifierUpperSampling\", description)\n",
    "        m4Public = [0.678571428, 0.642857142]\n",
    "        m4Private = [0.637168141, 0.620689655]\n",
    "        res.append(metrics)\n",
    "        df = getscoreforcsv(index_val, model_test, name_file = \"RandomForestClassifierUpSample.csv\")\n",
    "\n",
    "        #Undersampling\n",
    "        not_fraud_downsampled  = resample(not_fraud, replace=False, n_samples=len(fraud), # match number in minority  class\n",
    "                                random_state=1) # reproducible results\n",
    "        downsampled  = pd.concat([not_fraud_downsampled , fraud])\n",
    "        train_y_undersampled = downsampled.FraudResult\n",
    "        train_X_undersampled = downsampled.drop('FraudResult', axis=1)\n",
    "        undersampled = RandomForestClassifier(n_estimators=36, criterion = 'entropy', random_state=1)\n",
    "        undersampled.fit(train_X_over_sampled, train_y_over_sampled)\n",
    "        undersampled_pred = undersampled.predict(val_X)\n",
    "        model_test = undersampled.predict(test_X)\n",
    "        description = generaldescription+\"undersampled, n_estimators=36, criterion = entropy\"\n",
    "        metrics = listmetrics(val_y, undersampled_pred, \"RandomForestClassifierUnderSampling\", description)\n",
    "        m5Public = [0.549019607, 0.642857142]\n",
    "        m5Private = [0.480769230, 0.620689655]\n",
    "        res.append(metrics)\n",
    "        df = getscoreforcsv(index_val, model_test, name_file = \"RandomForestClassifierUndersampled.csv\")\n",
    "        \n",
    "        loldPublics = [m1Public, m2Public, m3Public, m500Public,m22Public, m4Public, m5Public]\n",
    "        loldPrivate = [m1Private, m2Private, m3Private, m500Private, m22Private, m4Private, m5Private]\n",
    "        \n",
    "    else:\n",
    "        loldPublics = [m1Public, m2Public, m3Public]\n",
    "        loldPrivate = [m1Private, m2Private,  m3Private]\n",
    "        \n",
    "\n",
    "\n",
    "    dfres = listmetricsintodf(res)\n",
    "    dfres[\"OldPublicScore\"] = loldPublics\n",
    "    dfres[\"OldPrivateScore\"] = loldPrivate\n",
    "    dfres[\"MeanOurMetrics\"] = dfres[['Precision', 'Recall','F1-score','Mcc']].mean(axis=1)\n",
    "    dfres.to_csv('output/resultatsTestEverything.csv', mode='a',index=False,header = False) \n",
    "    return dfres"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5eab429b",
   "metadata": {},
   "source": [
    "# Test de different model with different Data Here\n",
    "## 1. The reference model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73a9d70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "def_feature = pd.read_csv(\"input/Xente_Variable_Definitions.csv\")\n",
    "raw_data = pd.read_csv(\"input/training.csv\")\n",
    "X_test = pd.read_csv(\"input/test.csv\")\n",
    "sample_submission = pd.read_csv(\"input/sample_submission.csv\")\n",
    "\n",
    "#attribut initialization\n",
    "cols_unique_value = [] #Will be droped\n",
    "for col in raw_data.columns : \n",
    "    if len(raw_data[col].unique()) == 1 :\n",
    "        cols_unique_value.append(col)\n",
    "\n",
    "medium_cardianlity_cols = [\"ProductId\"]\n",
    "\n",
    "#Data transformation\n",
    "raw_data['TransactionStartTime'] = pd.to_datetime(raw_data['TransactionStartTime'])\n",
    "X_test['TransactionStartTime'] = pd.to_datetime(X_test['TransactionStartTime'])\n",
    "\n",
    "#Data cleaning\n",
    "data = raw_data.copy()\n",
    "data = data.dropna(axis=0) #Drop observations/rows with missing values\n",
    "X_test=X_test.dropna(axis=0)\n",
    "data.drop(cols_unique_value, axis=1, inplace=True)\n",
    "X_test.drop(cols_unique_value, axis=1, inplace=True)\n",
    "\n",
    "#Prepare index for the submission\n",
    "index_val = list(X_test.TransactionId.values.tolist())\n",
    "\n",
    "#Set the df index to the Transction Id\n",
    "data = transactioId_to_index(data)\n",
    "X_test = transactioId_to_index(X_test)\n",
    "\n",
    "#Adding data\n",
    "data = adding_date_col(data, 'TransactionStartTime')\n",
    "X_test = adding_date_col(X_test, 'TransactionStartTime')\n",
    "\n",
    "\n",
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "low_cardinality_cols = [cname for cname in data.columns if data[cname].nunique() < 15 and \n",
    "                        data[cname].dtype == \"object\"]\n",
    "low_cardinality_cols.append('PricingStrategy')\n",
    "\n",
    "#transform columns BatchId_54 to number\n",
    "    #transform columns BatchId_54 to number\n",
    "id_cols = data.filter(like=\"Id\").columns.tolist()\n",
    "data[id_cols] = data[id_cols].astype(str).apply(lambda x: x.str.replace(x.name + \"_\", \"\")).astype(int)\n",
    "X_test[id_cols] = X_test[id_cols].astype(str).apply(lambda x: x.str.replace(x.name + \"_\", \"\")).astype(int)\n",
    "\n",
    "data['PricingStrategy'] = data['PricingStrategy'].astype('int')\n",
    "X_test['PricingStrategy'] = X_test['PricingStrategy'].astype('int')\n",
    "data['Value'] = data['Value'].astype('float')\n",
    "X_test['Value'] = X_test['Value'].astype('float')\n",
    "\n",
    "X_test['PricingStrategy'] = X_test['PricingStrategy'].astype('str')\n",
    "data['PricingStrategy'] = data['PricingStrategy'].astype('str')\n",
    "\n",
    "#Data splitting\n",
    "y = data.FraudResult #The target label\n",
    "X = data.copy()\n",
    "X.drop(['FraudResult'], axis=1, inplace=True) #Only the features data\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "cat_cols = [col for col in X.columns if X[col].dtype == \"object\"]#liste of obejct columns\n",
    "cat_cols.append(\"PricingStrategy\")#pcq mm si c'est un chiffre il faut le considérer comme une catégorie\n",
    "\n",
    "\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(train_X[low_cardinality_cols]))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(val_X[low_cardinality_cols]))\n",
    "OH_cols_test = pd.DataFrame(OH_encoder.transform(X_test[low_cardinality_cols]))\n",
    "OH_cols_train.columns = OH_encoder.get_feature_names_out()\n",
    "OH_cols_valid.columns = OH_encoder.get_feature_names_out()\n",
    "OH_cols_test.columns = OH_encoder.get_feature_names_out()\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_train.index = train_X.index\n",
    "OH_cols_valid.index = val_X.index\n",
    "OH_cols_test.index = X_test.index\n",
    "\n",
    "OH_cols_train[list(OH_cols_train.columns)] = OH_cols_train[list(OH_cols_train.columns)].astype(int)\n",
    "OH_cols_valid[list(OH_cols_valid.columns)] = OH_cols_valid[list(OH_cols_valid.columns)].astype(int)\n",
    "OH_cols_test[list(OH_cols_test.columns)] = OH_cols_test[list(OH_cols_test.columns)].astype(int)\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train = train_X.drop(low_cardinality_cols, axis=1)\n",
    "num_X_valid = val_X.drop(low_cardinality_cols, axis=1)\n",
    "num_X_test = X_test.drop(low_cardinality_cols, axis=1)\n",
    "\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
    "OH_X_test = pd.concat([num_X_test, OH_cols_test], axis=1)\n",
    "\n",
    "# Problème de string\n",
    "OH_X_train.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_valid.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_test.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_train.columns = OH_X_train.columns.astype(str)\n",
    "OH_X_valid.columns = OH_X_valid.columns.astype(str)\n",
    "OH_X_test.columns = OH_X_test.columns.astype(str)\n",
    "\n",
    "train_X = OH_X_train\n",
    "val_X = OH_X_valid\n",
    "test_X = OH_X_test\n",
    "X_entier = pd.concat([train_X, val_X])\n",
    "\n",
    "referenceresult = comparemodels(train_X, train_y, val_X, test_X, \"The reference\")\n",
    "referenceresult[\"PublicScore\"] = [0.666666666, 0.690909090, 0.677419354, 0.678571428, 0.703703703, 0.678571428, 0.549019607]\n",
    "referenceresult[\"PrivateScore\"] = [0.661016949, 0.649122807,  0.676923076,0.666666666, 0.654867256, 0.637168141, 0.480769230]\n",
    "referenceresult"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd22a8e6",
   "metadata": {},
   "source": [
    "# Niko Test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "84994fe9",
   "metadata": {},
   "source": [
    "# Small preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb17ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"input/training.csv\")\n",
    "data = df.copy()\n",
    "y_train = df[\"FraudResult\"]\n",
    "X_test = pd.read_csv(\"input/test.csv\")\n",
    "X_valid = X_test.copy()\n",
    "sample_submission = pd.read_csv(\"input/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b295ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping column with one unique values:  ['CurrencyCode', 'CountryCode']\n",
      "Converting columns with Id:  ['TransactionId', 'BatchId', 'AccountId', 'SubscriptionId', 'CustomerId', 'ProviderId', 'ProductId', 'ChannelId']\n"
     ]
    }
   ],
   "source": [
    "# Count the number of unique entries in each column\n",
    "unique_counts = data.nunique()\n",
    "\n",
    "# Select only columns with more than one unique entry\n",
    "drop_cols = unique_counts[unique_counts == 1].index.tolist()\n",
    "print(\"Dropping column with one unique values: \", drop_cols)\n",
    "\n",
    "# Drop the selected columns\n",
    "data = data.drop(columns=drop_cols)\n",
    "X_test = X_test.drop(columns=drop_cols)\n",
    "\n",
    "# Get a list of column names that contain the string \"id\" in their name\n",
    "id_cols = data.filter(like=\"Id\").columns.tolist()\n",
    "\n",
    "# Print the list of column names\n",
    "print(\"Converting columns with Id: \", id_cols)\n",
    "\n",
    "# Remove column name prefix and convert to integer data type\n",
    "data[id_cols] = (\n",
    "    data[id_cols]\n",
    "    .astype(str)\n",
    "    .apply(lambda x: x.str.replace(x.name + \"_\", \"\"))\n",
    "    .astype(int)\n",
    ")\n",
    "X_test[id_cols] = (\n",
    "    X_test[id_cols]\n",
    "    .astype(str)\n",
    "    .apply(lambda x: x.str.replace(x.name + \"_\", \"\"))\n",
    "    .astype(int)\n",
    ")\n",
    "\n",
    "# convert TransactionStartTime column to datetime format\n",
    "data[\"TransactionStartTime\"] = pd.to_datetime(\n",
    "    df[\"TransactionStartTime\"], format=\"%Y-%m-%dT%H:%M:%SZ\"\n",
    ")\n",
    "X_test[\"TransactionStartTime\"] = pd.to_datetime(\n",
    "    X_test[\"TransactionStartTime\"], format=\"%Y-%m-%dT%H:%M:%SZ\"\n",
    ")\n",
    "\n",
    "# extract date and time features\n",
    "data[\"TransactionDayOfWeek\"] = data[\"TransactionStartTime\"].dt.dayofweek\n",
    "data[\"TransactionDayOfMonth\"] = data[\"TransactionStartTime\"].dt.day\n",
    "data[\"TransactionHour\"] = data[\"TransactionStartTime\"].dt.hour\n",
    "data[\"TransactionMinute\"] = data[\"TransactionStartTime\"].dt.minute\n",
    "\n",
    "X_test[\"TransactionDayOfWeek\"] = X_test[\"TransactionStartTime\"].dt.dayofweek\n",
    "X_test[\"TransactionDayOfMonth\"] = X_test[\"TransactionStartTime\"].dt.day\n",
    "X_test[\"TransactionHour\"] = X_test[\"TransactionStartTime\"].dt.hour\n",
    "X_test[\"TransactionMinute\"] = X_test[\"TransactionStartTime\"].dt.minute\n",
    "\n",
    "# drop TransactionStartTime\n",
    "data = data.drop(\"TransactionStartTime\", axis=1)\n",
    "X_test = X_test.drop(\"TransactionStartTime\", axis=1)\n",
    "\n",
    "# Factorize the \"ProductCategory\" column\n",
    "data['ProductCategory'] = pd.factorize(data['ProductCategory'])[0] + 1\n",
    "X_test['ProductCategory'] = pd.factorize(X_test['ProductCategory'])[0] + 1\n",
    "# Convert the \"ProductCategory\" column to integer data type\n",
    "data['ProductCategory'] = data['ProductCategory'].astype(int)\n",
    "X_test['ProductCategory'] = X_test['ProductCategory'].astype(int)\n",
    "\n",
    "# Removing redundant data\n",
    "data[\"Expense\"] = data[\"Amount\"] < 0\n",
    "data.Expense = data.Expense.astype(int)\n",
    "data = data.drop(\"Amount\", axis=1)\n",
    "\n",
    "X_test[\"Expense\"] = X_test[\"Amount\"] < 0\n",
    "X_test.Expense = X_test.Expense.astype(int)\n",
    "X_test = X_test.drop(\"Amount\", axis=1)\n",
    "\n",
    "# Continous value should be float\n",
    "data[\"Value\"] = data[\"Value\"].astype(float)\n",
    "X_test[\"Value\"] = X_test[\"Value\"].astype(float)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a5113b99",
   "metadata": {},
   "source": [
    "# Scenario 1: With All columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f35e9b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- Amount\n- ChannelId_1\n- ChannelId_2\n- ChannelId_3\n- ChannelId_5\n- ...\nFeature names seen at fit time, yet now missing:\n- ChannelId\n- Expense\n- PricingStrategy\n- ProductCategory\n- ProviderId\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39m# mi_score = make_mi_scores(data, y_train)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m train_X, val_X, train_y, val_y \u001b[39m=\u001b[39m train_test_split(X_1, y_train, random_state \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m referenceresult \u001b[39m=\u001b[39m comparemodels(train_X, train_y, val_X, X_test, \u001b[39m\"\u001b[39;49m\u001b[39mThe reference\u001b[39;49m\u001b[39m\"\u001b[39;49m, unbalanced\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      6\u001b[0m referenceresult\n",
      "Cell \u001b[1;32mIn[2], line 81\u001b[0m, in \u001b[0;36mcomparemodels\u001b[1;34m(train_X, train_y, val_X, test_X, generaldescription, unbalanced)\u001b[0m\n\u001b[0;32m     79\u001b[0m upsampledmodel\u001b[39m.\u001b[39mfit(train_X_over_sampled, train_y_over_sampled)\n\u001b[0;32m     80\u001b[0m upsampled_pred \u001b[39m=\u001b[39m upsampledmodel\u001b[39m.\u001b[39mpredict(val_X)\n\u001b[1;32m---> 81\u001b[0m model_test \u001b[39m=\u001b[39m upsampledmodel\u001b[39m.\u001b[39;49mpredict(OH_X_test)\n\u001b[0;32m     82\u001b[0m description \u001b[39m=\u001b[39m generaldescription\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mupsampled, n_estimators=36, criterion = entropy\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     83\u001b[0m metrics \u001b[39m=\u001b[39m listmetrics(val_y, upsampled_pred, \u001b[39m\"\u001b[39m\u001b[39mRandomForestClassifierUpperSampling\u001b[39m\u001b[39m\"\u001b[39m, description)\n",
      "File \u001b[1;32mc:\\Users\\sarah\\anaconda3\\envs\\AILab-ECAM4\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:820\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    799\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    800\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    801\u001b[0m \u001b[39m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[39m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    819\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 820\u001b[0m     proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_proba(X)\n\u001b[0;32m    822\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    823\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mtake(np\u001b[39m.\u001b[39margmax(proba, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\sarah\\anaconda3\\envs\\AILab-ECAM4\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:862\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    860\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m    861\u001b[0m \u001b[39m# Check data\u001b[39;00m\n\u001b[1;32m--> 862\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_X_predict(X)\n\u001b[0;32m    864\u001b[0m \u001b[39m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    865\u001b[0m n_jobs, _, _ \u001b[39m=\u001b[39m _partition_estimators(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_estimators, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32mc:\\Users\\sarah\\anaconda3\\envs\\AILab-ECAM4\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:602\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    599\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    600\u001b[0m \u001b[39mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[0;32m    601\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 602\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, dtype\u001b[39m=\u001b[39;49mDTYPE, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    603\u001b[0m \u001b[39mif\u001b[39;00m issparse(X) \u001b[39mand\u001b[39;00m (X\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc \u001b[39mor\u001b[39;00m X\u001b[39m.\u001b[39mindptr\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc):\n\u001b[0;32m    604\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\sarah\\anaconda3\\envs\\AILab-ECAM4\\lib\\site-packages\\sklearn\\base.py:548\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_data\u001b[39m(\n\u001b[0;32m    484\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    485\u001b[0m     X\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mno_validation\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params,\n\u001b[0;32m    490\u001b[0m ):\n\u001b[0;32m    491\u001b[0m     \u001b[39m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    492\u001b[0m \n\u001b[0;32m    493\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    546\u001b[0m \u001b[39m        validated.\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 548\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_feature_names(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[0;32m    550\u001b[0m     \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_tags()[\u001b[39m\"\u001b[39m\u001b[39mrequires_y\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    551\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    552\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThis \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m estimator \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    553\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mrequires y to be passed, but the target y is None.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    554\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\sarah\\anaconda3\\envs\\AILab-ECAM4\\lib\\site-packages\\sklearn\\base.py:481\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m missing_names \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m    477\u001b[0m     message \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[0;32m    478\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    479\u001b[0m     )\n\u001b[1;32m--> 481\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- Amount\n- ChannelId_1\n- ChannelId_2\n- ChannelId_3\n- ChannelId_5\n- ...\nFeature names seen at fit time, yet now missing:\n- ChannelId\n- Expense\n- PricingStrategy\n- ProductCategory\n- ProviderId\n- ...\n"
     ]
    }
   ],
   "source": [
    "# Evaluate data (drop FraudResult before)\n",
    "X_1 = data.drop(\"FraudResult\", axis=1)\n",
    "# mi_score = make_mi_scores(data, y_train)\n",
    "train_X, val_X, train_y, val_y = train_test_split(X_1, y_train, random_state = 0)\n",
    "referenceresult = comparemodels(train_X, train_y, val_X, X_test, \"With All Columns\", unbalanced=True)\n",
    "referenceresult"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d808c490",
   "metadata": {},
   "source": [
    "# Scenario 2: Dropping Unique ID columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a7bf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropping_cols = [\"TransactionId\", \"BatchId\", \"AccountId\", \"CustomerId\", \"SubscriptionId\"]\n",
    "\n",
    "for col in dropping_cols:\n",
    "    data = data.drop(col, axis=1)\n",
    "    X_test = X_test.drop(col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17906ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>The referencemax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 16:25:52.781051</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.871873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666, 0.666666666]</td>\n",
       "      <td>[0.661016949, 0.661016949]</td>\n",
       "      <td>0.872101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>The referencen_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:25:53.642787</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.839506</td>\n",
       "      <td>0.019592</td>\n",
       "      <td>0.839298</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909, 0.666666666]</td>\n",
       "      <td>[0.649122807, 0.649122807]</td>\n",
       "      <td>0.839518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>The referencescale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 16:25:54.347030</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.012057</td>\n",
       "      <td>0.899832</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354, 0.711864406]</td>\n",
       "      <td>[0.676923076, 0.715447154]</td>\n",
       "      <td>0.899958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model   \n",
       "0    DecisionTreeClassifier  \\\n",
       "1  Random Forest Classifier   \n",
       "2             XGBClassifier   \n",
       "\n",
       "                                           Description   \n",
       "0  The referencemax_leaf_nodes : 6 + with date columns  \\\n",
       "1             The referencen_estimators : 36 + Entropy   \n",
       "2                   The referencescale_pos_weight = 22   \n",
       "\n",
       "                        Date  Precision  Recall  F1-score   LogLoss       Mcc   \n",
       "0 2023-05-07 16:25:52.781051   0.894737    0.85  0.871795  0.015071  0.871873  \\\n",
       "1 2023-05-07 16:25:53.642787   0.829268    0.85  0.839506  0.019592  0.839298   \n",
       "2 2023-05-07 16:25:54.347030   0.900000    0.90  0.900000  0.012057  0.899832   \n",
       "\n",
       "   PublicScore  PrivateScore              OldPublicScore   \n",
       "0          NaN           NaN  [0.666666666, 0.666666666]  \\\n",
       "1          NaN           NaN   [0.69090909, 0.666666666]   \n",
       "2          NaN           NaN  [0.677419354, 0.711864406]   \n",
       "\n",
       "              OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949]        0.872101  \n",
       "1  [0.649122807, 0.649122807]        0.839518  \n",
       "2  [0.676923076, 0.715447154]        0.899958  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate data (drop FraudResult before)\n",
    "X_2 = data.drop(\"FraudResult\", axis=1)\n",
    "# mi_score = make_mi_scores(data, y_train)\n",
    "train_X, val_X, train_y, val_y = train_test_split(X_2, y_train, random_state = 0)\n",
    "referenceresult = comparemodels(train_X, train_y, val_X, X_test, \"The reference\", unbalanced=False)\n",
    "referenceresult"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "309e715a",
   "metadata": {},
   "source": [
    "# Scenario 3: Adding new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a214b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_col = [\"ProviderId\", \"ProductCategory\", \"ChannelId\", \"PricingStrategy\"]\n",
    "mean_std_col = ['ProductId', 'Expense', \"ProviderId\", \"ProductCategory\", \"ChannelId\", \"PricingStrategy\"]\n",
    "\n",
    "# Compute mean and standard deviation for specific features\n",
    "for feature in mean_std_col:\n",
    "    # Compute the mean and standard deviation of transactions for each feature\n",
    "    feature_avg_values = data.groupby(feature)['Value'].mean()\n",
    "    feature_std_values = data.groupby(feature)['Value'].std()\n",
    "    data[f\"{feature}_mean_amount\"] = data[feature].apply(lambda x: feature_avg_values[x])\n",
    "    data[f\"{feature}_std_amount\"] = data[feature].apply(lambda x: feature_std_values[x])\n",
    "    \n",
    "for feature in mean_std_col:\n",
    "    # Compute the mean and standard deviation of transactions for each feature\n",
    "    feature_avg_values = X_test.groupby(feature)['Value'].mean()\n",
    "    feature_std_values = X_test.groupby(feature)['Value'].std()\n",
    "    X_test[f\"{feature}_mean_amount\"] = X_test[feature].apply(lambda x: feature_avg_values[x])\n",
    "    X_test[f\"{feature}_std_amount\"] = X_test[feature].apply(lambda x: feature_std_values[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbaa3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the rows that contain missing values\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402f8b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHot Encode categorical features\n",
    "data = pd.get_dummies(data, columns=categorical_col)\n",
    "# Adding missing col\n",
    "data[\"ChannelId_4\"] = False\n",
    "data[\"PricingStrategy_3\"] = False\n",
    "X_test = pd.get_dummies(X_test, columns=categorical_col)\n",
    "# Adding missing col\n",
    "X_test[\"PricingStrategy_3\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d42f1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the boolean columns to integer columns\n",
    "bool_cols = data.select_dtypes(include=bool).columns.tolist()\n",
    "data[bool_cols] = data[bool_cols].astype(int)\n",
    "\n",
    "bool_cols = X_test.select_dtypes(include=bool).columns.tolist()\n",
    "X_test[bool_cols] = X_test[bool_cols].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661ded45",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = data.FraudResult\n",
    "data.drop(\"FraudResult\", inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fd8eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_score = make_mi_scores(data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c37814f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_mi_scores(mi_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de337b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>The referencemax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 16:26:18.106178</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.848426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666, 0.666666666]</td>\n",
       "      <td>[0.661016949, 0.661016949]</td>\n",
       "      <td>0.849240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>The referencen_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:26:19.035689</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.784810</td>\n",
       "      <td>0.025621</td>\n",
       "      <td>0.786037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909, 0.666666666]</td>\n",
       "      <td>[0.649122807, 0.649122807]</td>\n",
       "      <td>0.786695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>The referencescale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 16:26:20.300900</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.853662</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354, 0.711864406]</td>\n",
       "      <td>[0.676923076, 0.715447154]</td>\n",
       "      <td>0.853914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model   \n",
       "0    DecisionTreeClassifier  \\\n",
       "1  Random Forest Classifier   \n",
       "2             XGBClassifier   \n",
       "\n",
       "                                           Description   \n",
       "0  The referencemax_leaf_nodes : 6 + with date columns  \\\n",
       "1             The referencen_estimators : 36 + Entropy   \n",
       "2                   The referencescale_pos_weight = 22   \n",
       "\n",
       "                        Date  Precision    Recall  F1-score   LogLoss   \n",
       "0 2023-05-07 16:26:18.106178   0.916667  0.785714  0.846154  0.018085  \\\n",
       "1 2023-05-07 16:26:19.035689   0.837838  0.738095  0.784810  0.025621   \n",
       "2 2023-05-07 16:26:20.300900   0.875000  0.833333  0.853659  0.018085   \n",
       "\n",
       "        Mcc  PublicScore  PrivateScore              OldPublicScore   \n",
       "0  0.848426          NaN           NaN  [0.666666666, 0.666666666]  \\\n",
       "1  0.786037          NaN           NaN   [0.69090909, 0.666666666]   \n",
       "2  0.853662          NaN           NaN  [0.677419354, 0.711864406]   \n",
       "\n",
       "              OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949]        0.849240  \n",
       "1  [0.649122807, 0.649122807]        0.786695  \n",
       "2  [0.676923076, 0.715447154]        0.853914  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reorder the columns in alphabetical order\n",
    "data = data.sort_index(axis=1)\n",
    "X_test = X_test.sort_index(axis=1)\n",
    "\n",
    "# Evaluate data\n",
    "X_3 = data.copy()\n",
    "X_test_3 = X_test.copy()\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(X_3, y_train, random_state = 0)\n",
    "referenceresult = comparemodels(train_X, train_y, val_X, X_test_3, \"The reference\", unbalanced=False)\n",
    "referenceresult"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ade3d808",
   "metadata": {},
   "source": [
    "# Removing Low MI columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22cbe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_scores = make_mi_scores(X_3 , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2fe0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mediumMI = list(mi_scores[mi_scores<0.01].index)\n",
    "X_3.drop(mediumMI, inplace=True, axis=1, errors='ignore')\n",
    "X_test_3.drop(mediumMI, inplace=True, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d996dc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>The referencemax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 16:26:39.661577</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>0.859335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666, 0.666666666]</td>\n",
       "      <td>[0.661016949, 0.661016949]</td>\n",
       "      <td>0.861068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>The referencen_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:26:40.288866</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.845369</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909, 0.666666666]</td>\n",
       "      <td>[0.649122807, 0.649122807]</td>\n",
       "      <td>0.847513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>The referencescale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 16:26:40.972163</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.868421</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.873080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354, 0.711864406]</td>\n",
       "      <td>[0.676923076, 0.715447154]</td>\n",
       "      <td>0.874451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model   \n",
       "0    DecisionTreeClassifier  \\\n",
       "1  Random Forest Classifier   \n",
       "2             XGBClassifier   \n",
       "\n",
       "                                           Description   \n",
       "0  The referencemax_leaf_nodes : 6 + with date columns  \\\n",
       "1             The referencen_estimators : 36 + Entropy   \n",
       "2                   The referencescale_pos_weight = 22   \n",
       "\n",
       "                        Date  Precision    Recall  F1-score   LogLoss   \n",
       "0 2023-05-07 16:26:39.661577   0.969697  0.761905  0.853333  0.016578  \\\n",
       "1 2023-05-07 16:26:40.288866   0.968750  0.738095  0.837838  0.018085   \n",
       "2 2023-05-07 16:26:40.972163   0.970588  0.785714  0.868421  0.015071   \n",
       "\n",
       "        Mcc  PublicScore  PrivateScore              OldPublicScore   \n",
       "0  0.859335          NaN           NaN  [0.666666666, 0.666666666]  \\\n",
       "1  0.845369          NaN           NaN   [0.69090909, 0.666666666]   \n",
       "2  0.873080          NaN           NaN  [0.677419354, 0.711864406]   \n",
       "\n",
       "              OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949]        0.861068  \n",
       "1  [0.649122807, 0.649122807]        0.847513  \n",
       "2  [0.676923076, 0.715447154]        0.874451  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_X, val_X, train_y, val_y = train_test_split(X_3, y_train, random_state = 0)\n",
    "referenceresult = comparemodels(train_X, train_y, val_X, X_test_3, \"The reference\", unbalanced=False)\n",
    "referenceresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d110a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_4 = data.copy()\n",
    "X_test_4 = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d64cade",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowMI = list(mi_scores[mi_scores<0.001].index)\n",
    "X_4.drop(lowMI, inplace=True, axis=1)\n",
    "X_test_4.drop(lowMI, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf97fb8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>The referencemax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 16:29:30.025835</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>0.860489</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666, 0.666666666]</td>\n",
       "      <td>[0.661016949, 0.661016949]</td>\n",
       "      <td>0.861551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>The referencen_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:29:30.900209</td>\n",
       "      <td>0.868421</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.021099</td>\n",
       "      <td>0.825744</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909, 0.666666666]</td>\n",
       "      <td>[0.649122807, 0.649122807]</td>\n",
       "      <td>0.826220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>The referencescale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 16:29:31.901891</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.853662</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354, 0.711864406]</td>\n",
       "      <td>[0.676923076, 0.715447154]</td>\n",
       "      <td>0.853914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model   \n",
       "0    DecisionTreeClassifier  \\\n",
       "1  Random Forest Classifier   \n",
       "2             XGBClassifier   \n",
       "\n",
       "                                           Description   \n",
       "0  The referencemax_leaf_nodes : 6 + with date columns  \\\n",
       "1             The referencen_estimators : 36 + Entropy   \n",
       "2                   The referencescale_pos_weight = 22   \n",
       "\n",
       "                        Date  Precision    Recall  F1-score   LogLoss   \n",
       "0 2023-05-07 16:29:30.025835   0.942857  0.785714  0.857143  0.016578  \\\n",
       "1 2023-05-07 16:29:30.900209   0.868421  0.785714  0.825000  0.021099   \n",
       "2 2023-05-07 16:29:31.901891   0.875000  0.833333  0.853659  0.018085   \n",
       "\n",
       "        Mcc  PublicScore  PrivateScore              OldPublicScore   \n",
       "0  0.860489          NaN           NaN  [0.666666666, 0.666666666]  \\\n",
       "1  0.825744          NaN           NaN   [0.69090909, 0.666666666]   \n",
       "2  0.853662          NaN           NaN  [0.677419354, 0.711864406]   \n",
       "\n",
       "              OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949]        0.861551  \n",
       "1  [0.649122807, 0.649122807]        0.826220  \n",
       "2  [0.676923076, 0.715447154]        0.853914  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_X, val_X, train_y, val_y = train_test_split(X_4, y_train, random_state = 0)\n",
    "referenceresult = comparemodels(train_X, train_y, val_X, X_test_4, \"The reference\", unbalanced=False)\n",
    "referenceresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d43a667",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_5 = data.copy()\n",
    "X_test_5 = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb133429",
   "metadata": {},
   "outputs": [],
   "source": [
    "veryLowMI = list(mi_scores[mi_scores<0.0001].index)\n",
    "X_5.drop(veryLowMI, inplace=True, axis=1)\n",
    "X_test_5.drop(veryLowMI, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5871d9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>The referencemax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 16:36:03.274382</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.848426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666, 0.666666666]</td>\n",
       "      <td>[0.661016949, 0.661016949]</td>\n",
       "      <td>0.849240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>The referencen_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:36:04.176467</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.027128</td>\n",
       "      <td>0.780344</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909, 0.666666666]</td>\n",
       "      <td>[0.649122807, 0.649122807]</td>\n",
       "      <td>0.780684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>The referencescale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 16:36:05.332078</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.853662</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354, 0.711864406]</td>\n",
       "      <td>[0.676923076, 0.715447154]</td>\n",
       "      <td>0.853914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model   \n",
       "0    DecisionTreeClassifier  \\\n",
       "1  Random Forest Classifier   \n",
       "2             XGBClassifier   \n",
       "\n",
       "                                           Description   \n",
       "0  The referencemax_leaf_nodes : 6 + with date columns  \\\n",
       "1             The referencen_estimators : 36 + Entropy   \n",
       "2                   The referencescale_pos_weight = 22   \n",
       "\n",
       "                        Date  Precision    Recall  F1-score   LogLoss   \n",
       "0 2023-05-07 16:36:03.274382   0.916667  0.785714  0.846154  0.018085  \\\n",
       "1 2023-05-07 16:36:04.176467   0.800000  0.761905  0.780488  0.027128   \n",
       "2 2023-05-07 16:36:05.332078   0.875000  0.833333  0.853659  0.018085   \n",
       "\n",
       "        Mcc  PublicScore  PrivateScore              OldPublicScore   \n",
       "0  0.848426          NaN           NaN  [0.666666666, 0.666666666]  \\\n",
       "1  0.780344          NaN           NaN   [0.69090909, 0.666666666]   \n",
       "2  0.853662          NaN           NaN  [0.677419354, 0.711864406]   \n",
       "\n",
       "              OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949]        0.849240  \n",
       "1  [0.649122807, 0.649122807]        0.780684  \n",
       "2  [0.676923076, 0.715447154]        0.853914  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_X, val_X, train_y, val_y = train_test_split(X_5, y_train, random_state = 0)\n",
    "referenceresult = comparemodels(train_X, train_y, val_X, X_test_5, \"The reference\", unbalanced=False)\n",
    "referenceresult"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e76c528f",
   "metadata": {},
   "source": [
    "## 2. Play with deleting the low MI columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93200f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supprimer les MI trop faible\n",
    "def_feature = pd.read_csv(\"input/Xente_Variable_Definitions.csv\")\n",
    "raw_data = pd.read_csv(\"input/training.csv\")\n",
    "X_test = pd.read_csv(\"input/test.csv\")\n",
    "sample_submission = pd.read_csv(\"input/sample_submission.csv\")\n",
    "\n",
    "#attribut initialization\n",
    "cols_unique_value = [] #Will be droped\n",
    "for col in raw_data.columns : \n",
    "    if len(raw_data[col].unique()) == 1 :\n",
    "        cols_unique_value.append(col)\n",
    "\n",
    "medium_cardianlity_cols = [\"ProductId\"]\n",
    "\n",
    "#Data transformation\n",
    "raw_data['TransactionStartTime'] = pd.to_datetime(raw_data['TransactionStartTime'])\n",
    "X_test['TransactionStartTime'] = pd.to_datetime(X_test['TransactionStartTime'])\n",
    "\n",
    "#Data cleaning\n",
    "data = raw_data.copy()\n",
    "data = data.dropna(axis=0) #Drop observations/rows with missing values\n",
    "X_test=X_test.dropna(axis=0)\n",
    "data.drop(cols_unique_value, axis=1, inplace=True)\n",
    "X_test.drop(cols_unique_value, axis=1, inplace=True)\n",
    "\n",
    "#Prepare index for the submission\n",
    "index_val = list(X_test.TransactionId.values.tolist())\n",
    "\n",
    "#Set the df index to the Transction Id\n",
    "data = transactioId_to_index(data)\n",
    "X_test = transactioId_to_index(X_test)\n",
    "\n",
    "#Adding data\n",
    "data = adding_date_col(data, 'TransactionStartTime')\n",
    "X_test = adding_date_col(X_test, 'TransactionStartTime')\n",
    "\n",
    "\n",
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "low_cardinality_cols = [cname for cname in data.columns if data[cname].nunique() < 15 and \n",
    "                        data[cname].dtype == \"object\"]\n",
    "low_cardinality_cols.append('PricingStrategy')\n",
    "\n",
    "#transform columns BatchId_54 to number\n",
    "    #transform columns BatchId_54 to number\n",
    "id_cols = data.filter(like=\"Id\").columns.tolist()\n",
    "data[id_cols] = data[id_cols].astype(str).apply(lambda x: x.str.replace(x.name + \"_\", \"\")).astype(int)\n",
    "X_test[id_cols] = X_test[id_cols].astype(str).apply(lambda x: x.str.replace(x.name + \"_\", \"\")).astype(int)\n",
    "\n",
    "data['PricingStrategy'] = data['PricingStrategy'].astype('int')\n",
    "X_test['PricingStrategy'] = X_test['PricingStrategy'].astype('int')\n",
    "data['Value'] = data['Value'].astype('float')\n",
    "X_test['Value'] = X_test['Value'].astype('float')\n",
    "\n",
    "X_test['PricingStrategy'] = X_test['PricingStrategy'].astype('str')\n",
    "data['PricingStrategy'] = data['PricingStrategy'].astype('str')\n",
    "\n",
    "#Data splitting\n",
    "y = data.FraudResult #The target label\n",
    "X = data.copy()\n",
    "X.drop(['FraudResult'], axis=1, inplace=True) #Only the features data\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "cat_cols = [col for col in X.columns if X[col].dtype == \"object\"]#liste of obejct columns\n",
    "cat_cols.append(\"PricingStrategy\")#pcq mm si c'est un chiffre il faut le considérer comme une catégorie\n",
    "\n",
    "\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(train_X[low_cardinality_cols]))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(val_X[low_cardinality_cols]))\n",
    "OH_cols_test = pd.DataFrame(OH_encoder.transform(X_test[low_cardinality_cols]))\n",
    "OH_cols_train.columns = OH_encoder.get_feature_names_out()\n",
    "OH_cols_valid.columns = OH_encoder.get_feature_names_out()\n",
    "OH_cols_test.columns = OH_encoder.get_feature_names_out()\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_train.index = train_X.index\n",
    "OH_cols_valid.index = val_X.index\n",
    "OH_cols_test.index = X_test.index\n",
    "\n",
    "OH_cols_train[list(OH_cols_train.columns)] = OH_cols_train[list(OH_cols_train.columns)].astype(int)\n",
    "OH_cols_valid[list(OH_cols_valid.columns)] = OH_cols_valid[list(OH_cols_valid.columns)].astype(int)\n",
    "OH_cols_test[list(OH_cols_test.columns)] = OH_cols_test[list(OH_cols_test.columns)].astype(int)\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train = train_X.drop(low_cardinality_cols, axis=1)\n",
    "num_X_valid = val_X.drop(low_cardinality_cols, axis=1)\n",
    "num_X_test = X_test.drop(low_cardinality_cols, axis=1)\n",
    "\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
    "OH_X_test = pd.concat([num_X_test, OH_cols_test], axis=1)\n",
    "\n",
    "# Problème de string\n",
    "OH_X_train.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_valid.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_test.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_train.columns = OH_X_train.columns.astype(str)\n",
    "OH_X_valid.columns = OH_X_valid.columns.astype(str)\n",
    "OH_X_test.columns = OH_X_test.columns.astype(str)\n",
    "\n",
    "train_X = OH_X_train\n",
    "val_X = OH_X_valid\n",
    "test_X = OH_X_test\n",
    "X_entier = pd.concat([train_X, val_X])\n",
    "\n",
    "mi_scores = make_mi_scores(X_entier , y)\n",
    "\n",
    "verylowMI = list(mi_scores[mi_scores<0.0001].index)\n",
    "lowMI = list(mi_scores[(mi_scores>=0.0001)&(mi_scores<0.001)].index)\n",
    "mediumMI = list(mi_scores[(mi_scores>=0.001)&(mi_scores<0.01)].index)\n",
    "highMI = list(mi_scores[mi_scores>=0.01].index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ec3b1ea1",
   "metadata": {},
   "source": [
    "### 2.1 Delecte the very low MI columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e249b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Delete very low MImax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 12:47:02.126949</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.013564</td>\n",
       "      <td>0.881780</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.661017</td>\n",
       "      <td>[0.666666666, 0.666666666]</td>\n",
       "      <td>[0.661016949, 0.661016949]</td>\n",
       "      <td>0.882409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Delete very low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 12:47:03.327308</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.025621</td>\n",
       "      <td>0.801037</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>[0.69090909, 0.666666666]</td>\n",
       "      <td>[0.649122807, 0.649122807]</td>\n",
       "      <td>0.801648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Delete very low MIscale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 12:47:04.804995</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.891566</td>\n",
       "      <td>0.013564</td>\n",
       "      <td>0.891963</td>\n",
       "      <td>0.711864</td>\n",
       "      <td>0.715447</td>\n",
       "      <td>[0.677419354, 0.711864406]</td>\n",
       "      <td>[0.676923076, 0.715447154]</td>\n",
       "      <td>0.892249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>Delete very low MIupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 12:47:07.491174</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.025621</td>\n",
       "      <td>0.801037</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.801648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>Delete very low MIundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 12:47:10.004284</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.025621</td>\n",
       "      <td>0.801037</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.801648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Model  \\\n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  RandomForestClassifierUpperSampling   \n",
       "4  RandomForestClassifierUnderSampling   \n",
       "\n",
       "                                                            Description  \\\n",
       "0              Delete very low MImax_leaf_nodes : 6 + with date columns   \n",
       "1                         Delete very low MIn_estimators : 36 + Entropy   \n",
       "2                               Delete very low MIscale_pos_weight = 22   \n",
       "3     Delete very low MIupsampled, n_estimators=36, criterion = entropy   \n",
       "4  Delete very low MIundersampled, n_estimators=36, criterion = entropy   \n",
       "\n",
       "                        Date  Precision  Recall  F1-score   LogLoss       Mcc  \\\n",
       "0 2023-05-07 12:47:02.126949   0.942857   0.825  0.880000  0.013564  0.881780   \n",
       "1 2023-05-07 12:47:03.327308   0.755556   0.850  0.800000  0.025621  0.801037   \n",
       "2 2023-05-07 12:47:04.804995   0.860465   0.925  0.891566  0.013564  0.891963   \n",
       "3 2023-05-07 12:47:07.491174   0.755556   0.850  0.800000  0.025621  0.801037   \n",
       "4 2023-05-07 12:47:10.004284   0.755556   0.850  0.800000  0.025621  0.801037   \n",
       "\n",
       "   PublicScore  PrivateScore              OldPublicScore  \\\n",
       "0     0.666667      0.661017  [0.666666666, 0.666666666]   \n",
       "1     0.666667      0.649123   [0.69090909, 0.666666666]   \n",
       "2     0.711864      0.715447  [0.677419354, 0.711864406]   \n",
       "3     0.642857      0.620690  [0.678571428, 0.642857142]   \n",
       "4     0.642857      0.620690  [0.549019607, 0.642857142]   \n",
       "\n",
       "              OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949]        0.882409  \n",
       "1  [0.649122807, 0.649122807]        0.801648  \n",
       "2  [0.676923076, 0.715447154]        0.892249  \n",
       "3  [0.637168141, 0.620689655]        0.801648  \n",
       "4   [0.48076923, 0.620689655]        0.801648  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "val_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "test_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "X_entier.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "\n",
    "withoutverylowMI = comparemodels(train_X, train_y, val_X, test_X, \"Delete very low MI\")\n",
    "withoutverylowMI[\"PublicScore\"] = [0.666666666, 0.666666666, 0.711864406, 0.642857142, 0.642857142]\n",
    "withoutverylowMI[\"PrivateScore\"] = [0.661016949, 0.649122807, 0.715447154, 0.620689655, 0.620689655]\n",
    "withoutverylowMI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8706e9dd",
   "metadata": {},
   "source": [
    "### 2.2 Delete low MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e32077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Delete low MImax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 12:47:10.178916</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.157730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666, 0.666666666]</td>\n",
       "      <td>[0.661016949, 0.661016949]</td>\n",
       "      <td>0.199660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Delete low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 12:47:11.184763</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.051241</td>\n",
       "      <td>0.495474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909, 0.666666666]</td>\n",
       "      <td>[0.649122807, 0.649122807]</td>\n",
       "      <td>0.498927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Delete low MIscale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 12:47:12.293870</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.495413</td>\n",
       "      <td>0.082890</td>\n",
       "      <td>0.512908</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354, 0.711864406]</td>\n",
       "      <td>[0.676923076, 0.715447154]</td>\n",
       "      <td>0.518656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>Delete low MIupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 12:47:14.670724</td>\n",
       "      <td>0.358209</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.448598</td>\n",
       "      <td>0.088919</td>\n",
       "      <td>0.462470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.467319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>Delete low MIundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 12:47:17.138152</td>\n",
       "      <td>0.358209</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.448598</td>\n",
       "      <td>0.088919</td>\n",
       "      <td>0.462470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.467319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Model  \\\n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  RandomForestClassifierUpperSampling   \n",
       "4  RandomForestClassifierUnderSampling   \n",
       "\n",
       "                                                       Description  \\\n",
       "0              Delete low MImax_leaf_nodes : 6 + with date columns   \n",
       "1                         Delete low MIn_estimators : 36 + Entropy   \n",
       "2                               Delete low MIscale_pos_weight = 22   \n",
       "3     Delete low MIupsampled, n_estimators=36, criterion = entropy   \n",
       "4  Delete low MIundersampled, n_estimators=36, criterion = entropy   \n",
       "\n",
       "                        Date  Precision  Recall  F1-score   LogLoss       Mcc  \\\n",
       "0 2023-05-07 12:47:10.178916   0.500000   0.050  0.090909  0.060284  0.157730   \n",
       "1 2023-05-07 12:47:11.184763   0.615385   0.400  0.484848  0.051241  0.495474   \n",
       "2 2023-05-07 12:47:12.293870   0.391304   0.675  0.495413  0.082890  0.512908   \n",
       "3 2023-05-07 12:47:14.670724   0.358209   0.600  0.448598  0.088919  0.462470   \n",
       "4 2023-05-07 12:47:17.138152   0.358209   0.600  0.448598  0.088919  0.462470   \n",
       "\n",
       "   PublicScore  PrivateScore              OldPublicScore  \\\n",
       "0          NaN           NaN  [0.666666666, 0.666666666]   \n",
       "1          NaN           NaN   [0.69090909, 0.666666666]   \n",
       "2          NaN           NaN  [0.677419354, 0.711864406]   \n",
       "3          NaN           NaN  [0.678571428, 0.642857142]   \n",
       "4          NaN           NaN  [0.549019607, 0.642857142]   \n",
       "\n",
       "              OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949]        0.199660  \n",
       "1  [0.649122807, 0.649122807]        0.498927  \n",
       "2  [0.676923076, 0.715447154]        0.518656  \n",
       "3  [0.637168141, 0.620689655]        0.467319  \n",
       "4   [0.48076923, 0.620689655]        0.467319  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "val_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "test_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "X_entier.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "train_X.drop(lowMI, inplace=True, axis=1, errors='ignore')\n",
    "val_X.drop(lowMI, inplace=True, axis=1, errors='ignore')\n",
    "test_X.drop(lowMI, inplace=True, axis=1, errors='ignore')\n",
    "X_entier.drop(lowMI, inplace=True, axis=1, errors='ignore')\n",
    "\n",
    "withoutlowMI = comparemodels(train_X, train_y, val_X, test_X, \"Delete low MI\")\n",
    "withoutlowMI[\"PublicScore\"] = [np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "withoutlowMI[\"PrivateScore\"] = [np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "withoutlowMI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2dfcef5b",
   "metadata": {},
   "source": [
    "### 2.3 Delete medium MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19084bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarah\\Documents\\ECAM_non_One_Drive\\Interligence artificiel\\Projet Niko\\AI5L_AILab_FraudDetection\\EvaluationMetric.py:8: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  metric = tp / (tp+fp)\n",
      "C:\\Users\\sarah\\Documents\\ECAM_non_One_Drive\\Interligence artificiel\\Projet Niko\\AI5L_AILab_FraudDetection\\EvaluationMetric.py:20: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = tp / (tp+fp)\n",
      "C:\\Users\\sarah\\Documents\\ECAM_non_One_Drive\\Interligence artificiel\\Projet Niko\\AI5L_AILab_FraudDetection\\EvaluationMetric.py:8: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  metric = tp / (tp+fp)\n",
      "C:\\Users\\sarah\\Documents\\ECAM_non_One_Drive\\Interligence artificiel\\Projet Niko\\AI5L_AILab_FraudDetection\\EvaluationMetric.py:20: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = tp / (tp+fp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Delete medium MImax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 12:47:17.292606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666, 0.666666666]</td>\n",
       "      <td>[0.661016949, 0.661016949]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Delete medium MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 12:47:17.763021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909, 0.666666666]</td>\n",
       "      <td>[0.649122807, 0.649122807]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Delete medium MIscale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 12:47:18.356777</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.162791</td>\n",
       "      <td>0.108511</td>\n",
       "      <td>0.161685</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354, 0.711864406]</td>\n",
       "      <td>[0.676923076, 0.715447154]</td>\n",
       "      <td>0.162913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>Delete medium MIupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 12:47:19.203122</td>\n",
       "      <td>0.010398</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.020544</td>\n",
       "      <td>4.885998</td>\n",
       "      <td>0.084977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.241480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>Delete medium MIundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 12:47:20.018901</td>\n",
       "      <td>0.010398</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.020544</td>\n",
       "      <td>4.885998</td>\n",
       "      <td>0.084977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.241480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Model  \\\n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  RandomForestClassifierUpperSampling   \n",
       "4  RandomForestClassifierUnderSampling   \n",
       "\n",
       "                                                          Description  \\\n",
       "0              Delete medium MImax_leaf_nodes : 6 + with date columns   \n",
       "1                         Delete medium MIn_estimators : 36 + Entropy   \n",
       "2                               Delete medium MIscale_pos_weight = 22   \n",
       "3     Delete medium MIupsampled, n_estimators=36, criterion = entropy   \n",
       "4  Delete medium MIundersampled, n_estimators=36, criterion = entropy   \n",
       "\n",
       "                        Date  Precision  Recall  F1-score   LogLoss       Mcc  \\\n",
       "0 2023-05-07 12:47:17.292606        NaN   0.000       NaN  0.060284  0.000000   \n",
       "1 2023-05-07 12:47:17.763021        NaN   0.000       NaN  0.060284  0.000000   \n",
       "2 2023-05-07 12:47:18.356777   0.152174   0.175  0.162791  0.108511  0.161685   \n",
       "3 2023-05-07 12:47:19.203122   0.010398   0.850  0.020544  4.885998  0.084977   \n",
       "4 2023-05-07 12:47:20.018901   0.010398   0.850  0.020544  4.885998  0.084977   \n",
       "\n",
       "   PublicScore  PrivateScore              OldPublicScore  \\\n",
       "0          NaN           NaN  [0.666666666, 0.666666666]   \n",
       "1          NaN           NaN   [0.69090909, 0.666666666]   \n",
       "2          NaN           NaN  [0.677419354, 0.711864406]   \n",
       "3          NaN           NaN  [0.678571428, 0.642857142]   \n",
       "4          NaN           NaN  [0.549019607, 0.642857142]   \n",
       "\n",
       "              OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949]        0.000000  \n",
       "1  [0.649122807, 0.649122807]        0.000000  \n",
       "2  [0.676923076, 0.715447154]        0.162913  \n",
       "3  [0.637168141, 0.620689655]        0.241480  \n",
       "4   [0.48076923, 0.620689655]        0.241480  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "val_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "test_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "X_entier.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "train_X.drop(lowMI, inplace=True, axis=1, errors='ignore')\n",
    "val_X.drop(lowMI, inplace=True, axis=1, errors='ignore')\n",
    "test_X.drop(lowMI, inplace=True, axis=1, errors='ignore')\n",
    "X_entier.drop(lowMI, inplace=True, axis=1, errors='ignore')\n",
    "\n",
    "train_X.drop(mediumMI, inplace=True, axis=1, errors='ignore')\n",
    "val_X.drop(mediumMI, inplace=True, axis=1, errors='ignore')\n",
    "test_X.drop(mediumMI, inplace=True, axis=1, errors='ignore')\n",
    "X_entier.drop(mediumMI, inplace=True, axis=1, errors='ignore')\n",
    "\n",
    "withoutmediumMI = comparemodels(train_X, train_y, val_X, test_X, \"Delete medium MI\")\n",
    "withoutmediumMI[\"PublicScore\"] = [np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "withoutmediumMI[\"PrivateScore\"] = [np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "withoutmediumMI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "418bccbc",
   "metadata": {},
   "source": [
    "## 2. Play with deleting the low MI columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "46c1db32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supprimer les MI trop faible\n",
    "def_feature = pd.read_csv(\"input/Xente_Variable_Definitions.csv\")\n",
    "raw_data = pd.read_csv(\"input/training.csv\")\n",
    "X_test = pd.read_csv(\"input/test.csv\")\n",
    "sample_submission = pd.read_csv(\"input/sample_submission.csv\")\n",
    "\n",
    "#attribut initialization\n",
    "cols_unique_value = [] #Will be droped\n",
    "for col in raw_data.columns : \n",
    "    if len(raw_data[col].unique()) == 1 :\n",
    "        cols_unique_value.append(col)\n",
    "\n",
    "medium_cardianlity_cols = [\"ProductId\"]\n",
    "\n",
    "#Data transformation\n",
    "raw_data['TransactionStartTime'] = pd.to_datetime(raw_data['TransactionStartTime'])\n",
    "X_test['TransactionStartTime'] = pd.to_datetime(X_test['TransactionStartTime'])\n",
    "\n",
    "#Data cleaning\n",
    "data = raw_data.copy()\n",
    "data = data.dropna(axis=0) #Drop observations/rows with missing values\n",
    "X_test=X_test.dropna(axis=0)\n",
    "data.drop(cols_unique_value, axis=1, inplace=True)\n",
    "X_test.drop(cols_unique_value, axis=1, inplace=True)\n",
    "\n",
    "#Prepare index for the submission\n",
    "index_val = list(X_test.TransactionId.values.tolist())\n",
    "\n",
    "#Set the df index to the Transction Id\n",
    "data = transactioId_to_index(data)\n",
    "X_test = transactioId_to_index(X_test)\n",
    "\n",
    "#Adding data\n",
    "data = adding_date_col(data, 'TransactionStartTime')\n",
    "X_test = adding_date_col(X_test, 'TransactionStartTime')\n",
    "\n",
    "\n",
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "low_cardinality_cols = [cname for cname in data.columns if data[cname].nunique() < 15 and \n",
    "                        data[cname].dtype == \"object\"]\n",
    "low_cardinality_cols.append('PricingStrategy')\n",
    "\n",
    "#transform columns BatchId_54 to number\n",
    "    #transform columns BatchId_54 to number\n",
    "id_cols = data.filter(like=\"Id\").columns.tolist()\n",
    "data[id_cols] = data[id_cols].astype(str).apply(lambda x: x.str.replace(x.name + \"_\", \"\")).astype(int)\n",
    "X_test[id_cols] = X_test[id_cols].astype(str).apply(lambda x: x.str.replace(x.name + \"_\", \"\")).astype(int)\n",
    "\n",
    "data['PricingStrategy'] = data['PricingStrategy'].astype('int')\n",
    "X_test['PricingStrategy'] = X_test['PricingStrategy'].astype('int')\n",
    "data['Value'] = data['Value'].astype('float')\n",
    "X_test['Value'] = X_test['Value'].astype('float')\n",
    "\n",
    "X_test['PricingStrategy'] = X_test['PricingStrategy'].astype('str')\n",
    "data['PricingStrategy'] = data['PricingStrategy'].astype('str')\n",
    "\n",
    "#Data splitting\n",
    "y = data.FraudResult #The target label\n",
    "X = data.copy()\n",
    "X.drop(['FraudResult'], axis=1, inplace=True) #Only the features data\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "cat_cols = [col for col in X.columns if X[col].dtype == \"object\"]#liste of obejct columns\n",
    "cat_cols.append(\"PricingStrategy\")#pcq mm si c'est un chiffre il faut le considérer comme une catégorie\n",
    "\n",
    "\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(train_X[low_cardinality_cols]))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(val_X[low_cardinality_cols]))\n",
    "OH_cols_test = pd.DataFrame(OH_encoder.transform(X_test[low_cardinality_cols]))\n",
    "OH_cols_train.columns = OH_encoder.get_feature_names_out()\n",
    "OH_cols_valid.columns = OH_encoder.get_feature_names_out()\n",
    "OH_cols_test.columns = OH_encoder.get_feature_names_out()\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_train.index = train_X.index\n",
    "OH_cols_valid.index = val_X.index\n",
    "OH_cols_test.index = X_test.index\n",
    "\n",
    "OH_cols_train[list(OH_cols_train.columns)] = OH_cols_train[list(OH_cols_train.columns)].astype(int)\n",
    "OH_cols_valid[list(OH_cols_valid.columns)] = OH_cols_valid[list(OH_cols_valid.columns)].astype(int)\n",
    "OH_cols_test[list(OH_cols_test.columns)] = OH_cols_test[list(OH_cols_test.columns)].astype(int)\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train = train_X.drop(low_cardinality_cols, axis=1)\n",
    "num_X_valid = val_X.drop(low_cardinality_cols, axis=1)\n",
    "num_X_test = X_test.drop(low_cardinality_cols, axis=1)\n",
    "\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
    "OH_X_test = pd.concat([num_X_test, OH_cols_test], axis=1)\n",
    "\n",
    "# Problème de string\n",
    "OH_X_train.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_valid.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_test.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_train.columns = OH_X_train.columns.astype(str)\n",
    "OH_X_valid.columns = OH_X_valid.columns.astype(str)\n",
    "OH_X_test.columns = OH_X_test.columns.astype(str)\n",
    "\n",
    "train_X = OH_X_train\n",
    "val_X = OH_X_valid\n",
    "test_X = OH_X_test\n",
    "X_entier = pd.concat([train_X, val_X])\n",
    "\n",
    "mi_scores = make_mi_scores(X_entier , y)\n",
    "\n",
    "verylowMI = list(mi_scores[mi_scores<0.0001].index)\n",
    "lowMI = list(mi_scores[(mi_scores>=0.0001)&(mi_scores<0.001)].index)\n",
    "mediumMI = list(mi_scores[(mi_scores>=0.001)&(mi_scores<0.01)].index)\n",
    "highMI = list(mi_scores[mi_scores>=0.01].index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6da4602e",
   "metadata": {},
   "source": [
    "### 2.1 Delecte the very low MI columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "df174abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Delete very low MImax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 16:30:13.941221</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.013564</td>\n",
       "      <td>0.881780</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.661017</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.882409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Delete very low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:15.122144</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.021099</td>\n",
       "      <td>0.838969</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.839697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Delete very low MIscale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 16:30:16.312527</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.891566</td>\n",
       "      <td>0.013564</td>\n",
       "      <td>0.891963</td>\n",
       "      <td>0.711864</td>\n",
       "      <td>0.715447</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.892249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest ClassifierWeighted500</td>\n",
       "      <td>Delete very low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:17.497220</td>\n",
       "      <td>0.760870</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.024113</td>\n",
       "      <td>0.815615</td>\n",
       "      <td>0.654545</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>0.816359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest ClassifierWeighted22</td>\n",
       "      <td>Delete very low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:18.625953</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.025621</td>\n",
       "      <td>0.801037</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.647619</td>\n",
       "      <td>[0.703703703]</td>\n",
       "      <td>[0.654867256]</td>\n",
       "      <td>0.801648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>Delete very low MIupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 16:30:21.059364</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.030142</td>\n",
       "      <td>0.775535</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.776649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>Delete very low MIundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 16:30:23.314014</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.030142</td>\n",
       "      <td>0.775535</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.776649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Model  \\\n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  Random Forest ClassifierWeighted500   \n",
       "4   Random Forest ClassifierWeighted22   \n",
       "5  RandomForestClassifierUpperSampling   \n",
       "6  RandomForestClassifierUnderSampling   \n",
       "\n",
       "                                                            Description  \\\n",
       "0              Delete very low MImax_leaf_nodes : 6 + with date columns   \n",
       "1                         Delete very low MIn_estimators : 36 + Entropy   \n",
       "2                               Delete very low MIscale_pos_weight = 22   \n",
       "3                         Delete very low MIn_estimators : 36 + Entropy   \n",
       "4                         Delete very low MIn_estimators : 36 + Entropy   \n",
       "5     Delete very low MIupsampled, n_estimators=36, criterion = entropy   \n",
       "6  Delete very low MIundersampled, n_estimators=36, criterion = entropy   \n",
       "\n",
       "                        Date  Precision  Recall  F1-score   LogLoss       Mcc  \\\n",
       "0 2023-05-07 16:30:13.941221   0.942857   0.825  0.880000  0.013564  0.881780   \n",
       "1 2023-05-07 16:30:15.122144   0.782609   0.900  0.837209  0.021099  0.838969   \n",
       "2 2023-05-07 16:30:16.312527   0.860465   0.925  0.891566  0.013564  0.891963   \n",
       "3 2023-05-07 16:30:17.497220   0.760870   0.875  0.813953  0.024113  0.815615   \n",
       "4 2023-05-07 16:30:18.625953   0.755556   0.850  0.800000  0.025621  0.801037   \n",
       "5 2023-05-07 16:30:21.059364   0.708333   0.850  0.772727  0.030142  0.775535   \n",
       "6 2023-05-07 16:30:23.314014   0.708333   0.850  0.772727  0.030142  0.775535   \n",
       "\n",
       "   PublicScore  PrivateScore                           OldPublicScore  \\\n",
       "0     0.666667      0.661017  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1     0.666667      0.649123   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2     0.711864      0.715447  [0.677419354, 0.711864406, 0.092764378]   \n",
       "3     0.654545      0.666667                            [0.678571428]   \n",
       "4     0.595745      0.647619                            [0.703703703]   \n",
       "5     0.642857      0.620690               [0.678571428, 0.642857142]   \n",
       "6     0.642857      0.620690               [0.549019607, 0.642857142]   \n",
       "\n",
       "                           OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.882409  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.839697  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.892249  \n",
       "3                            [0.666666666]        0.816359  \n",
       "4                            [0.654867256]        0.801648  \n",
       "5               [0.637168141, 0.620689655]        0.776649  \n",
       "6                [0.48076923, 0.620689655]        0.776649  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "val_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "test_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "X_entier.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "\n",
    "withoutverylowMI = comparemodels(train_X, train_y, val_X, test_X, \"Delete very low MI\")\n",
    "withoutverylowMI[\"PublicScore\"] = [0.666666666, 0.666666666, 0.711864406, 0.654545454, 0.595744680, 0.642857142, 0.642857142]\n",
    "withoutverylowMI[\"PrivateScore\"] = [0.661016949, 0.649122807, 0.715447154, 0.666666666, 0.647619047, 0.620689655, 0.620689655]\n",
    "withoutverylowMI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "073967ea",
   "metadata": {},
   "source": [
    "### 2.2 Delete low MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0235a795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Delete low MImax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 16:30:23.482611</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.157730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.199660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Delete low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:24.429001</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.051241</td>\n",
       "      <td>0.495474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.498927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Delete low MIscale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 16:30:25.364763</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.495413</td>\n",
       "      <td>0.082890</td>\n",
       "      <td>0.512908</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.518656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest ClassifierWeighted500</td>\n",
       "      <td>Delete low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:26.329033</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.507463</td>\n",
       "      <td>0.049734</td>\n",
       "      <td>0.516643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>0.519684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest ClassifierWeighted22</td>\n",
       "      <td>Delete low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:27.271725</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.048227</td>\n",
       "      <td>0.526526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.703703703]</td>\n",
       "      <td>[0.654867256]</td>\n",
       "      <td>0.530131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>Delete low MIupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 16:30:29.422086</td>\n",
       "      <td>0.358209</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.448598</td>\n",
       "      <td>0.088919</td>\n",
       "      <td>0.462470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.467319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>Delete low MIundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 16:30:31.531002</td>\n",
       "      <td>0.358209</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.448598</td>\n",
       "      <td>0.088919</td>\n",
       "      <td>0.462470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.467319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Model  \\\n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  Random Forest ClassifierWeighted500   \n",
       "4   Random Forest ClassifierWeighted22   \n",
       "5  RandomForestClassifierUpperSampling   \n",
       "6  RandomForestClassifierUnderSampling   \n",
       "\n",
       "                                                       Description  \\\n",
       "0              Delete low MImax_leaf_nodes : 6 + with date columns   \n",
       "1                         Delete low MIn_estimators : 36 + Entropy   \n",
       "2                               Delete low MIscale_pos_weight = 22   \n",
       "3                         Delete low MIn_estimators : 36 + Entropy   \n",
       "4                         Delete low MIn_estimators : 36 + Entropy   \n",
       "5     Delete low MIupsampled, n_estimators=36, criterion = entropy   \n",
       "6  Delete low MIundersampled, n_estimators=36, criterion = entropy   \n",
       "\n",
       "                        Date  Precision  Recall  F1-score   LogLoss       Mcc  \\\n",
       "0 2023-05-07 16:30:23.482611   0.500000   0.050  0.090909  0.060284  0.157730   \n",
       "1 2023-05-07 16:30:24.429001   0.615385   0.400  0.484848  0.051241  0.495474   \n",
       "2 2023-05-07 16:30:25.364763   0.391304   0.675  0.495413  0.082890  0.512908   \n",
       "3 2023-05-07 16:30:26.329033   0.629630   0.425  0.507463  0.049734  0.516643   \n",
       "4 2023-05-07 16:30:27.271725   0.653846   0.425  0.515152  0.048227  0.526526   \n",
       "5 2023-05-07 16:30:29.422086   0.358209   0.600  0.448598  0.088919  0.462470   \n",
       "6 2023-05-07 16:30:31.531002   0.358209   0.600  0.448598  0.088919  0.462470   \n",
       "\n",
       "   PublicScore  PrivateScore                           OldPublicScore  \\\n",
       "0          NaN           NaN  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1          NaN           NaN   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2          NaN           NaN  [0.677419354, 0.711864406, 0.092764378]   \n",
       "3          NaN           NaN                            [0.678571428]   \n",
       "4          NaN           NaN                            [0.703703703]   \n",
       "5          NaN           NaN               [0.678571428, 0.642857142]   \n",
       "6          NaN           NaN               [0.549019607, 0.642857142]   \n",
       "\n",
       "                           OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.199660  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.498927  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.518656  \n",
       "3                            [0.666666666]        0.519684  \n",
       "4                            [0.654867256]        0.530131  \n",
       "5               [0.637168141, 0.620689655]        0.467319  \n",
       "6                [0.48076923, 0.620689655]        0.467319  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "val_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "test_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "X_entier.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "train_X.drop(lowMI, inplace=True, axis=1, errors='ignore')\n",
    "val_X.drop(lowMI, inplace=True, axis=1, errors='ignore')\n",
    "test_X.drop(lowMI, inplace=True, axis=1, errors='ignore')\n",
    "X_entier.drop(lowMI, inplace=True, axis=1, errors='ignore')\n",
    "\n",
    "withoutlowMI = comparemodels(train_X, train_y, val_X, test_X, \"Delete low MI\")\n",
    "withoutlowMI[\"PublicScore\"] = [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "withoutlowMI[\"PrivateScore\"] = [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "withoutlowMI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "47fb5923",
   "metadata": {},
   "source": [
    "### 2.3 Delete medium MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "463dd25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarah\\Documents\\ECAM_non_One_Drive\\Interligence artificiel\\Projet Niko\\AI5L_AILab_FraudDetection\\EvaluationMetric.py:8: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  metric = tp / (tp+fp)\n",
      "C:\\Users\\sarah\\Documents\\ECAM_non_One_Drive\\Interligence artificiel\\Projet Niko\\AI5L_AILab_FraudDetection\\EvaluationMetric.py:20: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = tp / (tp+fp)\n",
      "C:\\Users\\sarah\\Documents\\ECAM_non_One_Drive\\Interligence artificiel\\Projet Niko\\AI5L_AILab_FraudDetection\\EvaluationMetric.py:8: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  metric = tp / (tp+fp)\n",
      "C:\\Users\\sarah\\Documents\\ECAM_non_One_Drive\\Interligence artificiel\\Projet Niko\\AI5L_AILab_FraudDetection\\EvaluationMetric.py:20: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = tp / (tp+fp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarah\\Documents\\ECAM_non_One_Drive\\Interligence artificiel\\Projet Niko\\AI5L_AILab_FraudDetection\\EvaluationMetric.py:8: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  metric = tp / (tp+fp)\n",
      "C:\\Users\\sarah\\Documents\\ECAM_non_One_Drive\\Interligence artificiel\\Projet Niko\\AI5L_AILab_FraudDetection\\EvaluationMetric.py:20: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = tp / (tp+fp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarah\\Documents\\ECAM_non_One_Drive\\Interligence artificiel\\Projet Niko\\AI5L_AILab_FraudDetection\\EvaluationMetric.py:8: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  metric = tp / (tp+fp)\n",
      "C:\\Users\\sarah\\Documents\\ECAM_non_One_Drive\\Interligence artificiel\\Projet Niko\\AI5L_AILab_FraudDetection\\EvaluationMetric.py:20: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = tp / (tp+fp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Delete medium MImax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 16:30:31.663343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Delete medium MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:32.095585</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Delete medium MIscale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 16:30:32.543177</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.162791</td>\n",
       "      <td>0.108511</td>\n",
       "      <td>0.161685</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.162913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest ClassifierWeighted500</td>\n",
       "      <td>Delete medium MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:33.010695</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest ClassifierWeighted22</td>\n",
       "      <td>Delete medium MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:33.443986</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.703703703]</td>\n",
       "      <td>[0.654867256]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>Delete medium MIupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 16:30:34.208445</td>\n",
       "      <td>0.010398</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.020544</td>\n",
       "      <td>4.885998</td>\n",
       "      <td>0.084977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.241480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>Delete medium MIundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 16:30:34.949979</td>\n",
       "      <td>0.010398</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.020544</td>\n",
       "      <td>4.885998</td>\n",
       "      <td>0.084977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.241480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Model  \\\n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  Random Forest ClassifierWeighted500   \n",
       "4   Random Forest ClassifierWeighted22   \n",
       "5  RandomForestClassifierUpperSampling   \n",
       "6  RandomForestClassifierUnderSampling   \n",
       "\n",
       "                                                          Description  \\\n",
       "0              Delete medium MImax_leaf_nodes : 6 + with date columns   \n",
       "1                         Delete medium MIn_estimators : 36 + Entropy   \n",
       "2                               Delete medium MIscale_pos_weight = 22   \n",
       "3                         Delete medium MIn_estimators : 36 + Entropy   \n",
       "4                         Delete medium MIn_estimators : 36 + Entropy   \n",
       "5     Delete medium MIupsampled, n_estimators=36, criterion = entropy   \n",
       "6  Delete medium MIundersampled, n_estimators=36, criterion = entropy   \n",
       "\n",
       "                        Date  Precision  Recall  F1-score   LogLoss       Mcc  \\\n",
       "0 2023-05-07 16:30:31.663343        NaN   0.000       NaN  0.060284  0.000000   \n",
       "1 2023-05-07 16:30:32.095585        NaN   0.000       NaN  0.060284  0.000000   \n",
       "2 2023-05-07 16:30:32.543177   0.152174   0.175  0.162791  0.108511  0.161685   \n",
       "3 2023-05-07 16:30:33.010695        NaN   0.000       NaN  0.060284  0.000000   \n",
       "4 2023-05-07 16:30:33.443986        NaN   0.000       NaN  0.060284  0.000000   \n",
       "5 2023-05-07 16:30:34.208445   0.010398   0.850  0.020544  4.885998  0.084977   \n",
       "6 2023-05-07 16:30:34.949979   0.010398   0.850  0.020544  4.885998  0.084977   \n",
       "\n",
       "   PublicScore  PrivateScore                           OldPublicScore  \\\n",
       "0          NaN           NaN  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1          NaN           NaN   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2          NaN           NaN  [0.677419354, 0.711864406, 0.092764378]   \n",
       "3          NaN           NaN                            [0.678571428]   \n",
       "4          NaN           NaN                            [0.703703703]   \n",
       "5          NaN           NaN               [0.678571428, 0.642857142]   \n",
       "6          NaN           NaN               [0.549019607, 0.642857142]   \n",
       "\n",
       "                           OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.000000  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.000000  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.162913  \n",
       "3                            [0.666666666]        0.000000  \n",
       "4                            [0.654867256]        0.000000  \n",
       "5               [0.637168141, 0.620689655]        0.241480  \n",
       "6                [0.48076923, 0.620689655]        0.241480  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "val_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "test_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "X_entier.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "train_X.drop(lowMI, inplace=True, axis=1, errors='ignore')\n",
    "val_X.drop(lowMI, inplace=True, axis=1, errors='ignore')\n",
    "test_X.drop(lowMI, inplace=True, axis=1, errors='ignore')\n",
    "X_entier.drop(lowMI, inplace=True, axis=1, errors='ignore')\n",
    "\n",
    "train_X.drop(mediumMI, inplace=True, axis=1, errors='ignore')\n",
    "val_X.drop(mediumMI, inplace=True, axis=1, errors='ignore')\n",
    "test_X.drop(mediumMI, inplace=True, axis=1, errors='ignore')\n",
    "X_entier.drop(mediumMI, inplace=True, axis=1, errors='ignore')\n",
    "\n",
    "withoutmediumMI = comparemodels(train_X, train_y, val_X, test_X, \"Delete medium MI\")\n",
    "withoutmediumMI[\"PublicScore\"] = [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "withoutmediumMI[\"PrivateScore\"] = [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "withoutmediumMI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54f269ad",
   "metadata": {},
   "source": [
    "## 3 Undersampling with K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0f58714f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarah\\anaconda3\\envs\\AILab-ECAM4\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Kmeans UnderSamplingmax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 16:31:00.117654</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.371584</td>\n",
       "      <td>0.979557</td>\n",
       "      <td>0.006575</td>\n",
       "      <td>0.006863</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.987512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Kmeans UnderSamplingn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:31:00.285578</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.114752</td>\n",
       "      <td>0.938324</td>\n",
       "      <td>0.007513</td>\n",
       "      <td>0.007795</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.961903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Kmeans UnderSamplingon balanced data</td>\n",
       "      <td>2023-05-07 16:31:00.404309</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.114752</td>\n",
       "      <td>0.938324</td>\n",
       "      <td>0.092764</td>\n",
       "      <td>0.096565</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.961903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model  \\\n",
       "0    DecisionTreeClassifier   \n",
       "1  Random Forest Classifier   \n",
       "2             XGBClassifier   \n",
       "\n",
       "                                                  Description  \\\n",
       "0  Kmeans UnderSamplingmax_leaf_nodes : 6 + with date columns   \n",
       "1             Kmeans UnderSamplingn_estimators : 36 + Entropy   \n",
       "2                        Kmeans UnderSamplingon balanced data   \n",
       "\n",
       "                        Date  Precision  Recall  F1-score   LogLoss       Mcc  \\\n",
       "0 2023-05-07 16:31:00.117654   0.980392    1.00  0.990099  0.371584  0.979557   \n",
       "1 2023-05-07 16:31:00.285578   0.979592    0.96  0.969697  1.114752  0.938324   \n",
       "2 2023-05-07 16:31:00.404309   0.979592    0.96  0.969697  1.114752  0.938324   \n",
       "\n",
       "   PublicScore  PrivateScore                           OldPublicScore  \\\n",
       "0     0.006575      0.006863  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1     0.007513      0.007795   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2     0.092764      0.096565  [0.677419354, 0.711864406, 0.092764378]   \n",
       "\n",
       "                           OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.987512  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.961903  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.961903  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans \n",
    "\n",
    "# K-means fait sur training set entier (et ensuite sur seuelement le train_X)\n",
    "def_feature = pd.read_csv(\"input/Xente_Variable_Definitions.csv\")\n",
    "raw_data = pd.read_csv(\"input/training.csv\")\n",
    "X_test = pd.read_csv(\"input/test.csv\")\n",
    "sample_submission = pd.read_csv(\"input/sample_submission.csv\")\n",
    "\n",
    "#attribut initialization\n",
    "cols_unique_value = [] #Will be droped\n",
    "for col in raw_data.columns : \n",
    "    if len(raw_data[col].unique()) == 1 :\n",
    "        cols_unique_value.append(col)\n",
    "\n",
    "medium_cardianlity_cols = [\"ProductId\"]\n",
    "\n",
    "#Data transformation\n",
    "raw_data['TransactionStartTime'] = pd.to_datetime(raw_data['TransactionStartTime'])\n",
    "X_test['TransactionStartTime'] = pd.to_datetime(X_test['TransactionStartTime'])\n",
    "\n",
    "#Data cleaning\n",
    "data = raw_data.copy()\n",
    "data = data.dropna(axis=0) #Drop observations/rows with missing values\n",
    "X_test=X_test.dropna(axis=0)\n",
    "data.drop(cols_unique_value, axis=1, inplace=True)\n",
    "X_test.drop(cols_unique_value, axis=1, inplace=True)\n",
    "\n",
    "#Prepare index for the submission\n",
    "index_val = list(X_test.TransactionId.values.tolist())\n",
    "\n",
    "#Set the df index to the Transction Id\n",
    "data = transactioId_to_index(data)\n",
    "X_test = transactioId_to_index(X_test)\n",
    "\n",
    "#Adding data\n",
    "data = adding_date_col(data, 'TransactionStartTime')\n",
    "X_test = adding_date_col(X_test, 'TransactionStartTime')\n",
    "\n",
    "\n",
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "low_cardinality_cols = [cname for cname in data.columns if data[cname].nunique() < 15 and \n",
    "                        data[cname].dtype == \"object\"]\n",
    "low_cardinality_cols.append('PricingStrategy')\n",
    "\n",
    "#transform columns BatchId_54 to number\n",
    "    #transform columns BatchId_54 to number\n",
    "id_cols = data.filter(like=\"Id\").columns.tolist()\n",
    "data[id_cols] = data[id_cols].astype(str).apply(lambda x: x.str.replace(x.name + \"_\", \"\")).astype(int)\n",
    "X_test[id_cols] = X_test[id_cols].astype(str).apply(lambda x: x.str.replace(x.name + \"_\", \"\")).astype(int)\n",
    "\n",
    "data['PricingStrategy'] = data['PricingStrategy'].astype('int')\n",
    "X_test['PricingStrategy'] = X_test['PricingStrategy'].astype('int')\n",
    "data['Value'] = data['Value'].astype('float')\n",
    "X_test['Value'] = X_test['Value'].astype('float')\n",
    "\n",
    "X_test['PricingStrategy'] = X_test['PricingStrategy'].astype('str')\n",
    "data['PricingStrategy'] = data['PricingStrategy'].astype('str')\n",
    "\n",
    "#Data splitting\n",
    "y = data.FraudResult #The target label\n",
    "X = data.copy()\n",
    "X.drop(['FraudResult'], axis=1, inplace=True) #Only the features data\n",
    "\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "OH_cols_X = pd.DataFrame(OH_encoder.fit_transform(X[low_cardinality_cols]))\n",
    "OH_cols_X.columns = OH_encoder.get_feature_names_out()\n",
    "OH_cols_test = pd.DataFrame(OH_encoder.transform(X_test[low_cardinality_cols]))\n",
    "OH_cols_test.columns = OH_encoder.get_feature_names_out()\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_X.index = X.index\n",
    "OH_cols_test.index = X_test.index\n",
    "\n",
    "OH_cols_X[list(OH_cols_X.columns)] = OH_cols_X[list(OH_cols_X.columns)].astype(int)\n",
    "OH_cols_test[list(OH_cols_test.columns)] = OH_cols_test[list(OH_cols_test.columns)].astype(int)\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X = X.drop(low_cardinality_cols, axis=1)\n",
    "num_X_test = X_test.drop(low_cardinality_cols, axis=1)\n",
    "\n",
    "OH_X = pd.concat([num_X, OH_cols_X], axis=1)\n",
    "OH_X_test = pd.concat([num_X_test, OH_cols_test], axis=1)\n",
    "\n",
    "# Problème de string\n",
    "OH_X.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_test.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X.columns = OH_X.columns.astype(str)\n",
    "OH_X_test.columns = OH_X_test.columns.astype(str)\n",
    "\n",
    "X = OH_X\n",
    "\n",
    "#####K-Means\n",
    "X_0 = X[y == 0] # instances avec FraudResult=0\n",
    "X_1 = X[y == 1] # instances avec FraudResult=1\n",
    "\n",
    "# Créer des \"centres\" pour KMeans\n",
    "n_clusters = 193\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(X_0)\n",
    "centers = kmeans.cluster_centers_\n",
    "\n",
    "# Trouver les indices des instances à garder dans la classe FraudResult=0\n",
    "labels = kmeans.predict(X_0)\n",
    "distances = np.sum((X_0 - centers[labels]) ** 2, axis=1)\n",
    "keep_indices = np.argsort(distances)[:n_clusters]\n",
    "\n",
    "df_filtré = X_0[X_0.index.isin(list(keep_indices.index))]\n",
    "\n",
    "# Combiner les instances sous-échantillonnées\n",
    "X_undersampled = pd.concat([df_filtré, X_1])\n",
    "y_undersampled = np.concatenate((np.zeros(n_clusters), np.ones(len(X_1))), axis=0)\n",
    "\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(X_undersampled, y_undersampled, random_state = 0)\n",
    "\n",
    "\n",
    "#train_X.drop(verylowMI, inplace=True, axis=1)\n",
    "#val_X.drop(verylowMI, inplace=True, axis=1)\n",
    "#test_X.drop(verylowMI, inplace=True, axis=1)\n",
    "#X_entier.drop(verylowMI, inplace=True, axis=1)\n",
    "\n",
    "kmeansundersampling = comparemodels(train_X, train_y, val_X, OH_X_test, \"Kmeans UnderSampling\", unbalanced = False)\n",
    "kmeansundersampling[\"PublicScore\"] = [0.006575486, 0.007513148, 0.092764378]\n",
    "kmeansundersampling[\"PrivateScore\"] = [0.006863327, 0.007794933, 0.096564531] ###Cest trop nulle \n",
    "kmeansundersampling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "789ddb0c",
   "metadata": {},
   "source": [
    "## 4. SMOTE (Synthetic Minority Oversampling Technique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ed3fa295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>SMOTEmax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 16:31:18.853308</td>\n",
       "      <td>0.113372</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.203125</td>\n",
       "      <td>0.461171</td>\n",
       "      <td>0.330225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.405431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>SMOTEn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:31:22.707671</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.027128</td>\n",
       "      <td>0.804629</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.686567</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.806157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>SMOTEon balanced data</td>\n",
       "      <td>2023-05-07 16:31:25.958940</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.862324</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.376068</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.863034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model                                  Description  \\\n",
       "0    DecisionTreeClassifier  SMOTEmax_leaf_nodes : 6 + with date columns   \n",
       "1  Random Forest Classifier             SMOTEn_estimators : 36 + Entropy   \n",
       "2             XGBClassifier                        SMOTEon balanced data   \n",
       "\n",
       "                        Date  Precision  Recall  F1-score   LogLoss       Mcc  \\\n",
       "0 2023-05-07 16:31:18.853308   0.113372   0.975  0.203125  0.461171  0.330225   \n",
       "1 2023-05-07 16:31:22.707671   0.720000   0.900  0.800000  0.027128  0.804629   \n",
       "2 2023-05-07 16:31:25.958940   0.804348   0.925  0.860465  0.018085  0.862324   \n",
       "\n",
       "   PublicScore  PrivateScore                           OldPublicScore  \\\n",
       "0          NaN           NaN  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1     0.709677      0.686567   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2     0.358974      0.376068  [0.677419354, 0.711864406, 0.092764378]   \n",
       "\n",
       "                           OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.405431  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.806157  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.863034  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SMOTE\n",
    "def_feature = pd.read_csv(\"input/Xente_Variable_Definitions.csv\")\n",
    "raw_data = pd.read_csv(\"input/training.csv\")\n",
    "X_test = pd.read_csv(\"input/test.csv\")\n",
    "sample_submission = pd.read_csv(\"input/sample_submission.csv\")\n",
    "\n",
    "#attribut initialization\n",
    "cols_unique_value = [] #Will be droped\n",
    "for col in raw_data.columns : \n",
    "    if len(raw_data[col].unique()) == 1 :\n",
    "        cols_unique_value.append(col)\n",
    "\n",
    "medium_cardianlity_cols = [\"ProductId\"]\n",
    "\n",
    "#Data transformation\n",
    "raw_data['TransactionStartTime'] = pd.to_datetime(raw_data['TransactionStartTime'])\n",
    "X_test['TransactionStartTime'] = pd.to_datetime(X_test['TransactionStartTime'])\n",
    "\n",
    "#Data cleaning\n",
    "data = raw_data.copy()\n",
    "data = data.dropna(axis=0) #Drop observations/rows with missing values\n",
    "X_test=X_test.dropna(axis=0)\n",
    "data.drop(cols_unique_value, axis=1, inplace=True)\n",
    "X_test.drop(cols_unique_value, axis=1, inplace=True)\n",
    "\n",
    "#Prepare index for the submission\n",
    "index_val = list(X_test.TransactionId.values.tolist())\n",
    "\n",
    "#Set the df index to the Transction Id\n",
    "data = transactioId_to_index(data)\n",
    "X_test = transactioId_to_index(X_test)\n",
    "\n",
    "#Adding data\n",
    "data = adding_date_col(data, 'TransactionStartTime')\n",
    "X_test = adding_date_col(X_test, 'TransactionStartTime')\n",
    "\n",
    "\n",
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "low_cardinality_cols = [cname for cname in data.columns if data[cname].nunique() < 15 and \n",
    "                        data[cname].dtype == \"object\"]\n",
    "low_cardinality_cols.append('PricingStrategy')\n",
    "\n",
    "#transform columns BatchId_54 to number\n",
    "    #transform columns BatchId_54 to number\n",
    "id_cols = data.filter(like=\"Id\").columns.tolist()\n",
    "data[id_cols] = data[id_cols].astype(str).apply(lambda x: x.str.replace(x.name + \"_\", \"\")).astype(int)\n",
    "X_test[id_cols] = X_test[id_cols].astype(str).apply(lambda x: x.str.replace(x.name + \"_\", \"\")).astype(int)\n",
    "\n",
    "data['PricingStrategy'] = data['PricingStrategy'].astype('int')\n",
    "X_test['PricingStrategy'] = X_test['PricingStrategy'].astype('int')\n",
    "data['Value'] = data['Value'].astype('float')\n",
    "X_test['Value'] = X_test['Value'].astype('float')\n",
    "\n",
    "X_test['PricingStrategy'] = X_test['PricingStrategy'].astype('str')\n",
    "data['PricingStrategy'] = data['PricingStrategy'].astype('str')\n",
    "\n",
    "#Data splitting\n",
    "y = data.FraudResult #The target label\n",
    "X = data.copy()\n",
    "X.drop(['FraudResult'], axis=1, inplace=True) #Only the features data\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "cat_cols = [col for col in X.columns if X[col].dtype == \"object\"]#liste of obejct columns\n",
    "cat_cols.append(\"PricingStrategy\")#pcq mm si c'est un chiffre il faut le considérer comme une catégorie\n",
    "\n",
    "\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(train_X[low_cardinality_cols]))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(val_X[low_cardinality_cols]))\n",
    "OH_cols_test = pd.DataFrame(OH_encoder.transform(X_test[low_cardinality_cols]))\n",
    "OH_cols_train.columns = OH_encoder.get_feature_names_out()\n",
    "OH_cols_valid.columns = OH_encoder.get_feature_names_out()\n",
    "OH_cols_test.columns = OH_encoder.get_feature_names_out()\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_train.index = train_X.index\n",
    "OH_cols_valid.index = val_X.index\n",
    "OH_cols_test.index = X_test.index\n",
    "\n",
    "OH_cols_train[list(OH_cols_train.columns)] = OH_cols_train[list(OH_cols_train.columns)].astype(int)\n",
    "OH_cols_valid[list(OH_cols_valid.columns)] = OH_cols_valid[list(OH_cols_valid.columns)].astype(int)\n",
    "OH_cols_test[list(OH_cols_test.columns)] = OH_cols_test[list(OH_cols_test.columns)].astype(int)\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train = train_X.drop(low_cardinality_cols, axis=1)\n",
    "num_X_valid = val_X.drop(low_cardinality_cols, axis=1)\n",
    "num_X_test = X_test.drop(low_cardinality_cols, axis=1)\n",
    "\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
    "OH_X_test = pd.concat([num_X_test, OH_cols_test], axis=1)\n",
    "\n",
    "# Problème de string\n",
    "OH_X_train.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_valid.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_test.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_train.columns = OH_X_train.columns.astype(str)\n",
    "OH_X_valid.columns = OH_X_valid.columns.astype(str)\n",
    "OH_X_test.columns = OH_X_test.columns.astype(str)\n",
    "\n",
    "train_X = OH_X_train\n",
    "val_X = OH_X_valid\n",
    "test_X = OH_X_test\n",
    "X_entier = pd.concat([train_X, val_X])\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(train_X, train_y)\n",
    "\n",
    "mi_scores = make_mi_scores(X_entier, y)\n",
    "\n",
    "verylowMI = list(mi_scores[mi_scores<0.0001].index)\n",
    "lowMI = list(mi_scores[(mi_scores>=0.0001)&(mi_scores<0.001)].index)\n",
    "mediumMI = list(mi_scores[(mi_scores>=0.001)&(mi_scores<0.01)].index)\n",
    "highMI = list(mi_scores[mi_scores>=0.01].index)\n",
    "\n",
    "\n",
    "#train_X.drop(verylowMI, inplace=True, axis=1)\n",
    "#val_X.drop(verylowMI, inplace=True, axis=1)\n",
    "#test_X.drop(verylowMI, inplace=True, axis=1)\n",
    "#X_entier.drop(verylowMI, inplace=True, axis=1)\n",
    "\n",
    "SMOTERes = comparemodels(X_res, y_res, val_X, test_X, \"SMOTE\", unbalanced = False)\n",
    "SMOTERes[\"PublicScore\"] = [np.nan, 0.709677419, 0.358974358] #ici voit que le RandomForest est mieux\n",
    "SMOTERes[\"PrivateScore\"] = [np.nan, 0.686567164, 0.376068376]  \n",
    "SMOTERes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb6650c6",
   "metadata": {},
   "source": [
    "# Compare result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "78eddab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>The referencemax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 16:29:46.815175</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>0.857566</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.661017</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.857900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>The referencen_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:29:47.996356</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.843373</td>\n",
       "      <td>0.019592</td>\n",
       "      <td>0.843655</td>\n",
       "      <td>0.690909</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.843995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>The referencescale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 16:29:49.487206</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>0.871874</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.676923</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.872421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest ClassifierWeighted500</td>\n",
       "      <td>The referencen_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:29:50.689128</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.862324</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>0.863034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest ClassifierWeighted22</td>\n",
       "      <td>The referencen_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:29:51.854001</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.862324</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.654867</td>\n",
       "      <td>[0.703703703]</td>\n",
       "      <td>[0.654867256]</td>\n",
       "      <td>0.863034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>The referenceupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 16:29:54.212174</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.022606</td>\n",
       "      <td>0.824649</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.637168</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.825239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>The referenceundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 16:29:56.454271</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.022606</td>\n",
       "      <td>0.824649</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.825239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Delete very low MImax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 16:30:13.941221</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.013564</td>\n",
       "      <td>0.881780</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.661017</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.882409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Delete very low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:15.122144</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.021099</td>\n",
       "      <td>0.838969</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.839697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Delete very low MIscale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 16:30:16.312527</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.891566</td>\n",
       "      <td>0.013564</td>\n",
       "      <td>0.891963</td>\n",
       "      <td>0.711864</td>\n",
       "      <td>0.715447</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.892249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest ClassifierWeighted500</td>\n",
       "      <td>Delete very low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:17.497220</td>\n",
       "      <td>0.760870</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.024113</td>\n",
       "      <td>0.815615</td>\n",
       "      <td>0.654545</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>0.816359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest ClassifierWeighted22</td>\n",
       "      <td>Delete very low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:18.625953</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.025621</td>\n",
       "      <td>0.801037</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.647619</td>\n",
       "      <td>[0.703703703]</td>\n",
       "      <td>[0.654867256]</td>\n",
       "      <td>0.801648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>Delete very low MIupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 16:30:21.059364</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.030142</td>\n",
       "      <td>0.775535</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.776649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>Delete very low MIundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 16:30:23.314014</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.030142</td>\n",
       "      <td>0.775535</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.776649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Delete low MImax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 16:30:23.482611</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.157730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.199660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Delete low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:24.429001</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.051241</td>\n",
       "      <td>0.495474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.498927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Delete low MIscale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 16:30:25.364763</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.495413</td>\n",
       "      <td>0.082890</td>\n",
       "      <td>0.512908</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.518656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest ClassifierWeighted500</td>\n",
       "      <td>Delete low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:26.329033</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.507463</td>\n",
       "      <td>0.049734</td>\n",
       "      <td>0.516643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>0.519684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest ClassifierWeighted22</td>\n",
       "      <td>Delete low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:27.271725</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.048227</td>\n",
       "      <td>0.526526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.703703703]</td>\n",
       "      <td>[0.654867256]</td>\n",
       "      <td>0.530131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>Delete low MIupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 16:30:29.422086</td>\n",
       "      <td>0.358209</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.448598</td>\n",
       "      <td>0.088919</td>\n",
       "      <td>0.462470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.467319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>Delete low MIundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 16:30:31.531002</td>\n",
       "      <td>0.358209</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.448598</td>\n",
       "      <td>0.088919</td>\n",
       "      <td>0.462470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.467319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Delete medium MImax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 16:30:31.663343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Delete medium MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:32.095585</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Delete medium MIscale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 16:30:32.543177</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.162791</td>\n",
       "      <td>0.108511</td>\n",
       "      <td>0.161685</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.162913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest ClassifierWeighted500</td>\n",
       "      <td>Delete medium MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:33.010695</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest ClassifierWeighted22</td>\n",
       "      <td>Delete medium MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:33.443986</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.703703703]</td>\n",
       "      <td>[0.654867256]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>Delete medium MIupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 16:30:34.208445</td>\n",
       "      <td>0.010398</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.020544</td>\n",
       "      <td>4.885998</td>\n",
       "      <td>0.084977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.241480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>Delete medium MIundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 16:30:34.949979</td>\n",
       "      <td>0.010398</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.020544</td>\n",
       "      <td>4.885998</td>\n",
       "      <td>0.084977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.241480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Kmeans UnderSamplingmax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 16:31:00.117654</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.371584</td>\n",
       "      <td>0.979557</td>\n",
       "      <td>0.006575</td>\n",
       "      <td>0.006863</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.987512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Kmeans UnderSamplingn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:31:00.285578</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.114752</td>\n",
       "      <td>0.938324</td>\n",
       "      <td>0.007513</td>\n",
       "      <td>0.007795</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.961903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Kmeans UnderSamplingon balanced data</td>\n",
       "      <td>2023-05-07 16:31:00.404309</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.114752</td>\n",
       "      <td>0.938324</td>\n",
       "      <td>0.092764</td>\n",
       "      <td>0.096565</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.961903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>SMOTEmax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 16:31:18.853308</td>\n",
       "      <td>0.113372</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.203125</td>\n",
       "      <td>0.461171</td>\n",
       "      <td>0.330225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.405431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>SMOTEn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:31:22.707671</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.027128</td>\n",
       "      <td>0.804629</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.686567</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.806157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>SMOTEon balanced data</td>\n",
       "      <td>2023-05-07 16:31:25.958940</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.862324</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.376068</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.863034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Model  \\\n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  Random Forest ClassifierWeighted500   \n",
       "4   Random Forest ClassifierWeighted22   \n",
       "5  RandomForestClassifierUpperSampling   \n",
       "6  RandomForestClassifierUnderSampling   \n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  Random Forest ClassifierWeighted500   \n",
       "4   Random Forest ClassifierWeighted22   \n",
       "5  RandomForestClassifierUpperSampling   \n",
       "6  RandomForestClassifierUnderSampling   \n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  Random Forest ClassifierWeighted500   \n",
       "4   Random Forest ClassifierWeighted22   \n",
       "5  RandomForestClassifierUpperSampling   \n",
       "6  RandomForestClassifierUnderSampling   \n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  Random Forest ClassifierWeighted500   \n",
       "4   Random Forest ClassifierWeighted22   \n",
       "5  RandomForestClassifierUpperSampling   \n",
       "6  RandomForestClassifierUnderSampling   \n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "\n",
       "                                                            Description  \\\n",
       "0                   The referencemax_leaf_nodes : 6 + with date columns   \n",
       "1                              The referencen_estimators : 36 + Entropy   \n",
       "2                                    The referencescale_pos_weight = 22   \n",
       "3                              The referencen_estimators : 36 + Entropy   \n",
       "4                              The referencen_estimators : 36 + Entropy   \n",
       "5          The referenceupsampled, n_estimators=36, criterion = entropy   \n",
       "6       The referenceundersampled, n_estimators=36, criterion = entropy   \n",
       "0              Delete very low MImax_leaf_nodes : 6 + with date columns   \n",
       "1                         Delete very low MIn_estimators : 36 + Entropy   \n",
       "2                               Delete very low MIscale_pos_weight = 22   \n",
       "3                         Delete very low MIn_estimators : 36 + Entropy   \n",
       "4                         Delete very low MIn_estimators : 36 + Entropy   \n",
       "5     Delete very low MIupsampled, n_estimators=36, criterion = entropy   \n",
       "6  Delete very low MIundersampled, n_estimators=36, criterion = entropy   \n",
       "0                   Delete low MImax_leaf_nodes : 6 + with date columns   \n",
       "1                              Delete low MIn_estimators : 36 + Entropy   \n",
       "2                                    Delete low MIscale_pos_weight = 22   \n",
       "3                              Delete low MIn_estimators : 36 + Entropy   \n",
       "4                              Delete low MIn_estimators : 36 + Entropy   \n",
       "5          Delete low MIupsampled, n_estimators=36, criterion = entropy   \n",
       "6       Delete low MIundersampled, n_estimators=36, criterion = entropy   \n",
       "0                Delete medium MImax_leaf_nodes : 6 + with date columns   \n",
       "1                           Delete medium MIn_estimators : 36 + Entropy   \n",
       "2                                 Delete medium MIscale_pos_weight = 22   \n",
       "3                           Delete medium MIn_estimators : 36 + Entropy   \n",
       "4                           Delete medium MIn_estimators : 36 + Entropy   \n",
       "5       Delete medium MIupsampled, n_estimators=36, criterion = entropy   \n",
       "6    Delete medium MIundersampled, n_estimators=36, criterion = entropy   \n",
       "0            Kmeans UnderSamplingmax_leaf_nodes : 6 + with date columns   \n",
       "1                       Kmeans UnderSamplingn_estimators : 36 + Entropy   \n",
       "2                                  Kmeans UnderSamplingon balanced data   \n",
       "0                           SMOTEmax_leaf_nodes : 6 + with date columns   \n",
       "1                                      SMOTEn_estimators : 36 + Entropy   \n",
       "2                                                 SMOTEon balanced data   \n",
       "\n",
       "                        Date  Precision  Recall  F1-score   LogLoss       Mcc  \\\n",
       "0 2023-05-07 16:29:46.815175   0.891892   0.825  0.857143  0.016578  0.857566   \n",
       "1 2023-05-07 16:29:47.996356   0.813953   0.875  0.843373  0.019592  0.843655   \n",
       "2 2023-05-07 16:29:49.487206   0.822222   0.925  0.870588  0.016578  0.871874   \n",
       "3 2023-05-07 16:29:50.689128   0.804348   0.925  0.860465  0.018085  0.862324   \n",
       "4 2023-05-07 16:29:51.854001   0.804348   0.925  0.860465  0.018085  0.862324   \n",
       "5 2023-05-07 16:29:54.212174   0.777778   0.875  0.823529  0.022606  0.824649   \n",
       "6 2023-05-07 16:29:56.454271   0.777778   0.875  0.823529  0.022606  0.824649   \n",
       "0 2023-05-07 16:30:13.941221   0.942857   0.825  0.880000  0.013564  0.881780   \n",
       "1 2023-05-07 16:30:15.122144   0.782609   0.900  0.837209  0.021099  0.838969   \n",
       "2 2023-05-07 16:30:16.312527   0.860465   0.925  0.891566  0.013564  0.891963   \n",
       "3 2023-05-07 16:30:17.497220   0.760870   0.875  0.813953  0.024113  0.815615   \n",
       "4 2023-05-07 16:30:18.625953   0.755556   0.850  0.800000  0.025621  0.801037   \n",
       "5 2023-05-07 16:30:21.059364   0.708333   0.850  0.772727  0.030142  0.775535   \n",
       "6 2023-05-07 16:30:23.314014   0.708333   0.850  0.772727  0.030142  0.775535   \n",
       "0 2023-05-07 16:30:23.482611   0.500000   0.050  0.090909  0.060284  0.157730   \n",
       "1 2023-05-07 16:30:24.429001   0.615385   0.400  0.484848  0.051241  0.495474   \n",
       "2 2023-05-07 16:30:25.364763   0.391304   0.675  0.495413  0.082890  0.512908   \n",
       "3 2023-05-07 16:30:26.329033   0.629630   0.425  0.507463  0.049734  0.516643   \n",
       "4 2023-05-07 16:30:27.271725   0.653846   0.425  0.515152  0.048227  0.526526   \n",
       "5 2023-05-07 16:30:29.422086   0.358209   0.600  0.448598  0.088919  0.462470   \n",
       "6 2023-05-07 16:30:31.531002   0.358209   0.600  0.448598  0.088919  0.462470   \n",
       "0 2023-05-07 16:30:31.663343        NaN   0.000       NaN  0.060284  0.000000   \n",
       "1 2023-05-07 16:30:32.095585        NaN   0.000       NaN  0.060284  0.000000   \n",
       "2 2023-05-07 16:30:32.543177   0.152174   0.175  0.162791  0.108511  0.161685   \n",
       "3 2023-05-07 16:30:33.010695        NaN   0.000       NaN  0.060284  0.000000   \n",
       "4 2023-05-07 16:30:33.443986        NaN   0.000       NaN  0.060284  0.000000   \n",
       "5 2023-05-07 16:30:34.208445   0.010398   0.850  0.020544  4.885998  0.084977   \n",
       "6 2023-05-07 16:30:34.949979   0.010398   0.850  0.020544  4.885998  0.084977   \n",
       "0 2023-05-07 16:31:00.117654   0.980392   1.000  0.990099  0.371584  0.979557   \n",
       "1 2023-05-07 16:31:00.285578   0.979592   0.960  0.969697  1.114752  0.938324   \n",
       "2 2023-05-07 16:31:00.404309   0.979592   0.960  0.969697  1.114752  0.938324   \n",
       "0 2023-05-07 16:31:18.853308   0.113372   0.975  0.203125  0.461171  0.330225   \n",
       "1 2023-05-07 16:31:22.707671   0.720000   0.900  0.800000  0.027128  0.804629   \n",
       "2 2023-05-07 16:31:25.958940   0.804348   0.925  0.860465  0.018085  0.862324   \n",
       "\n",
       "   PublicScore  PrivateScore                           OldPublicScore  \\\n",
       "0     0.666667      0.661017  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1     0.690909      0.649123   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2     0.677419      0.676923  [0.677419354, 0.711864406, 0.092764378]   \n",
       "3     0.678571      0.666667                            [0.678571428]   \n",
       "4     0.703704      0.654867                            [0.703703703]   \n",
       "5     0.678571      0.637168               [0.678571428, 0.642857142]   \n",
       "6     0.549020      0.480769               [0.549019607, 0.642857142]   \n",
       "0     0.666667      0.661017  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1     0.666667      0.649123   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2     0.711864      0.715447  [0.677419354, 0.711864406, 0.092764378]   \n",
       "3     0.654545      0.666667                            [0.678571428]   \n",
       "4     0.595745      0.647619                            [0.703703703]   \n",
       "5     0.642857      0.620690               [0.678571428, 0.642857142]   \n",
       "6     0.642857      0.620690               [0.549019607, 0.642857142]   \n",
       "0          NaN           NaN  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1          NaN           NaN   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2          NaN           NaN  [0.677419354, 0.711864406, 0.092764378]   \n",
       "3          NaN           NaN                            [0.678571428]   \n",
       "4          NaN           NaN                            [0.703703703]   \n",
       "5          NaN           NaN               [0.678571428, 0.642857142]   \n",
       "6          NaN           NaN               [0.549019607, 0.642857142]   \n",
       "0          NaN           NaN  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1          NaN           NaN   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2          NaN           NaN  [0.677419354, 0.711864406, 0.092764378]   \n",
       "3          NaN           NaN                            [0.678571428]   \n",
       "4          NaN           NaN                            [0.703703703]   \n",
       "5          NaN           NaN               [0.678571428, 0.642857142]   \n",
       "6          NaN           NaN               [0.549019607, 0.642857142]   \n",
       "0     0.006575      0.006863  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1     0.007513      0.007795   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2     0.092764      0.096565  [0.677419354, 0.711864406, 0.092764378]   \n",
       "0          NaN           NaN  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1     0.709677      0.686567   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2     0.358974      0.376068  [0.677419354, 0.711864406, 0.092764378]   \n",
       "\n",
       "                           OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.857900  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.843995  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.872421  \n",
       "3                            [0.666666666]        0.863034  \n",
       "4                            [0.654867256]        0.863034  \n",
       "5               [0.637168141, 0.620689655]        0.825239  \n",
       "6                [0.48076923, 0.620689655]        0.825239  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.882409  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.839697  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.892249  \n",
       "3                            [0.666666666]        0.816359  \n",
       "4                            [0.654867256]        0.801648  \n",
       "5               [0.637168141, 0.620689655]        0.776649  \n",
       "6                [0.48076923, 0.620689655]        0.776649  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.199660  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.498927  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.518656  \n",
       "3                            [0.666666666]        0.519684  \n",
       "4                            [0.654867256]        0.530131  \n",
       "5               [0.637168141, 0.620689655]        0.467319  \n",
       "6                [0.48076923, 0.620689655]        0.467319  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.000000  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.000000  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.162913  \n",
       "3                            [0.666666666]        0.000000  \n",
       "4                            [0.654867256]        0.000000  \n",
       "5               [0.637168141, 0.620689655]        0.241480  \n",
       "6                [0.48076923, 0.620689655]        0.241480  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.987512  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.961903  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.961903  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.405431  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.806157  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.863034  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfResult = pd.concat([referenceresult, withoutverylowMI, withoutlowMI, withoutmediumMI, kmeansundersampling, SMOTERes])\n",
    "dfResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d7c6ddd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>The referencemax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 16:31:18.853308</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.461171</td>\n",
       "      <td>0.979557</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.661017</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.987512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>The referencen_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:31:22.707671</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.114752</td>\n",
       "      <td>0.938324</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.686567</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.961903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest ClassifierWeighted22</th>\n",
       "      <td>The referencen_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:33.443986</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.862324</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.654867</td>\n",
       "      <td>[0.703703703]</td>\n",
       "      <td>[0.654867256]</td>\n",
       "      <td>0.863034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest ClassifierWeighted500</th>\n",
       "      <td>The referencen_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:33.010695</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.862324</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>0.863034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifierUnderSampling</th>\n",
       "      <td>The referenceundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 16:30:34.949979</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>4.885998</td>\n",
       "      <td>0.824649</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.825239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifierUpperSampling</th>\n",
       "      <td>The referenceupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 16:30:34.208445</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>4.885998</td>\n",
       "      <td>0.824649</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.637168</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.825239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>The referencescale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 16:31:25.958940</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.114752</td>\n",
       "      <td>0.938324</td>\n",
       "      <td>0.711864</td>\n",
       "      <td>0.715447</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.961903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                         Description  \\\n",
       "Model                                                                                                  \n",
       "DecisionTreeClassifier                           The referencemax_leaf_nodes : 6 + with date columns   \n",
       "Random Forest Classifier                                    The referencen_estimators : 36 + Entropy   \n",
       "Random Forest ClassifierWeighted22                          The referencen_estimators : 36 + Entropy   \n",
       "Random Forest ClassifierWeighted500                         The referencen_estimators : 36 + Entropy   \n",
       "RandomForestClassifierUnderSampling  The referenceundersampled, n_estimators=36, criterion = entropy   \n",
       "RandomForestClassifierUpperSampling     The referenceupsampled, n_estimators=36, criterion = entropy   \n",
       "XGBClassifier                                                     The referencescale_pos_weight = 22   \n",
       "\n",
       "                                                          Date  Precision  \\\n",
       "Model                                                                       \n",
       "DecisionTreeClassifier              2023-05-07 16:31:18.853308   0.980392   \n",
       "Random Forest Classifier            2023-05-07 16:31:22.707671   0.979592   \n",
       "Random Forest ClassifierWeighted22  2023-05-07 16:30:33.443986   0.804348   \n",
       "Random Forest ClassifierWeighted500 2023-05-07 16:30:33.010695   0.804348   \n",
       "RandomForestClassifierUnderSampling 2023-05-07 16:30:34.949979   0.777778   \n",
       "RandomForestClassifierUpperSampling 2023-05-07 16:30:34.208445   0.777778   \n",
       "XGBClassifier                       2023-05-07 16:31:25.958940   0.979592   \n",
       "\n",
       "                                     Recall  F1-score   LogLoss       Mcc  \\\n",
       "Model                                                                       \n",
       "DecisionTreeClassifier                1.000  0.990099  0.461171  0.979557   \n",
       "Random Forest Classifier              0.960  0.969697  1.114752  0.938324   \n",
       "Random Forest ClassifierWeighted22    0.925  0.860465  0.060284  0.862324   \n",
       "Random Forest ClassifierWeighted500   0.925  0.860465  0.060284  0.862324   \n",
       "RandomForestClassifierUnderSampling   0.875  0.823529  4.885998  0.824649   \n",
       "RandomForestClassifierUpperSampling   0.875  0.823529  4.885998  0.824649   \n",
       "XGBClassifier                         0.960  0.969697  1.114752  0.938324   \n",
       "\n",
       "                                     PublicScore  PrivateScore  \\\n",
       "Model                                                            \n",
       "DecisionTreeClassifier                  0.666667      0.661017   \n",
       "Random Forest Classifier                0.709677      0.686567   \n",
       "Random Forest ClassifierWeighted22      0.703704      0.654867   \n",
       "Random Forest ClassifierWeighted500     0.678571      0.666667   \n",
       "RandomForestClassifierUnderSampling     0.642857      0.620690   \n",
       "RandomForestClassifierUpperSampling     0.678571      0.637168   \n",
       "XGBClassifier                           0.711864      0.715447   \n",
       "\n",
       "                                                              OldPublicScore  \\\n",
       "Model                                                                          \n",
       "DecisionTreeClassifier               [0.666666666, 0.666666666, 0.006575486]   \n",
       "Random Forest Classifier              [0.69090909, 0.666666666, 0.007513148]   \n",
       "Random Forest ClassifierWeighted22                             [0.703703703]   \n",
       "Random Forest ClassifierWeighted500                            [0.678571428]   \n",
       "RandomForestClassifierUnderSampling               [0.549019607, 0.642857142]   \n",
       "RandomForestClassifierUpperSampling               [0.678571428, 0.642857142]   \n",
       "XGBClassifier                        [0.677419354, 0.711864406, 0.092764378]   \n",
       "\n",
       "                                                             OldPrivateScore  \\\n",
       "Model                                                                          \n",
       "DecisionTreeClassifier               [0.661016949, 0.661016949, 0.006863327]   \n",
       "Random Forest Classifier             [0.649122807, 0.649122807, 0.007794933]   \n",
       "Random Forest ClassifierWeighted22                             [0.654867256]   \n",
       "Random Forest ClassifierWeighted500                            [0.666666666]   \n",
       "RandomForestClassifierUnderSampling                [0.48076923, 0.620689655]   \n",
       "RandomForestClassifierUpperSampling               [0.637168141, 0.620689655]   \n",
       "XGBClassifier                        [0.676923076, 0.715447154, 0.096564531]   \n",
       "\n",
       "                                     MeanOurMetrics  \n",
       "Model                                                \n",
       "DecisionTreeClassifier                     0.987512  \n",
       "Random Forest Classifier                   0.961903  \n",
       "Random Forest ClassifierWeighted22         0.863034  \n",
       "Random Forest ClassifierWeighted500        0.863034  \n",
       "RandomForestClassifierUnderSampling        0.825239  \n",
       "RandomForestClassifierUpperSampling        0.825239  \n",
       "XGBClassifier                              0.961903  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfResult.groupby(\"Model\").max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e425a7b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can only compare identically-labeled Series objects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dfResult[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDescription\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mloc[[\u001b[43mdfResult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPublicScore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdfResult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mModel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPublicScore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m]]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\AILab-ECAM4\\lib\\site-packages\\pandas\\core\\ops\\common.py:72\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     70\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\AILab-ECAM4\\lib\\site-packages\\pandas\\core\\arraylike.py:42\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\AILab-ECAM4\\lib\\site-packages\\pandas\\core\\series.py:6237\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   6234\u001b[0m res_name \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mget_op_result_name(\u001b[38;5;28mself\u001b[39m, other)\n\u001b[0;32m   6236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, Series) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indexed_same(other):\n\u001b[1;32m-> 6237\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only compare identically-labeled Series objects\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6239\u001b[0m lvalues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   6240\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mValueError\u001b[0m: Can only compare identically-labeled Series objects"
     ]
    }
   ],
   "source": [
    "dfResult[[\"Description\"]].loc[[dfResult['PublicScore'] == dfResult.groupby([\"Model\"])['PublicScore'].max()]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f71d0234",
   "metadata": {},
   "source": [
    "# Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3ba35bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>La basemax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-06 20:37:01.701978</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>0.857566</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>[0.661016949]</td>\n",
       "      <td>0.857900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>La basen_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-06 20:37:02.891559</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.019592</td>\n",
       "      <td>0.848262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909]</td>\n",
       "      <td>[0.649122807]</td>\n",
       "      <td>0.848830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>La basescale_pos_weight = 22</td>\n",
       "      <td>2023-05-06 20:37:04.316049</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.881747</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354]</td>\n",
       "      <td>[0.676923076]</td>\n",
       "      <td>0.882152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>La baseupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-06 20:37:06.774426</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.022606</td>\n",
       "      <td>0.829975</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.637168141]</td>\n",
       "      <td>0.830880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>La baseundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-06 20:37:09.025865</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.022606</td>\n",
       "      <td>0.829975</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.549019607]</td>\n",
       "      <td>[0.48076923]</td>\n",
       "      <td>0.830880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Kmeans UnderSamplingn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:31:00.285578</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.114752</td>\n",
       "      <td>0.938324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.961903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Kmeans UnderSamplingon balanced data</td>\n",
       "      <td>2023-05-07 16:31:00.404309</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.114752</td>\n",
       "      <td>0.938324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.961903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>SMOTEmax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 16:31:18.853308</td>\n",
       "      <td>0.113372</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.203125</td>\n",
       "      <td>0.461171</td>\n",
       "      <td>0.330225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.405431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>SMOTEn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:31:22.707671</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.027128</td>\n",
       "      <td>0.804629</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.806157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>SMOTEon balanced data</td>\n",
       "      <td>2023-05-07 16:31:25.958940</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.862324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.863034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Model  \\\n",
       "0               Decision Tree Classifier   \n",
       "1               Random Forest Classifier   \n",
       "2                          XGBClassifier   \n",
       "3    RandomForestClassifierUpperSampling   \n",
       "4    RandomForestClassifierUnderSampling   \n",
       "..                                   ...   \n",
       "248             Random Forest Classifier   \n",
       "249                        XGBClassifier   \n",
       "250               DecisionTreeClassifier   \n",
       "251             Random Forest Classifier   \n",
       "252                        XGBClassifier   \n",
       "\n",
       "                                                   Description  \\\n",
       "0                La basemax_leaf_nodes : 6 + with date columns   \n",
       "1                           La basen_estimators : 36 + Entropy   \n",
       "2                                 La basescale_pos_weight = 22   \n",
       "3       La baseupsampled, n_estimators=36, criterion = entropy   \n",
       "4    La baseundersampled, n_estimators=36, criterion = entropy   \n",
       "..                                                         ...   \n",
       "248            Kmeans UnderSamplingn_estimators : 36 + Entropy   \n",
       "249                       Kmeans UnderSamplingon balanced data   \n",
       "250                SMOTEmax_leaf_nodes : 6 + with date columns   \n",
       "251                           SMOTEn_estimators : 36 + Entropy   \n",
       "252                                      SMOTEon balanced data   \n",
       "\n",
       "                           Date  Precision  Recall  F1-score   LogLoss  \\\n",
       "0    2023-05-06 20:37:01.701978   0.891892   0.825  0.857143  0.016578   \n",
       "1    2023-05-06 20:37:02.891559   0.800000   0.900  0.847059  0.019592   \n",
       "2    2023-05-06 20:37:04.316049   0.840909   0.925  0.880952  0.015071   \n",
       "3    2023-05-06 20:37:06.774426   0.765957   0.900  0.827586  0.022606   \n",
       "4    2023-05-06 20:37:09.025865   0.765957   0.900  0.827586  0.022606   \n",
       "..                          ...        ...     ...       ...       ...   \n",
       "248  2023-05-07 16:31:00.285578   0.979592   0.960  0.969697  1.114752   \n",
       "249  2023-05-07 16:31:00.404309   0.979592   0.960  0.969697  1.114752   \n",
       "250  2023-05-07 16:31:18.853308   0.113372   0.975  0.203125  0.461171   \n",
       "251  2023-05-07 16:31:22.707671   0.720000   0.900  0.800000  0.027128   \n",
       "252  2023-05-07 16:31:25.958940   0.804348   0.925  0.860465  0.018085   \n",
       "\n",
       "          Mcc  PublicScore  PrivateScore  \\\n",
       "0    0.857566          NaN           NaN   \n",
       "1    0.848262          NaN           NaN   \n",
       "2    0.881747          NaN           NaN   \n",
       "3    0.829975          NaN           NaN   \n",
       "4    0.829975          NaN           NaN   \n",
       "..        ...          ...           ...   \n",
       "248  0.938324          NaN           NaN   \n",
       "249  0.938324          NaN           NaN   \n",
       "250  0.330225          NaN           NaN   \n",
       "251  0.804629          NaN           NaN   \n",
       "252  0.862324          NaN           NaN   \n",
       "\n",
       "                              OldPublicScore  \\\n",
       "0                              [0.666666666]   \n",
       "1                               [0.69090909]   \n",
       "2                              [0.677419354]   \n",
       "3                              [0.678571428]   \n",
       "4                              [0.549019607]   \n",
       "..                                       ...   \n",
       "248   [0.69090909, 0.666666666, 0.007513148]   \n",
       "249  [0.677419354, 0.711864406, 0.092764378]   \n",
       "250  [0.666666666, 0.666666666, 0.006575486]   \n",
       "251   [0.69090909, 0.666666666, 0.007513148]   \n",
       "252  [0.677419354, 0.711864406, 0.092764378]   \n",
       "\n",
       "                             OldPrivateScore  MeanOurMetrics  \n",
       "0                              [0.661016949]        0.857900  \n",
       "1                              [0.649122807]        0.848830  \n",
       "2                              [0.676923076]        0.882152  \n",
       "3                              [0.637168141]        0.830880  \n",
       "4                               [0.48076923]        0.830880  \n",
       "..                                       ...             ...  \n",
       "248  [0.649122807, 0.649122807, 0.007794933]        0.961903  \n",
       "249  [0.676923076, 0.715447154, 0.096564531]        0.961903  \n",
       "250  [0.661016949, 0.661016949, 0.006863327]        0.405431  \n",
       "251  [0.649122807, 0.649122807, 0.007794933]        0.806157  \n",
       "252  [0.676923076, 0.715447154, 0.096564531]        0.863034  \n",
       "\n",
       "[253 rows x 13 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfresult  = pd.read_csv(\"output/resultatsTestEverything.csv\")\n",
    "dfresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b9a49624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les meilleurs résultat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarah\\AppData\\Local\\Temp\\ipykernel_2988\\2367281751.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  dfresult.groupby(['Model'])['Precision','Recall','F1-score','LogLoss','MeanOurMetrics'].max()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classifier</th>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.882409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.461171</td>\n",
       "      <td>0.987512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.114752</td>\n",
       "      <td>0.961903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest ClassifierWeighted</th>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.863034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest ClassifierWeighted22</th>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.863034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest ClassifierWeighted500</th>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.863034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifierUnderSampling</th>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>4.923675</td>\n",
       "      <td>0.839697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifierUpperSampling</th>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>4.923675</td>\n",
       "      <td>0.839697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.114752</td>\n",
       "      <td>0.961903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Precision  Recall  F1-score   LogLoss  \\\n",
       "Model                                                                        \n",
       "Decision Tree Classifier              0.942857   0.825  0.880000  0.060284   \n",
       "DecisionTreeClassifier                0.980392   1.000  0.990099  0.461171   \n",
       "Random Forest Classifier              0.979592   0.960  0.969697  1.114752   \n",
       "Random Forest ClassifierWeighted      0.804348   0.925  0.860465  0.018085   \n",
       "Random Forest ClassifierWeighted22    0.823529   0.925  0.860465  0.060284   \n",
       "Random Forest ClassifierWeighted500   0.804348   0.925  0.860465  0.060284   \n",
       "RandomForestClassifierUnderSampling   0.782609   0.900  0.837209  4.923675   \n",
       "RandomForestClassifierUpperSampling   0.782609   0.900  0.837209  4.923675   \n",
       "XGBClassifier                         0.979592   0.960  0.969697  1.114752   \n",
       "\n",
       "                                     MeanOurMetrics  \n",
       "Model                                                \n",
       "Decision Tree Classifier                   0.882409  \n",
       "DecisionTreeClassifier                     0.987512  \n",
       "Random Forest Classifier                   0.961903  \n",
       "Random Forest ClassifierWeighted           0.863034  \n",
       "Random Forest ClassifierWeighted22         0.863034  \n",
       "Random Forest ClassifierWeighted500        0.863034  \n",
       "RandomForestClassifierUnderSampling        0.839697  \n",
       "RandomForestClassifierUpperSampling        0.839697  \n",
       "XGBClassifier                              0.961903  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Les meilleurs résultat\")\n",
    "dfresult.groupby(['Model'])['Precision','Recall','F1-score','LogLoss','MeanOurMetrics'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6e794338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les pire résultat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarah\\AppData\\Local\\Temp\\ipykernel_2988\\2101499374.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  dfresult.groupby(['Model'])['Precision','Recall','F1-score','LogLoss','MeanOurMetrics'].min()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classifier</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.013564</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.113372</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.013564</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.019592</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest ClassifierWeighted</th>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.863034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest ClassifierWeighted22</th>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest ClassifierWeighted500</th>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifierUnderSampling</th>\n",
       "      <td>0.010398</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.020544</td>\n",
       "      <td>0.021099</td>\n",
       "      <td>0.241480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifierUpperSampling</th>\n",
       "      <td>0.010398</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.020544</td>\n",
       "      <td>0.021099</td>\n",
       "      <td>0.241480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.162791</td>\n",
       "      <td>0.013564</td>\n",
       "      <td>0.162913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Precision  Recall  F1-score   LogLoss  \\\n",
       "Model                                                                        \n",
       "Decision Tree Classifier              0.500000   0.000  0.090909  0.013564   \n",
       "DecisionTreeClassifier                0.113372   0.000  0.090909  0.013564   \n",
       "Random Forest Classifier              0.566667   0.000  0.484848  0.019592   \n",
       "Random Forest ClassifierWeighted      0.804348   0.925  0.860465  0.018085   \n",
       "Random Forest ClassifierWeighted22    0.653846   0.000  0.491228  0.018085   \n",
       "Random Forest ClassifierWeighted500   0.629630   0.000  0.482759  0.018085   \n",
       "RandomForestClassifierUnderSampling   0.010398   0.400  0.020544  0.021099   \n",
       "RandomForestClassifierUpperSampling   0.010398   0.400  0.020544  0.021099   \n",
       "XGBClassifier                         0.152174   0.175  0.162791  0.013564   \n",
       "\n",
       "                                     MeanOurMetrics  \n",
       "Model                                                \n",
       "Decision Tree Classifier                   0.000000  \n",
       "DecisionTreeClassifier                     0.000000  \n",
       "Random Forest Classifier                   0.000000  \n",
       "Random Forest ClassifierWeighted           0.863034  \n",
       "Random Forest ClassifierWeighted22         0.000000  \n",
       "Random Forest ClassifierWeighted500        0.000000  \n",
       "RandomForestClassifierUnderSampling        0.241480  \n",
       "RandomForestClassifierUpperSampling        0.241480  \n",
       "XGBClassifier                              0.162913  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Les pire résultat\")\n",
    "dfresult.groupby(['Model'])['Precision','Recall','F1-score','LogLoss','MeanOurMetrics'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "596a8536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_undersampled"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
