{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "efcbf836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import resample\n",
    "from sklearn.cluster import KMeans \n",
    "import datetime as dt\n",
    "from math import ceil, sqrt\n",
    "from Utils import *\n",
    "pd.set_option('max_colwidth', None)\n",
    "from EvaluationMetric import *\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5bae6abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparemodels(train_X, train_y, val_X, test_X, generaldescription, unbalanced = True):\n",
    "    res = []\n",
    "\n",
    "    model1 = DecisionTreeClassifier(max_leaf_nodes= 6, random_state=1)\n",
    "    model1.fit(train_X, train_y)\n",
    "    preds_val1 = model1.predict(val_X)\n",
    "    model_test1 = model1.predict(test_X)\n",
    "    description = generaldescription+\"max_leaf_nodes : 6 + with date columns\"\n",
    "    metrics1 = listmetrics(val_y, preds_val1, \"DecisionTreeClassifier\", description)\n",
    "    m1Public = [0.666666666, 0.666666666, 0.006575486]\n",
    "    m1Private = [0.661016949, 0.661016949, 0.006863327]\n",
    "    res.append(metrics1)\n",
    "    df1 = getscoreforcsv(index_val, model_test1, name_file = \"TreeClass5leaf.csv\")\n",
    "\n",
    "\n",
    "    model2 = RandomForestClassifier(n_estimators=36, criterion = 'entropy', random_state=1)\n",
    "    model2.fit(train_X, train_y)\n",
    "    preds_val2 = model2.predict(val_X)\n",
    "    model_test2 = model2.predict(test_X)\n",
    "    description = generaldescription+\"n_estimators : 36 + Entropy\"\n",
    "    metrics2 = listmetrics(val_y, preds_val2, \"Random Forest Classifier\", description)\n",
    "    m2Public = [0.690909090, 0.666666666, 0.007513148]\n",
    "    m2Private = [0.649122807, 0.649122807, 0.007794933]\n",
    "    res.append(metrics2)\n",
    "    df2 = getscoreforcsv(index_val, model_test2, name_file = \"RandomForestN36Entropy.csv\")\n",
    "\n",
    "\n",
    "    ##################ICi donne un 0.71 de scrore !!! mtn comprendre pq en diminuant les feature si bon score mais que pour lui !############\n",
    "    #Ne fonctionne pas bien quadn le training set est entier. \n",
    "    if (unbalanced) : \n",
    "        model2 = XGBClassifier(scale_pos_weight=22, random_state=1)\n",
    "        description = generaldescription+\"scale_pos_weight = 22\"\n",
    "    else : \n",
    "        model2 = XGBClassifier(random_state=1)\n",
    "        description = generaldescription+\"on balanced data\"\n",
    "    model2.fit(train_X, train_y)\n",
    "    preds_val2 = model2.predict(val_X)\n",
    "    model_test2 = model2.predict(test_X)\n",
    "    metrics2 = listmetrics(val_y, preds_val2, \"XGBClassifier\", description)\n",
    "    m3Public = [0.677419354, 0.711864406, 0.092764378]\n",
    "    m3Private = [0.676923076,  0.715447154, 0.096564531]\n",
    "    res.append(metrics2)\n",
    "    df2 = getscoreforcsv(index_val, model_test2, name_file = \"XGBClassifierW22.csv\")\n",
    "    \n",
    "    if (unbalanced) :\n",
    "        \n",
    "        model2 = RandomForestClassifier(n_estimators=36, criterion = 'entropy', class_weight = {0: 95469, 1 : 193}, random_state=1)\n",
    "        model2.fit(train_X, train_y)\n",
    "        preds_val2 = model2.predict(val_X)\n",
    "        model_test2 = model2.predict(test_X)\n",
    "        description = generaldescription+\"n_estimators : 36 + Entropy\"\n",
    "        metrics2 = listmetrics(val_y, preds_val2, \"Random Forest ClassifierWeighted500\", description)\n",
    "        m500Public = [0.678571428]\n",
    "        m500Private = [0.666666666]\n",
    "        res.append(metrics2)\n",
    "        df2 = getscoreforcsv(index_val, model_test2, name_file = \"RandomForestWeigthed500.csv\")\n",
    "\n",
    "        model2 = RandomForestClassifier(n_estimators=36, criterion = 'entropy', class_weight = {0: 22, 1 : 1}, random_state=1)\n",
    "        model2.fit(train_X, train_y)\n",
    "        preds_val2 = model2.predict(val_X)\n",
    "        model_test2 = model2.predict(test_X)\n",
    "        description = generaldescription+\"n_estimators : 36 + Entropy\"\n",
    "        metrics2 = listmetrics(val_y, preds_val2, \"Random Forest ClassifierWeighted22\", description)\n",
    "        m22Public = [0.703703703]\n",
    "        m22Private = [0.654867256]\n",
    "        res.append(metrics2)\n",
    "        df2 = getscoreforcsv(index_val, model_test2, name_file = \"RandomForestWeigthed22.csv\")\n",
    "\n",
    "        #oversamplesimple\n",
    "        X_con = pd.concat([train_X, train_y], axis=1) \n",
    "        not_fraud = X_con[X_con.FraudResult==0]\n",
    "        fraud = X_con[X_con.FraudResult==1]\n",
    "        fraud_upsampled = resample(fraud, replace=True, n_samples=len(not_fraud), # match number in majority class\n",
    "                                random_state=1) # reproducible results\n",
    "        upsampled = pd.concat([not_fraud, fraud_upsampled])\n",
    "        train_y_over_sampled = upsampled.FraudResult\n",
    "        train_X_over_sampled = upsampled.drop('FraudResult', axis=1)\n",
    "        upsampledmodel = RandomForestClassifier(n_estimators=36, criterion = 'entropy', random_state=1)\n",
    "        upsampledmodel.fit(train_X_over_sampled, train_y_over_sampled)\n",
    "        upsampled_pred = upsampledmodel.predict(val_X)\n",
    "        model_test = upsampledmodel.predict(OH_X_test)\n",
    "        description = generaldescription+\"upsampled, n_estimators=36, criterion = entropy\"\n",
    "        metrics = listmetrics(val_y, upsampled_pred, \"RandomForestClassifierUpperSampling\", description)\n",
    "        m4Public = [0.678571428, 0.642857142]\n",
    "        m4Private = [0.637168141, 0.620689655]\n",
    "        res.append(metrics)\n",
    "        df = getscoreforcsv(index_val, model_test, name_file = \"RandomForestClassifierUpSample.csv\")\n",
    "\n",
    "        #Undersampling\n",
    "        not_fraud_downsampled  = resample(not_fraud, replace=False, n_samples=len(fraud), # match number in minority  class\n",
    "                                random_state=1) # reproducible results\n",
    "        downsampled  = pd.concat([not_fraud_downsampled , fraud])\n",
    "        train_y_undersampled = downsampled.FraudResult\n",
    "        train_X_undersampled = downsampled.drop('FraudResult', axis=1)\n",
    "        undersampled = RandomForestClassifier(n_estimators=36, criterion = 'entropy', random_state=1)\n",
    "        undersampled.fit(train_X_over_sampled, train_y_over_sampled)\n",
    "        undersampled_pred = undersampled.predict(val_X)\n",
    "        model_test = undersampled.predict(OH_X_test)\n",
    "        description = generaldescription+\"undersampled, n_estimators=36, criterion = entropy\"\n",
    "        metrics = listmetrics(val_y, undersampled_pred, \"RandomForestClassifierUnderSampling\", description)\n",
    "        m5Public = [0.549019607, 0.642857142]\n",
    "        m5Private = [0.480769230, 0.620689655]\n",
    "        res.append(metrics)\n",
    "        df = getscoreforcsv(index_val, model_test, name_file = \"RandomForestClassifierUndersampled.csv\")\n",
    "        \n",
    "        loldPublics = [m1Public, m2Public, m3Public, m500Public,m22Public, m4Public, m5Public]\n",
    "        loldPrivate = [m1Private, m2Private, m3Private, m500Private, m22Private, m4Private, m5Private]\n",
    "        \n",
    "    else:\n",
    "        loldPublics = [m1Public, m2Public, m3Public]\n",
    "        loldPrivate = [m1Private, m2Private,  m3Private]\n",
    "        \n",
    "\n",
    "\n",
    "    dfres = listmetricsintodf(res)\n",
    "    dfres[\"OldPublicScore\"] = loldPublics\n",
    "    dfres[\"OldPrivateScore\"] = loldPrivate\n",
    "    dfres[\"MeanOurMetrics\"] = dfres[['Precision', 'Recall','F1-score','Mcc']].mean(axis=1)\n",
    "    dfres.to_csv('output/resultatsTestEverything.csv', mode='a',index=False,header = False) \n",
    "    return dfres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eab429b",
   "metadata": {},
   "source": [
    "# Test de different model with different Data Here\n",
    "## 1. The reference model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "73a9d70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>The referencemax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 16:29:46.815175</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>0.857566</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.661017</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.857900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>The referencen_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:29:47.996356</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.843373</td>\n",
       "      <td>0.019592</td>\n",
       "      <td>0.843655</td>\n",
       "      <td>0.690909</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.843995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>The referencescale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 16:29:49.487206</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>0.871874</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.676923</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.872421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest ClassifierWeighted500</td>\n",
       "      <td>The referencen_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:29:50.689128</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.862324</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>0.863034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest ClassifierWeighted22</td>\n",
       "      <td>The referencen_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:29:51.854001</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.862324</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.654867</td>\n",
       "      <td>[0.703703703]</td>\n",
       "      <td>[0.654867256]</td>\n",
       "      <td>0.863034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>The referenceupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 16:29:54.212174</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.022606</td>\n",
       "      <td>0.824649</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.637168</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.825239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>The referenceundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 16:29:56.454271</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.022606</td>\n",
       "      <td>0.824649</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.825239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Model  \\\n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  Random Forest ClassifierWeighted500   \n",
       "4   Random Forest ClassifierWeighted22   \n",
       "5  RandomForestClassifierUpperSampling   \n",
       "6  RandomForestClassifierUnderSampling   \n",
       "\n",
       "                                                       Description  \\\n",
       "0              The referencemax_leaf_nodes : 6 + with date columns   \n",
       "1                         The referencen_estimators : 36 + Entropy   \n",
       "2                               The referencescale_pos_weight = 22   \n",
       "3                         The referencen_estimators : 36 + Entropy   \n",
       "4                         The referencen_estimators : 36 + Entropy   \n",
       "5     The referenceupsampled, n_estimators=36, criterion = entropy   \n",
       "6  The referenceundersampled, n_estimators=36, criterion = entropy   \n",
       "\n",
       "                        Date  Precision  Recall  F1-score   LogLoss       Mcc  \\\n",
       "0 2023-05-07 16:29:46.815175   0.891892   0.825  0.857143  0.016578  0.857566   \n",
       "1 2023-05-07 16:29:47.996356   0.813953   0.875  0.843373  0.019592  0.843655   \n",
       "2 2023-05-07 16:29:49.487206   0.822222   0.925  0.870588  0.016578  0.871874   \n",
       "3 2023-05-07 16:29:50.689128   0.804348   0.925  0.860465  0.018085  0.862324   \n",
       "4 2023-05-07 16:29:51.854001   0.804348   0.925  0.860465  0.018085  0.862324   \n",
       "5 2023-05-07 16:29:54.212174   0.777778   0.875  0.823529  0.022606  0.824649   \n",
       "6 2023-05-07 16:29:56.454271   0.777778   0.875  0.823529  0.022606  0.824649   \n",
       "\n",
       "   PublicScore  PrivateScore                           OldPublicScore  \\\n",
       "0     0.666667      0.661017  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1     0.690909      0.649123   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2     0.677419      0.676923  [0.677419354, 0.711864406, 0.092764378]   \n",
       "3     0.678571      0.666667                            [0.678571428]   \n",
       "4     0.703704      0.654867                            [0.703703703]   \n",
       "5     0.678571      0.637168               [0.678571428, 0.642857142]   \n",
       "6     0.549020      0.480769               [0.549019607, 0.642857142]   \n",
       "\n",
       "                           OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.857900  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.843995  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.872421  \n",
       "3                            [0.666666666]        0.863034  \n",
       "4                            [0.654867256]        0.863034  \n",
       "5               [0.637168141, 0.620689655]        0.825239  \n",
       "6                [0.48076923, 0.620689655]        0.825239  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def_feature = pd.read_csv(\"input/Xente_Variable_Definitions.csv\")\n",
    "raw_data = pd.read_csv(\"input/training.csv\")\n",
    "X_test = pd.read_csv(\"input/test.csv\")\n",
    "sample_submission = pd.read_csv(\"input/sample_submission.csv\")\n",
    "\n",
    "#attribut initialization\n",
    "cols_unique_value = [] #Will be droped\n",
    "for col in raw_data.columns : \n",
    "    if len(raw_data[col].unique()) == 1 :\n",
    "        cols_unique_value.append(col)\n",
    "\n",
    "medium_cardianlity_cols = [\"ProductId\"]\n",
    "\n",
    "#Data transformation\n",
    "raw_data['TransactionStartTime'] = pd.to_datetime(raw_data['TransactionStartTime'])\n",
    "X_test['TransactionStartTime'] = pd.to_datetime(X_test['TransactionStartTime'])\n",
    "\n",
    "#Data cleaning\n",
    "data = raw_data.copy()\n",
    "data = data.dropna(axis=0) #Drop observations/rows with missing values\n",
    "X_test=X_test.dropna(axis=0)\n",
    "data.drop(cols_unique_value, axis=1, inplace=True)\n",
    "X_test.drop(cols_unique_value, axis=1, inplace=True)\n",
    "\n",
    "#Prepare index for the submission\n",
    "index_val = list(X_test.TransactionId.values.tolist())\n",
    "\n",
    "#Set the df index to the Transction Id\n",
    "data = transactioId_to_index(data)\n",
    "X_test = transactioId_to_index(X_test)\n",
    "\n",
    "#Adding data\n",
    "data = adding_date_col(data, 'TransactionStartTime')\n",
    "X_test = adding_date_col(X_test, 'TransactionStartTime')\n",
    "\n",
    "\n",
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "low_cardinality_cols = [cname for cname in data.columns if data[cname].nunique() < 15 and \n",
    "                        data[cname].dtype == \"object\"]\n",
    "low_cardinality_cols.append('PricingStrategy')\n",
    "\n",
    "#transform columns BatchId_54 to number\n",
    "    #transform columns BatchId_54 to number\n",
    "id_cols = data.filter(like=\"Id\").columns.tolist()\n",
    "data[id_cols] = data[id_cols].astype(str).apply(lambda x: x.str.replace(x.name + \"_\", \"\")).astype(int)\n",
    "X_test[id_cols] = X_test[id_cols].astype(str).apply(lambda x: x.str.replace(x.name + \"_\", \"\")).astype(int)\n",
    "\n",
    "data['PricingStrategy'] = data['PricingStrategy'].astype('int')\n",
    "X_test['PricingStrategy'] = X_test['PricingStrategy'].astype('int')\n",
    "data['Value'] = data['Value'].astype('float')\n",
    "X_test['Value'] = X_test['Value'].astype('float')\n",
    "\n",
    "X_test['PricingStrategy'] = X_test['PricingStrategy'].astype('str')\n",
    "data['PricingStrategy'] = data['PricingStrategy'].astype('str')\n",
    "\n",
    "#Data splitting\n",
    "y = data.FraudResult #The target label\n",
    "X = data.copy()\n",
    "X.drop(['FraudResult'], axis=1, inplace=True) #Only the features data\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "cat_cols = [col for col in X.columns if X[col].dtype == \"object\"]#liste of obejct columns\n",
    "cat_cols.append(\"PricingStrategy\")#pcq mm si c'est un chiffre il faut le considérer comme une catégorie\n",
    "\n",
    "\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(train_X[low_cardinality_cols]))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(val_X[low_cardinality_cols]))\n",
    "OH_cols_test = pd.DataFrame(OH_encoder.transform(X_test[low_cardinality_cols]))\n",
    "OH_cols_train.columns = OH_encoder.get_feature_names_out()\n",
    "OH_cols_valid.columns = OH_encoder.get_feature_names_out()\n",
    "OH_cols_test.columns = OH_encoder.get_feature_names_out()\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_train.index = train_X.index\n",
    "OH_cols_valid.index = val_X.index\n",
    "OH_cols_test.index = X_test.index\n",
    "\n",
    "OH_cols_train[list(OH_cols_train.columns)] = OH_cols_train[list(OH_cols_train.columns)].astype(int)\n",
    "OH_cols_valid[list(OH_cols_valid.columns)] = OH_cols_valid[list(OH_cols_valid.columns)].astype(int)\n",
    "OH_cols_test[list(OH_cols_test.columns)] = OH_cols_test[list(OH_cols_test.columns)].astype(int)\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train = train_X.drop(low_cardinality_cols, axis=1)\n",
    "num_X_valid = val_X.drop(low_cardinality_cols, axis=1)\n",
    "num_X_test = X_test.drop(low_cardinality_cols, axis=1)\n",
    "\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
    "OH_X_test = pd.concat([num_X_test, OH_cols_test], axis=1)\n",
    "\n",
    "# Problème de string\n",
    "OH_X_train.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_valid.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_test.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_train.columns = OH_X_train.columns.astype(str)\n",
    "OH_X_valid.columns = OH_X_valid.columns.astype(str)\n",
    "OH_X_test.columns = OH_X_test.columns.astype(str)\n",
    "\n",
    "train_X = OH_X_train\n",
    "val_X = OH_X_valid\n",
    "test_X = OH_X_test\n",
    "X_entier = pd.concat([train_X, val_X])\n",
    "\n",
    "referenceresult = comparemodels(train_X, train_y, val_X, test_X, \"The reference\")\n",
    "referenceresult[\"PublicScore\"] = [0.666666666, 0.690909090, 0.677419354, 0.678571428, 0.703703703, 0.678571428, 0.549019607]\n",
    "referenceresult[\"PrivateScore\"] = [0.661016949, 0.649122807,  0.676923076,0.666666666, 0.654867256, 0.637168141, 0.480769230]\n",
    "referenceresult"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418bccbc",
   "metadata": {},
   "source": [
    "## 2. Play with deleting the low MI columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "46c1db32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supprimer les MI trop faible\n",
    "def_feature = pd.read_csv(\"input/Xente_Variable_Definitions.csv\")\n",
    "raw_data = pd.read_csv(\"input/training.csv\")\n",
    "X_test = pd.read_csv(\"input/test.csv\")\n",
    "sample_submission = pd.read_csv(\"input/sample_submission.csv\")\n",
    "\n",
    "#attribut initialization\n",
    "cols_unique_value = [] #Will be droped\n",
    "for col in raw_data.columns : \n",
    "    if len(raw_data[col].unique()) == 1 :\n",
    "        cols_unique_value.append(col)\n",
    "\n",
    "medium_cardianlity_cols = [\"ProductId\"]\n",
    "\n",
    "#Data transformation\n",
    "raw_data['TransactionStartTime'] = pd.to_datetime(raw_data['TransactionStartTime'])\n",
    "X_test['TransactionStartTime'] = pd.to_datetime(X_test['TransactionStartTime'])\n",
    "\n",
    "#Data cleaning\n",
    "data = raw_data.copy()\n",
    "data = data.dropna(axis=0) #Drop observations/rows with missing values\n",
    "X_test=X_test.dropna(axis=0)\n",
    "data.drop(cols_unique_value, axis=1, inplace=True)\n",
    "X_test.drop(cols_unique_value, axis=1, inplace=True)\n",
    "\n",
    "#Prepare index for the submission\n",
    "index_val = list(X_test.TransactionId.values.tolist())\n",
    "\n",
    "#Set the df index to the Transction Id\n",
    "data = transactioId_to_index(data)\n",
    "X_test = transactioId_to_index(X_test)\n",
    "\n",
    "#Adding data\n",
    "data = adding_date_col(data, 'TransactionStartTime')\n",
    "X_test = adding_date_col(X_test, 'TransactionStartTime')\n",
    "\n",
    "\n",
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "low_cardinality_cols = [cname for cname in data.columns if data[cname].nunique() < 15 and \n",
    "                        data[cname].dtype == \"object\"]\n",
    "low_cardinality_cols.append('PricingStrategy')\n",
    "\n",
    "#transform columns BatchId_54 to number\n",
    "    #transform columns BatchId_54 to number\n",
    "id_cols = data.filter(like=\"Id\").columns.tolist()\n",
    "data[id_cols] = data[id_cols].astype(str).apply(lambda x: x.str.replace(x.name + \"_\", \"\")).astype(int)\n",
    "X_test[id_cols] = X_test[id_cols].astype(str).apply(lambda x: x.str.replace(x.name + \"_\", \"\")).astype(int)\n",
    "\n",
    "data['PricingStrategy'] = data['PricingStrategy'].astype('int')\n",
    "X_test['PricingStrategy'] = X_test['PricingStrategy'].astype('int')\n",
    "data['Value'] = data['Value'].astype('float')\n",
    "X_test['Value'] = X_test['Value'].astype('float')\n",
    "\n",
    "X_test['PricingStrategy'] = X_test['PricingStrategy'].astype('str')\n",
    "data['PricingStrategy'] = data['PricingStrategy'].astype('str')\n",
    "\n",
    "#Data splitting\n",
    "y = data.FraudResult #The target label\n",
    "X = data.copy()\n",
    "X.drop(['FraudResult'], axis=1, inplace=True) #Only the features data\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "cat_cols = [col for col in X.columns if X[col].dtype == \"object\"]#liste of obejct columns\n",
    "cat_cols.append(\"PricingStrategy\")#pcq mm si c'est un chiffre il faut le considérer comme une catégorie\n",
    "\n",
    "\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(train_X[low_cardinality_cols]))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(val_X[low_cardinality_cols]))\n",
    "OH_cols_test = pd.DataFrame(OH_encoder.transform(X_test[low_cardinality_cols]))\n",
    "OH_cols_train.columns = OH_encoder.get_feature_names_out()\n",
    "OH_cols_valid.columns = OH_encoder.get_feature_names_out()\n",
    "OH_cols_test.columns = OH_encoder.get_feature_names_out()\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_train.index = train_X.index\n",
    "OH_cols_valid.index = val_X.index\n",
    "OH_cols_test.index = X_test.index\n",
    "\n",
    "OH_cols_train[list(OH_cols_train.columns)] = OH_cols_train[list(OH_cols_train.columns)].astype(int)\n",
    "OH_cols_valid[list(OH_cols_valid.columns)] = OH_cols_valid[list(OH_cols_valid.columns)].astype(int)\n",
    "OH_cols_test[list(OH_cols_test.columns)] = OH_cols_test[list(OH_cols_test.columns)].astype(int)\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train = train_X.drop(low_cardinality_cols, axis=1)\n",
    "num_X_valid = val_X.drop(low_cardinality_cols, axis=1)\n",
    "num_X_test = X_test.drop(low_cardinality_cols, axis=1)\n",
    "\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
    "OH_X_test = pd.concat([num_X_test, OH_cols_test], axis=1)\n",
    "\n",
    "# Problème de string\n",
    "OH_X_train.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_valid.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_test.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_train.columns = OH_X_train.columns.astype(str)\n",
    "OH_X_valid.columns = OH_X_valid.columns.astype(str)\n",
    "OH_X_test.columns = OH_X_test.columns.astype(str)\n",
    "\n",
    "train_X = OH_X_train\n",
    "val_X = OH_X_valid\n",
    "test_X = OH_X_test\n",
    "X_entier = pd.concat([train_X, val_X])\n",
    "\n",
    "mi_scores = make_mi_scores(X_entier , y)\n",
    "\n",
    "verylowMI = list(mi_scores[mi_scores<0.0001].index)\n",
    "lowMI = list(mi_scores[(mi_scores>=0.0001)&(mi_scores<0.001)].index)\n",
    "mediumMI = list(mi_scores[(mi_scores>=0.001)&(mi_scores<0.01)].index)\n",
    "highMI = list(mi_scores[mi_scores>=0.01].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da4602e",
   "metadata": {},
   "source": [
    "### 2.1 Delecte the very low MI columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "df174abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Delete very low MImax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 16:30:13.941221</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.013564</td>\n",
       "      <td>0.881780</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.661017</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.882409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Delete very low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:15.122144</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.021099</td>\n",
       "      <td>0.838969</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.839697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Delete very low MIscale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 16:30:16.312527</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.891566</td>\n",
       "      <td>0.013564</td>\n",
       "      <td>0.891963</td>\n",
       "      <td>0.711864</td>\n",
       "      <td>0.715447</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.892249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest ClassifierWeighted500</td>\n",
       "      <td>Delete very low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:17.497220</td>\n",
       "      <td>0.760870</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.024113</td>\n",
       "      <td>0.815615</td>\n",
       "      <td>0.654545</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>0.816359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest ClassifierWeighted22</td>\n",
       "      <td>Delete very low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:18.625953</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.025621</td>\n",
       "      <td>0.801037</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.647619</td>\n",
       "      <td>[0.703703703]</td>\n",
       "      <td>[0.654867256]</td>\n",
       "      <td>0.801648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>Delete very low MIupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 16:30:21.059364</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.030142</td>\n",
       "      <td>0.775535</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.776649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>Delete very low MIundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 16:30:23.314014</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.030142</td>\n",
       "      <td>0.775535</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.776649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Model  \\\n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  Random Forest ClassifierWeighted500   \n",
       "4   Random Forest ClassifierWeighted22   \n",
       "5  RandomForestClassifierUpperSampling   \n",
       "6  RandomForestClassifierUnderSampling   \n",
       "\n",
       "                                                            Description  \\\n",
       "0              Delete very low MImax_leaf_nodes : 6 + with date columns   \n",
       "1                         Delete very low MIn_estimators : 36 + Entropy   \n",
       "2                               Delete very low MIscale_pos_weight = 22   \n",
       "3                         Delete very low MIn_estimators : 36 + Entropy   \n",
       "4                         Delete very low MIn_estimators : 36 + Entropy   \n",
       "5     Delete very low MIupsampled, n_estimators=36, criterion = entropy   \n",
       "6  Delete very low MIundersampled, n_estimators=36, criterion = entropy   \n",
       "\n",
       "                        Date  Precision  Recall  F1-score   LogLoss       Mcc  \\\n",
       "0 2023-05-07 16:30:13.941221   0.942857   0.825  0.880000  0.013564  0.881780   \n",
       "1 2023-05-07 16:30:15.122144   0.782609   0.900  0.837209  0.021099  0.838969   \n",
       "2 2023-05-07 16:30:16.312527   0.860465   0.925  0.891566  0.013564  0.891963   \n",
       "3 2023-05-07 16:30:17.497220   0.760870   0.875  0.813953  0.024113  0.815615   \n",
       "4 2023-05-07 16:30:18.625953   0.755556   0.850  0.800000  0.025621  0.801037   \n",
       "5 2023-05-07 16:30:21.059364   0.708333   0.850  0.772727  0.030142  0.775535   \n",
       "6 2023-05-07 16:30:23.314014   0.708333   0.850  0.772727  0.030142  0.775535   \n",
       "\n",
       "   PublicScore  PrivateScore                           OldPublicScore  \\\n",
       "0     0.666667      0.661017  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1     0.666667      0.649123   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2     0.711864      0.715447  [0.677419354, 0.711864406, 0.092764378]   \n",
       "3     0.654545      0.666667                            [0.678571428]   \n",
       "4     0.595745      0.647619                            [0.703703703]   \n",
       "5     0.642857      0.620690               [0.678571428, 0.642857142]   \n",
       "6     0.642857      0.620690               [0.549019607, 0.642857142]   \n",
       "\n",
       "                           OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.882409  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.839697  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.892249  \n",
       "3                            [0.666666666]        0.816359  \n",
       "4                            [0.654867256]        0.801648  \n",
       "5               [0.637168141, 0.620689655]        0.776649  \n",
       "6                [0.48076923, 0.620689655]        0.776649  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "val_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "test_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "X_entier.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "\n",
    "withoutverylowMI = comparemodels(train_X, train_y, val_X, test_X, \"Delete very low MI\")\n",
    "withoutverylowMI[\"PublicScore\"] = [0.666666666, 0.666666666, 0.711864406, 0.654545454, 0.595744680, 0.642857142, 0.642857142]\n",
    "withoutverylowMI[\"PrivateScore\"] = [0.661016949, 0.649122807, 0.715447154, 0.666666666, 0.647619047, 0.620689655, 0.620689655]\n",
    "withoutverylowMI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073967ea",
   "metadata": {},
   "source": [
    "### 2.2 Delete low MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0235a795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Delete low MImax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 16:30:23.482611</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.157730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.199660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Delete low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:24.429001</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.051241</td>\n",
       "      <td>0.495474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.498927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Delete low MIscale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 16:30:25.364763</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.495413</td>\n",
       "      <td>0.082890</td>\n",
       "      <td>0.512908</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.518656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest ClassifierWeighted500</td>\n",
       "      <td>Delete low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:26.329033</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.507463</td>\n",
       "      <td>0.049734</td>\n",
       "      <td>0.516643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>0.519684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest ClassifierWeighted22</td>\n",
       "      <td>Delete low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:27.271725</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.048227</td>\n",
       "      <td>0.526526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.703703703]</td>\n",
       "      <td>[0.654867256]</td>\n",
       "      <td>0.530131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>Delete low MIupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 16:30:29.422086</td>\n",
       "      <td>0.358209</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.448598</td>\n",
       "      <td>0.088919</td>\n",
       "      <td>0.462470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.467319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>Delete low MIundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 16:30:31.531002</td>\n",
       "      <td>0.358209</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.448598</td>\n",
       "      <td>0.088919</td>\n",
       "      <td>0.462470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.467319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Model  \\\n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  Random Forest ClassifierWeighted500   \n",
       "4   Random Forest ClassifierWeighted22   \n",
       "5  RandomForestClassifierUpperSampling   \n",
       "6  RandomForestClassifierUnderSampling   \n",
       "\n",
       "                                                       Description  \\\n",
       "0              Delete low MImax_leaf_nodes : 6 + with date columns   \n",
       "1                         Delete low MIn_estimators : 36 + Entropy   \n",
       "2                               Delete low MIscale_pos_weight = 22   \n",
       "3                         Delete low MIn_estimators : 36 + Entropy   \n",
       "4                         Delete low MIn_estimators : 36 + Entropy   \n",
       "5     Delete low MIupsampled, n_estimators=36, criterion = entropy   \n",
       "6  Delete low MIundersampled, n_estimators=36, criterion = entropy   \n",
       "\n",
       "                        Date  Precision  Recall  F1-score   LogLoss       Mcc  \\\n",
       "0 2023-05-07 16:30:23.482611   0.500000   0.050  0.090909  0.060284  0.157730   \n",
       "1 2023-05-07 16:30:24.429001   0.615385   0.400  0.484848  0.051241  0.495474   \n",
       "2 2023-05-07 16:30:25.364763   0.391304   0.675  0.495413  0.082890  0.512908   \n",
       "3 2023-05-07 16:30:26.329033   0.629630   0.425  0.507463  0.049734  0.516643   \n",
       "4 2023-05-07 16:30:27.271725   0.653846   0.425  0.515152  0.048227  0.526526   \n",
       "5 2023-05-07 16:30:29.422086   0.358209   0.600  0.448598  0.088919  0.462470   \n",
       "6 2023-05-07 16:30:31.531002   0.358209   0.600  0.448598  0.088919  0.462470   \n",
       "\n",
       "   PublicScore  PrivateScore                           OldPublicScore  \\\n",
       "0          NaN           NaN  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1          NaN           NaN   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2          NaN           NaN  [0.677419354, 0.711864406, 0.092764378]   \n",
       "3          NaN           NaN                            [0.678571428]   \n",
       "4          NaN           NaN                            [0.703703703]   \n",
       "5          NaN           NaN               [0.678571428, 0.642857142]   \n",
       "6          NaN           NaN               [0.549019607, 0.642857142]   \n",
       "\n",
       "                           OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.199660  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.498927  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.518656  \n",
       "3                            [0.666666666]        0.519684  \n",
       "4                            [0.654867256]        0.530131  \n",
       "5               [0.637168141, 0.620689655]        0.467319  \n",
       "6                [0.48076923, 0.620689655]        0.467319  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "val_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "test_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "X_entier.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "train_X.drop(lowMI, inplace=True, axis=1, errors='ignore')\n",
    "val_X.drop(lowMI, inplace=True, axis=1, errors='ignore')\n",
    "test_X.drop(lowMI, inplace=True, axis=1, errors='ignore')\n",
    "X_entier.drop(lowMI, inplace=True, axis=1, errors='ignore')\n",
    "\n",
    "withoutlowMI = comparemodels(train_X, train_y, val_X, test_X, \"Delete low MI\")\n",
    "withoutlowMI[\"PublicScore\"] = [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "withoutlowMI[\"PrivateScore\"] = [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "withoutlowMI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fb5923",
   "metadata": {},
   "source": [
    "### 2.3 Delete medium MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "463dd25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarah\\Documents\\ECAM_non_One_Drive\\Interligence artificiel\\Projet Niko\\AI5L_AILab_FraudDetection\\EvaluationMetric.py:8: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  metric = tp / (tp+fp)\n",
      "C:\\Users\\sarah\\Documents\\ECAM_non_One_Drive\\Interligence artificiel\\Projet Niko\\AI5L_AILab_FraudDetection\\EvaluationMetric.py:20: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = tp / (tp+fp)\n",
      "C:\\Users\\sarah\\Documents\\ECAM_non_One_Drive\\Interligence artificiel\\Projet Niko\\AI5L_AILab_FraudDetection\\EvaluationMetric.py:8: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  metric = tp / (tp+fp)\n",
      "C:\\Users\\sarah\\Documents\\ECAM_non_One_Drive\\Interligence artificiel\\Projet Niko\\AI5L_AILab_FraudDetection\\EvaluationMetric.py:20: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = tp / (tp+fp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarah\\Documents\\ECAM_non_One_Drive\\Interligence artificiel\\Projet Niko\\AI5L_AILab_FraudDetection\\EvaluationMetric.py:8: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  metric = tp / (tp+fp)\n",
      "C:\\Users\\sarah\\Documents\\ECAM_non_One_Drive\\Interligence artificiel\\Projet Niko\\AI5L_AILab_FraudDetection\\EvaluationMetric.py:20: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = tp / (tp+fp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarah\\Documents\\ECAM_non_One_Drive\\Interligence artificiel\\Projet Niko\\AI5L_AILab_FraudDetection\\EvaluationMetric.py:8: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  metric = tp / (tp+fp)\n",
      "C:\\Users\\sarah\\Documents\\ECAM_non_One_Drive\\Interligence artificiel\\Projet Niko\\AI5L_AILab_FraudDetection\\EvaluationMetric.py:20: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = tp / (tp+fp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Delete medium MImax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 16:30:31.663343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Delete medium MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:32.095585</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Delete medium MIscale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 16:30:32.543177</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.162791</td>\n",
       "      <td>0.108511</td>\n",
       "      <td>0.161685</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.162913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest ClassifierWeighted500</td>\n",
       "      <td>Delete medium MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:33.010695</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest ClassifierWeighted22</td>\n",
       "      <td>Delete medium MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:33.443986</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.703703703]</td>\n",
       "      <td>[0.654867256]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>Delete medium MIupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 16:30:34.208445</td>\n",
       "      <td>0.010398</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.020544</td>\n",
       "      <td>4.885998</td>\n",
       "      <td>0.084977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.241480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>Delete medium MIundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 16:30:34.949979</td>\n",
       "      <td>0.010398</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.020544</td>\n",
       "      <td>4.885998</td>\n",
       "      <td>0.084977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.241480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Model  \\\n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  Random Forest ClassifierWeighted500   \n",
       "4   Random Forest ClassifierWeighted22   \n",
       "5  RandomForestClassifierUpperSampling   \n",
       "6  RandomForestClassifierUnderSampling   \n",
       "\n",
       "                                                          Description  \\\n",
       "0              Delete medium MImax_leaf_nodes : 6 + with date columns   \n",
       "1                         Delete medium MIn_estimators : 36 + Entropy   \n",
       "2                               Delete medium MIscale_pos_weight = 22   \n",
       "3                         Delete medium MIn_estimators : 36 + Entropy   \n",
       "4                         Delete medium MIn_estimators : 36 + Entropy   \n",
       "5     Delete medium MIupsampled, n_estimators=36, criterion = entropy   \n",
       "6  Delete medium MIundersampled, n_estimators=36, criterion = entropy   \n",
       "\n",
       "                        Date  Precision  Recall  F1-score   LogLoss       Mcc  \\\n",
       "0 2023-05-07 16:30:31.663343        NaN   0.000       NaN  0.060284  0.000000   \n",
       "1 2023-05-07 16:30:32.095585        NaN   0.000       NaN  0.060284  0.000000   \n",
       "2 2023-05-07 16:30:32.543177   0.152174   0.175  0.162791  0.108511  0.161685   \n",
       "3 2023-05-07 16:30:33.010695        NaN   0.000       NaN  0.060284  0.000000   \n",
       "4 2023-05-07 16:30:33.443986        NaN   0.000       NaN  0.060284  0.000000   \n",
       "5 2023-05-07 16:30:34.208445   0.010398   0.850  0.020544  4.885998  0.084977   \n",
       "6 2023-05-07 16:30:34.949979   0.010398   0.850  0.020544  4.885998  0.084977   \n",
       "\n",
       "   PublicScore  PrivateScore                           OldPublicScore  \\\n",
       "0          NaN           NaN  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1          NaN           NaN   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2          NaN           NaN  [0.677419354, 0.711864406, 0.092764378]   \n",
       "3          NaN           NaN                            [0.678571428]   \n",
       "4          NaN           NaN                            [0.703703703]   \n",
       "5          NaN           NaN               [0.678571428, 0.642857142]   \n",
       "6          NaN           NaN               [0.549019607, 0.642857142]   \n",
       "\n",
       "                           OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.000000  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.000000  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.162913  \n",
       "3                            [0.666666666]        0.000000  \n",
       "4                            [0.654867256]        0.000000  \n",
       "5               [0.637168141, 0.620689655]        0.241480  \n",
       "6                [0.48076923, 0.620689655]        0.241480  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "val_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "test_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "X_entier.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "train_X.drop(lowMI, inplace=True, axis=1, errors='ignore')\n",
    "val_X.drop(lowMI, inplace=True, axis=1, errors='ignore')\n",
    "test_X.drop(lowMI, inplace=True, axis=1, errors='ignore')\n",
    "X_entier.drop(lowMI, inplace=True, axis=1, errors='ignore')\n",
    "\n",
    "train_X.drop(mediumMI, inplace=True, axis=1, errors='ignore')\n",
    "val_X.drop(mediumMI, inplace=True, axis=1, errors='ignore')\n",
    "test_X.drop(mediumMI, inplace=True, axis=1, errors='ignore')\n",
    "X_entier.drop(mediumMI, inplace=True, axis=1, errors='ignore')\n",
    "\n",
    "withoutmediumMI = comparemodels(train_X, train_y, val_X, test_X, \"Delete medium MI\")\n",
    "withoutmediumMI[\"PublicScore\"] = [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "withoutmediumMI[\"PrivateScore\"] = [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "withoutmediumMI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f269ad",
   "metadata": {},
   "source": [
    "## 3 Undersampling with K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0f58714f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarah\\anaconda3\\envs\\AILab-ECAM4\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Kmeans UnderSamplingmax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 16:31:00.117654</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.371584</td>\n",
       "      <td>0.979557</td>\n",
       "      <td>0.006575</td>\n",
       "      <td>0.006863</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.987512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Kmeans UnderSamplingn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:31:00.285578</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.114752</td>\n",
       "      <td>0.938324</td>\n",
       "      <td>0.007513</td>\n",
       "      <td>0.007795</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.961903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Kmeans UnderSamplingon balanced data</td>\n",
       "      <td>2023-05-07 16:31:00.404309</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.114752</td>\n",
       "      <td>0.938324</td>\n",
       "      <td>0.092764</td>\n",
       "      <td>0.096565</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.961903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model  \\\n",
       "0    DecisionTreeClassifier   \n",
       "1  Random Forest Classifier   \n",
       "2             XGBClassifier   \n",
       "\n",
       "                                                  Description  \\\n",
       "0  Kmeans UnderSamplingmax_leaf_nodes : 6 + with date columns   \n",
       "1             Kmeans UnderSamplingn_estimators : 36 + Entropy   \n",
       "2                        Kmeans UnderSamplingon balanced data   \n",
       "\n",
       "                        Date  Precision  Recall  F1-score   LogLoss       Mcc  \\\n",
       "0 2023-05-07 16:31:00.117654   0.980392    1.00  0.990099  0.371584  0.979557   \n",
       "1 2023-05-07 16:31:00.285578   0.979592    0.96  0.969697  1.114752  0.938324   \n",
       "2 2023-05-07 16:31:00.404309   0.979592    0.96  0.969697  1.114752  0.938324   \n",
       "\n",
       "   PublicScore  PrivateScore                           OldPublicScore  \\\n",
       "0     0.006575      0.006863  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1     0.007513      0.007795   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2     0.092764      0.096565  [0.677419354, 0.711864406, 0.092764378]   \n",
       "\n",
       "                           OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.987512  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.961903  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.961903  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans \n",
    "\n",
    "# K-means fait sur training set entier (et ensuite sur seuelement le train_X)\n",
    "def_feature = pd.read_csv(\"input/Xente_Variable_Definitions.csv\")\n",
    "raw_data = pd.read_csv(\"input/training.csv\")\n",
    "X_test = pd.read_csv(\"input/test.csv\")\n",
    "sample_submission = pd.read_csv(\"input/sample_submission.csv\")\n",
    "\n",
    "#attribut initialization\n",
    "cols_unique_value = [] #Will be droped\n",
    "for col in raw_data.columns : \n",
    "    if len(raw_data[col].unique()) == 1 :\n",
    "        cols_unique_value.append(col)\n",
    "\n",
    "medium_cardianlity_cols = [\"ProductId\"]\n",
    "\n",
    "#Data transformation\n",
    "raw_data['TransactionStartTime'] = pd.to_datetime(raw_data['TransactionStartTime'])\n",
    "X_test['TransactionStartTime'] = pd.to_datetime(X_test['TransactionStartTime'])\n",
    "\n",
    "#Data cleaning\n",
    "data = raw_data.copy()\n",
    "data = data.dropna(axis=0) #Drop observations/rows with missing values\n",
    "X_test=X_test.dropna(axis=0)\n",
    "data.drop(cols_unique_value, axis=1, inplace=True)\n",
    "X_test.drop(cols_unique_value, axis=1, inplace=True)\n",
    "\n",
    "#Prepare index for the submission\n",
    "index_val = list(X_test.TransactionId.values.tolist())\n",
    "\n",
    "#Set the df index to the Transction Id\n",
    "data = transactioId_to_index(data)\n",
    "X_test = transactioId_to_index(X_test)\n",
    "\n",
    "#Adding data\n",
    "data = adding_date_col(data, 'TransactionStartTime')\n",
    "X_test = adding_date_col(X_test, 'TransactionStartTime')\n",
    "\n",
    "\n",
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "low_cardinality_cols = [cname for cname in data.columns if data[cname].nunique() < 15 and \n",
    "                        data[cname].dtype == \"object\"]\n",
    "low_cardinality_cols.append('PricingStrategy')\n",
    "\n",
    "#transform columns BatchId_54 to number\n",
    "    #transform columns BatchId_54 to number\n",
    "id_cols = data.filter(like=\"Id\").columns.tolist()\n",
    "data[id_cols] = data[id_cols].astype(str).apply(lambda x: x.str.replace(x.name + \"_\", \"\")).astype(int)\n",
    "X_test[id_cols] = X_test[id_cols].astype(str).apply(lambda x: x.str.replace(x.name + \"_\", \"\")).astype(int)\n",
    "\n",
    "data['PricingStrategy'] = data['PricingStrategy'].astype('int')\n",
    "X_test['PricingStrategy'] = X_test['PricingStrategy'].astype('int')\n",
    "data['Value'] = data['Value'].astype('float')\n",
    "X_test['Value'] = X_test['Value'].astype('float')\n",
    "\n",
    "X_test['PricingStrategy'] = X_test['PricingStrategy'].astype('str')\n",
    "data['PricingStrategy'] = data['PricingStrategy'].astype('str')\n",
    "\n",
    "#Data splitting\n",
    "y = data.FraudResult #The target label\n",
    "X = data.copy()\n",
    "X.drop(['FraudResult'], axis=1, inplace=True) #Only the features data\n",
    "\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "OH_cols_X = pd.DataFrame(OH_encoder.fit_transform(X[low_cardinality_cols]))\n",
    "OH_cols_X.columns = OH_encoder.get_feature_names_out()\n",
    "OH_cols_test = pd.DataFrame(OH_encoder.transform(X_test[low_cardinality_cols]))\n",
    "OH_cols_test.columns = OH_encoder.get_feature_names_out()\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_X.index = X.index\n",
    "OH_cols_test.index = X_test.index\n",
    "\n",
    "OH_cols_X[list(OH_cols_X.columns)] = OH_cols_X[list(OH_cols_X.columns)].astype(int)\n",
    "OH_cols_test[list(OH_cols_test.columns)] = OH_cols_test[list(OH_cols_test.columns)].astype(int)\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X = X.drop(low_cardinality_cols, axis=1)\n",
    "num_X_test = X_test.drop(low_cardinality_cols, axis=1)\n",
    "\n",
    "OH_X = pd.concat([num_X, OH_cols_X], axis=1)\n",
    "OH_X_test = pd.concat([num_X_test, OH_cols_test], axis=1)\n",
    "\n",
    "# Problème de string\n",
    "OH_X.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_test.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X.columns = OH_X.columns.astype(str)\n",
    "OH_X_test.columns = OH_X_test.columns.astype(str)\n",
    "\n",
    "X = OH_X\n",
    "\n",
    "#####K-Means\n",
    "X_0 = X[y == 0] # instances avec FraudResult=0\n",
    "X_1 = X[y == 1] # instances avec FraudResult=1\n",
    "\n",
    "# Créer des \"centres\" pour KMeans\n",
    "n_clusters = 193\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(X_0)\n",
    "centers = kmeans.cluster_centers_\n",
    "\n",
    "# Trouver les indices des instances à garder dans la classe FraudResult=0\n",
    "labels = kmeans.predict(X_0)\n",
    "distances = np.sum((X_0 - centers[labels]) ** 2, axis=1)\n",
    "keep_indices = np.argsort(distances)[:n_clusters]\n",
    "\n",
    "df_filtré = X_0[X_0.index.isin(list(keep_indices.index))]\n",
    "\n",
    "# Combiner les instances sous-échantillonnées\n",
    "X_undersampled = pd.concat([df_filtré, X_1])\n",
    "y_undersampled = np.concatenate((np.zeros(n_clusters), np.ones(len(X_1))), axis=0)\n",
    "\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(X_undersampled, y_undersampled, random_state = 0)\n",
    "\n",
    "\n",
    "#train_X.drop(verylowMI, inplace=True, axis=1)\n",
    "#val_X.drop(verylowMI, inplace=True, axis=1)\n",
    "#test_X.drop(verylowMI, inplace=True, axis=1)\n",
    "#X_entier.drop(verylowMI, inplace=True, axis=1)\n",
    "\n",
    "kmeansundersampling = comparemodels(train_X, train_y, val_X, OH_X_test, \"Kmeans UnderSampling\", unbalanced = False)\n",
    "kmeansundersampling[\"PublicScore\"] = [0.006575486, 0.007513148, 0.092764378]\n",
    "kmeansundersampling[\"PrivateScore\"] = [0.006863327, 0.007794933, 0.096564531] ###Cest trop nulle \n",
    "kmeansundersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789ddb0c",
   "metadata": {},
   "source": [
    "## 4. SMOTE (Synthetic Minority Oversampling Technique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ed3fa295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>SMOTEmax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 16:31:18.853308</td>\n",
       "      <td>0.113372</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.203125</td>\n",
       "      <td>0.461171</td>\n",
       "      <td>0.330225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.405431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>SMOTEn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:31:22.707671</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.027128</td>\n",
       "      <td>0.804629</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.686567</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.806157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>SMOTEon balanced data</td>\n",
       "      <td>2023-05-07 16:31:25.958940</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.862324</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.376068</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.863034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model                                  Description  \\\n",
       "0    DecisionTreeClassifier  SMOTEmax_leaf_nodes : 6 + with date columns   \n",
       "1  Random Forest Classifier             SMOTEn_estimators : 36 + Entropy   \n",
       "2             XGBClassifier                        SMOTEon balanced data   \n",
       "\n",
       "                        Date  Precision  Recall  F1-score   LogLoss       Mcc  \\\n",
       "0 2023-05-07 16:31:18.853308   0.113372   0.975  0.203125  0.461171  0.330225   \n",
       "1 2023-05-07 16:31:22.707671   0.720000   0.900  0.800000  0.027128  0.804629   \n",
       "2 2023-05-07 16:31:25.958940   0.804348   0.925  0.860465  0.018085  0.862324   \n",
       "\n",
       "   PublicScore  PrivateScore                           OldPublicScore  \\\n",
       "0          NaN           NaN  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1     0.709677      0.686567   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2     0.358974      0.376068  [0.677419354, 0.711864406, 0.092764378]   \n",
       "\n",
       "                           OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.405431  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.806157  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.863034  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SMOTE\n",
    "def_feature = pd.read_csv(\"input/Xente_Variable_Definitions.csv\")\n",
    "raw_data = pd.read_csv(\"input/training.csv\")\n",
    "X_test = pd.read_csv(\"input/test.csv\")\n",
    "sample_submission = pd.read_csv(\"input/sample_submission.csv\")\n",
    "\n",
    "#attribut initialization\n",
    "cols_unique_value = [] #Will be droped\n",
    "for col in raw_data.columns : \n",
    "    if len(raw_data[col].unique()) == 1 :\n",
    "        cols_unique_value.append(col)\n",
    "\n",
    "medium_cardianlity_cols = [\"ProductId\"]\n",
    "\n",
    "#Data transformation\n",
    "raw_data['TransactionStartTime'] = pd.to_datetime(raw_data['TransactionStartTime'])\n",
    "X_test['TransactionStartTime'] = pd.to_datetime(X_test['TransactionStartTime'])\n",
    "\n",
    "#Data cleaning\n",
    "data = raw_data.copy()\n",
    "data = data.dropna(axis=0) #Drop observations/rows with missing values\n",
    "X_test=X_test.dropna(axis=0)\n",
    "data.drop(cols_unique_value, axis=1, inplace=True)\n",
    "X_test.drop(cols_unique_value, axis=1, inplace=True)\n",
    "\n",
    "#Prepare index for the submission\n",
    "index_val = list(X_test.TransactionId.values.tolist())\n",
    "\n",
    "#Set the df index to the Transction Id\n",
    "data = transactioId_to_index(data)\n",
    "X_test = transactioId_to_index(X_test)\n",
    "\n",
    "#Adding data\n",
    "data = adding_date_col(data, 'TransactionStartTime')\n",
    "X_test = adding_date_col(X_test, 'TransactionStartTime')\n",
    "\n",
    "\n",
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "low_cardinality_cols = [cname for cname in data.columns if data[cname].nunique() < 15 and \n",
    "                        data[cname].dtype == \"object\"]\n",
    "low_cardinality_cols.append('PricingStrategy')\n",
    "\n",
    "#transform columns BatchId_54 to number\n",
    "    #transform columns BatchId_54 to number\n",
    "id_cols = data.filter(like=\"Id\").columns.tolist()\n",
    "data[id_cols] = data[id_cols].astype(str).apply(lambda x: x.str.replace(x.name + \"_\", \"\")).astype(int)\n",
    "X_test[id_cols] = X_test[id_cols].astype(str).apply(lambda x: x.str.replace(x.name + \"_\", \"\")).astype(int)\n",
    "\n",
    "data['PricingStrategy'] = data['PricingStrategy'].astype('int')\n",
    "X_test['PricingStrategy'] = X_test['PricingStrategy'].astype('int')\n",
    "data['Value'] = data['Value'].astype('float')\n",
    "X_test['Value'] = X_test['Value'].astype('float')\n",
    "\n",
    "X_test['PricingStrategy'] = X_test['PricingStrategy'].astype('str')\n",
    "data['PricingStrategy'] = data['PricingStrategy'].astype('str')\n",
    "\n",
    "#Data splitting\n",
    "y = data.FraudResult #The target label\n",
    "X = data.copy()\n",
    "X.drop(['FraudResult'], axis=1, inplace=True) #Only the features data\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "cat_cols = [col for col in X.columns if X[col].dtype == \"object\"]#liste of obejct columns\n",
    "cat_cols.append(\"PricingStrategy\")#pcq mm si c'est un chiffre il faut le considérer comme une catégorie\n",
    "\n",
    "\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(train_X[low_cardinality_cols]))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(val_X[low_cardinality_cols]))\n",
    "OH_cols_test = pd.DataFrame(OH_encoder.transform(X_test[low_cardinality_cols]))\n",
    "OH_cols_train.columns = OH_encoder.get_feature_names_out()\n",
    "OH_cols_valid.columns = OH_encoder.get_feature_names_out()\n",
    "OH_cols_test.columns = OH_encoder.get_feature_names_out()\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_train.index = train_X.index\n",
    "OH_cols_valid.index = val_X.index\n",
    "OH_cols_test.index = X_test.index\n",
    "\n",
    "OH_cols_train[list(OH_cols_train.columns)] = OH_cols_train[list(OH_cols_train.columns)].astype(int)\n",
    "OH_cols_valid[list(OH_cols_valid.columns)] = OH_cols_valid[list(OH_cols_valid.columns)].astype(int)\n",
    "OH_cols_test[list(OH_cols_test.columns)] = OH_cols_test[list(OH_cols_test.columns)].astype(int)\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train = train_X.drop(low_cardinality_cols, axis=1)\n",
    "num_X_valid = val_X.drop(low_cardinality_cols, axis=1)\n",
    "num_X_test = X_test.drop(low_cardinality_cols, axis=1)\n",
    "\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
    "OH_X_test = pd.concat([num_X_test, OH_cols_test], axis=1)\n",
    "\n",
    "# Problème de string\n",
    "OH_X_train.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_valid.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_test.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_train.columns = OH_X_train.columns.astype(str)\n",
    "OH_X_valid.columns = OH_X_valid.columns.astype(str)\n",
    "OH_X_test.columns = OH_X_test.columns.astype(str)\n",
    "\n",
    "train_X = OH_X_train\n",
    "val_X = OH_X_valid\n",
    "test_X = OH_X_test\n",
    "X_entier = pd.concat([train_X, val_X])\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(train_X, train_y)\n",
    "\n",
    "mi_scores = make_mi_scores(X_entier, y)\n",
    "\n",
    "verylowMI = list(mi_scores[mi_scores<0.0001].index)\n",
    "lowMI = list(mi_scores[(mi_scores>=0.0001)&(mi_scores<0.001)].index)\n",
    "mediumMI = list(mi_scores[(mi_scores>=0.001)&(mi_scores<0.01)].index)\n",
    "highMI = list(mi_scores[mi_scores>=0.01].index)\n",
    "\n",
    "\n",
    "#train_X.drop(verylowMI, inplace=True, axis=1)\n",
    "#val_X.drop(verylowMI, inplace=True, axis=1)\n",
    "#test_X.drop(verylowMI, inplace=True, axis=1)\n",
    "#X_entier.drop(verylowMI, inplace=True, axis=1)\n",
    "\n",
    "SMOTERes = comparemodels(X_res, y_res, val_X, test_X, \"SMOTE\", unbalanced = False)\n",
    "SMOTERes[\"PublicScore\"] = [np.nan, 0.709677419, 0.358974358] #ici voit que le RandomForest est mieux\n",
    "SMOTERes[\"PrivateScore\"] = [np.nan, 0.686567164, 0.376068376]  \n",
    "SMOTERes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6650c6",
   "metadata": {},
   "source": [
    "# Compare result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "78eddab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>The referencemax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 16:29:46.815175</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>0.857566</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.661017</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.857900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>The referencen_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:29:47.996356</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.843373</td>\n",
       "      <td>0.019592</td>\n",
       "      <td>0.843655</td>\n",
       "      <td>0.690909</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.843995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>The referencescale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 16:29:49.487206</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>0.871874</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.676923</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.872421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest ClassifierWeighted500</td>\n",
       "      <td>The referencen_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:29:50.689128</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.862324</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>0.863034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest ClassifierWeighted22</td>\n",
       "      <td>The referencen_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:29:51.854001</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.862324</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.654867</td>\n",
       "      <td>[0.703703703]</td>\n",
       "      <td>[0.654867256]</td>\n",
       "      <td>0.863034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>The referenceupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 16:29:54.212174</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.022606</td>\n",
       "      <td>0.824649</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.637168</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.825239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>The referenceundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 16:29:56.454271</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.022606</td>\n",
       "      <td>0.824649</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.825239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Delete very low MImax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 16:30:13.941221</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.013564</td>\n",
       "      <td>0.881780</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.661017</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.882409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Delete very low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:15.122144</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.021099</td>\n",
       "      <td>0.838969</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.839697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Delete very low MIscale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 16:30:16.312527</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.891566</td>\n",
       "      <td>0.013564</td>\n",
       "      <td>0.891963</td>\n",
       "      <td>0.711864</td>\n",
       "      <td>0.715447</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.892249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest ClassifierWeighted500</td>\n",
       "      <td>Delete very low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:17.497220</td>\n",
       "      <td>0.760870</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.024113</td>\n",
       "      <td>0.815615</td>\n",
       "      <td>0.654545</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>0.816359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest ClassifierWeighted22</td>\n",
       "      <td>Delete very low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:18.625953</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.025621</td>\n",
       "      <td>0.801037</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.647619</td>\n",
       "      <td>[0.703703703]</td>\n",
       "      <td>[0.654867256]</td>\n",
       "      <td>0.801648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>Delete very low MIupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 16:30:21.059364</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.030142</td>\n",
       "      <td>0.775535</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.776649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>Delete very low MIundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 16:30:23.314014</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.030142</td>\n",
       "      <td>0.775535</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.776649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Delete low MImax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 16:30:23.482611</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.157730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.199660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Delete low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:24.429001</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.051241</td>\n",
       "      <td>0.495474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.498927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Delete low MIscale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 16:30:25.364763</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.495413</td>\n",
       "      <td>0.082890</td>\n",
       "      <td>0.512908</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.518656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest ClassifierWeighted500</td>\n",
       "      <td>Delete low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:26.329033</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.507463</td>\n",
       "      <td>0.049734</td>\n",
       "      <td>0.516643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>0.519684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest ClassifierWeighted22</td>\n",
       "      <td>Delete low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:27.271725</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.048227</td>\n",
       "      <td>0.526526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.703703703]</td>\n",
       "      <td>[0.654867256]</td>\n",
       "      <td>0.530131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>Delete low MIupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 16:30:29.422086</td>\n",
       "      <td>0.358209</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.448598</td>\n",
       "      <td>0.088919</td>\n",
       "      <td>0.462470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.467319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>Delete low MIundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 16:30:31.531002</td>\n",
       "      <td>0.358209</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.448598</td>\n",
       "      <td>0.088919</td>\n",
       "      <td>0.462470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.467319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Delete medium MImax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 16:30:31.663343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Delete medium MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:32.095585</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Delete medium MIscale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 16:30:32.543177</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.162791</td>\n",
       "      <td>0.108511</td>\n",
       "      <td>0.161685</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.162913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest ClassifierWeighted500</td>\n",
       "      <td>Delete medium MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:33.010695</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest ClassifierWeighted22</td>\n",
       "      <td>Delete medium MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:33.443986</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.703703703]</td>\n",
       "      <td>[0.654867256]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>Delete medium MIupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 16:30:34.208445</td>\n",
       "      <td>0.010398</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.020544</td>\n",
       "      <td>4.885998</td>\n",
       "      <td>0.084977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.241480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>Delete medium MIundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 16:30:34.949979</td>\n",
       "      <td>0.010398</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.020544</td>\n",
       "      <td>4.885998</td>\n",
       "      <td>0.084977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.241480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Kmeans UnderSamplingmax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 16:31:00.117654</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.371584</td>\n",
       "      <td>0.979557</td>\n",
       "      <td>0.006575</td>\n",
       "      <td>0.006863</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.987512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Kmeans UnderSamplingn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:31:00.285578</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.114752</td>\n",
       "      <td>0.938324</td>\n",
       "      <td>0.007513</td>\n",
       "      <td>0.007795</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.961903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Kmeans UnderSamplingon balanced data</td>\n",
       "      <td>2023-05-07 16:31:00.404309</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.114752</td>\n",
       "      <td>0.938324</td>\n",
       "      <td>0.092764</td>\n",
       "      <td>0.096565</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.961903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>SMOTEmax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 16:31:18.853308</td>\n",
       "      <td>0.113372</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.203125</td>\n",
       "      <td>0.461171</td>\n",
       "      <td>0.330225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.405431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>SMOTEn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:31:22.707671</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.027128</td>\n",
       "      <td>0.804629</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.686567</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.806157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>SMOTEon balanced data</td>\n",
       "      <td>2023-05-07 16:31:25.958940</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.862324</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.376068</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.863034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Model  \\\n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  Random Forest ClassifierWeighted500   \n",
       "4   Random Forest ClassifierWeighted22   \n",
       "5  RandomForestClassifierUpperSampling   \n",
       "6  RandomForestClassifierUnderSampling   \n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  Random Forest ClassifierWeighted500   \n",
       "4   Random Forest ClassifierWeighted22   \n",
       "5  RandomForestClassifierUpperSampling   \n",
       "6  RandomForestClassifierUnderSampling   \n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  Random Forest ClassifierWeighted500   \n",
       "4   Random Forest ClassifierWeighted22   \n",
       "5  RandomForestClassifierUpperSampling   \n",
       "6  RandomForestClassifierUnderSampling   \n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  Random Forest ClassifierWeighted500   \n",
       "4   Random Forest ClassifierWeighted22   \n",
       "5  RandomForestClassifierUpperSampling   \n",
       "6  RandomForestClassifierUnderSampling   \n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "\n",
       "                                                            Description  \\\n",
       "0                   The referencemax_leaf_nodes : 6 + with date columns   \n",
       "1                              The referencen_estimators : 36 + Entropy   \n",
       "2                                    The referencescale_pos_weight = 22   \n",
       "3                              The referencen_estimators : 36 + Entropy   \n",
       "4                              The referencen_estimators : 36 + Entropy   \n",
       "5          The referenceupsampled, n_estimators=36, criterion = entropy   \n",
       "6       The referenceundersampled, n_estimators=36, criterion = entropy   \n",
       "0              Delete very low MImax_leaf_nodes : 6 + with date columns   \n",
       "1                         Delete very low MIn_estimators : 36 + Entropy   \n",
       "2                               Delete very low MIscale_pos_weight = 22   \n",
       "3                         Delete very low MIn_estimators : 36 + Entropy   \n",
       "4                         Delete very low MIn_estimators : 36 + Entropy   \n",
       "5     Delete very low MIupsampled, n_estimators=36, criterion = entropy   \n",
       "6  Delete very low MIundersampled, n_estimators=36, criterion = entropy   \n",
       "0                   Delete low MImax_leaf_nodes : 6 + with date columns   \n",
       "1                              Delete low MIn_estimators : 36 + Entropy   \n",
       "2                                    Delete low MIscale_pos_weight = 22   \n",
       "3                              Delete low MIn_estimators : 36 + Entropy   \n",
       "4                              Delete low MIn_estimators : 36 + Entropy   \n",
       "5          Delete low MIupsampled, n_estimators=36, criterion = entropy   \n",
       "6       Delete low MIundersampled, n_estimators=36, criterion = entropy   \n",
       "0                Delete medium MImax_leaf_nodes : 6 + with date columns   \n",
       "1                           Delete medium MIn_estimators : 36 + Entropy   \n",
       "2                                 Delete medium MIscale_pos_weight = 22   \n",
       "3                           Delete medium MIn_estimators : 36 + Entropy   \n",
       "4                           Delete medium MIn_estimators : 36 + Entropy   \n",
       "5       Delete medium MIupsampled, n_estimators=36, criterion = entropy   \n",
       "6    Delete medium MIundersampled, n_estimators=36, criterion = entropy   \n",
       "0            Kmeans UnderSamplingmax_leaf_nodes : 6 + with date columns   \n",
       "1                       Kmeans UnderSamplingn_estimators : 36 + Entropy   \n",
       "2                                  Kmeans UnderSamplingon balanced data   \n",
       "0                           SMOTEmax_leaf_nodes : 6 + with date columns   \n",
       "1                                      SMOTEn_estimators : 36 + Entropy   \n",
       "2                                                 SMOTEon balanced data   \n",
       "\n",
       "                        Date  Precision  Recall  F1-score   LogLoss       Mcc  \\\n",
       "0 2023-05-07 16:29:46.815175   0.891892   0.825  0.857143  0.016578  0.857566   \n",
       "1 2023-05-07 16:29:47.996356   0.813953   0.875  0.843373  0.019592  0.843655   \n",
       "2 2023-05-07 16:29:49.487206   0.822222   0.925  0.870588  0.016578  0.871874   \n",
       "3 2023-05-07 16:29:50.689128   0.804348   0.925  0.860465  0.018085  0.862324   \n",
       "4 2023-05-07 16:29:51.854001   0.804348   0.925  0.860465  0.018085  0.862324   \n",
       "5 2023-05-07 16:29:54.212174   0.777778   0.875  0.823529  0.022606  0.824649   \n",
       "6 2023-05-07 16:29:56.454271   0.777778   0.875  0.823529  0.022606  0.824649   \n",
       "0 2023-05-07 16:30:13.941221   0.942857   0.825  0.880000  0.013564  0.881780   \n",
       "1 2023-05-07 16:30:15.122144   0.782609   0.900  0.837209  0.021099  0.838969   \n",
       "2 2023-05-07 16:30:16.312527   0.860465   0.925  0.891566  0.013564  0.891963   \n",
       "3 2023-05-07 16:30:17.497220   0.760870   0.875  0.813953  0.024113  0.815615   \n",
       "4 2023-05-07 16:30:18.625953   0.755556   0.850  0.800000  0.025621  0.801037   \n",
       "5 2023-05-07 16:30:21.059364   0.708333   0.850  0.772727  0.030142  0.775535   \n",
       "6 2023-05-07 16:30:23.314014   0.708333   0.850  0.772727  0.030142  0.775535   \n",
       "0 2023-05-07 16:30:23.482611   0.500000   0.050  0.090909  0.060284  0.157730   \n",
       "1 2023-05-07 16:30:24.429001   0.615385   0.400  0.484848  0.051241  0.495474   \n",
       "2 2023-05-07 16:30:25.364763   0.391304   0.675  0.495413  0.082890  0.512908   \n",
       "3 2023-05-07 16:30:26.329033   0.629630   0.425  0.507463  0.049734  0.516643   \n",
       "4 2023-05-07 16:30:27.271725   0.653846   0.425  0.515152  0.048227  0.526526   \n",
       "5 2023-05-07 16:30:29.422086   0.358209   0.600  0.448598  0.088919  0.462470   \n",
       "6 2023-05-07 16:30:31.531002   0.358209   0.600  0.448598  0.088919  0.462470   \n",
       "0 2023-05-07 16:30:31.663343        NaN   0.000       NaN  0.060284  0.000000   \n",
       "1 2023-05-07 16:30:32.095585        NaN   0.000       NaN  0.060284  0.000000   \n",
       "2 2023-05-07 16:30:32.543177   0.152174   0.175  0.162791  0.108511  0.161685   \n",
       "3 2023-05-07 16:30:33.010695        NaN   0.000       NaN  0.060284  0.000000   \n",
       "4 2023-05-07 16:30:33.443986        NaN   0.000       NaN  0.060284  0.000000   \n",
       "5 2023-05-07 16:30:34.208445   0.010398   0.850  0.020544  4.885998  0.084977   \n",
       "6 2023-05-07 16:30:34.949979   0.010398   0.850  0.020544  4.885998  0.084977   \n",
       "0 2023-05-07 16:31:00.117654   0.980392   1.000  0.990099  0.371584  0.979557   \n",
       "1 2023-05-07 16:31:00.285578   0.979592   0.960  0.969697  1.114752  0.938324   \n",
       "2 2023-05-07 16:31:00.404309   0.979592   0.960  0.969697  1.114752  0.938324   \n",
       "0 2023-05-07 16:31:18.853308   0.113372   0.975  0.203125  0.461171  0.330225   \n",
       "1 2023-05-07 16:31:22.707671   0.720000   0.900  0.800000  0.027128  0.804629   \n",
       "2 2023-05-07 16:31:25.958940   0.804348   0.925  0.860465  0.018085  0.862324   \n",
       "\n",
       "   PublicScore  PrivateScore                           OldPublicScore  \\\n",
       "0     0.666667      0.661017  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1     0.690909      0.649123   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2     0.677419      0.676923  [0.677419354, 0.711864406, 0.092764378]   \n",
       "3     0.678571      0.666667                            [0.678571428]   \n",
       "4     0.703704      0.654867                            [0.703703703]   \n",
       "5     0.678571      0.637168               [0.678571428, 0.642857142]   \n",
       "6     0.549020      0.480769               [0.549019607, 0.642857142]   \n",
       "0     0.666667      0.661017  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1     0.666667      0.649123   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2     0.711864      0.715447  [0.677419354, 0.711864406, 0.092764378]   \n",
       "3     0.654545      0.666667                            [0.678571428]   \n",
       "4     0.595745      0.647619                            [0.703703703]   \n",
       "5     0.642857      0.620690               [0.678571428, 0.642857142]   \n",
       "6     0.642857      0.620690               [0.549019607, 0.642857142]   \n",
       "0          NaN           NaN  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1          NaN           NaN   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2          NaN           NaN  [0.677419354, 0.711864406, 0.092764378]   \n",
       "3          NaN           NaN                            [0.678571428]   \n",
       "4          NaN           NaN                            [0.703703703]   \n",
       "5          NaN           NaN               [0.678571428, 0.642857142]   \n",
       "6          NaN           NaN               [0.549019607, 0.642857142]   \n",
       "0          NaN           NaN  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1          NaN           NaN   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2          NaN           NaN  [0.677419354, 0.711864406, 0.092764378]   \n",
       "3          NaN           NaN                            [0.678571428]   \n",
       "4          NaN           NaN                            [0.703703703]   \n",
       "5          NaN           NaN               [0.678571428, 0.642857142]   \n",
       "6          NaN           NaN               [0.549019607, 0.642857142]   \n",
       "0     0.006575      0.006863  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1     0.007513      0.007795   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2     0.092764      0.096565  [0.677419354, 0.711864406, 0.092764378]   \n",
       "0          NaN           NaN  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1     0.709677      0.686567   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2     0.358974      0.376068  [0.677419354, 0.711864406, 0.092764378]   \n",
       "\n",
       "                           OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.857900  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.843995  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.872421  \n",
       "3                            [0.666666666]        0.863034  \n",
       "4                            [0.654867256]        0.863034  \n",
       "5               [0.637168141, 0.620689655]        0.825239  \n",
       "6                [0.48076923, 0.620689655]        0.825239  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.882409  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.839697  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.892249  \n",
       "3                            [0.666666666]        0.816359  \n",
       "4                            [0.654867256]        0.801648  \n",
       "5               [0.637168141, 0.620689655]        0.776649  \n",
       "6                [0.48076923, 0.620689655]        0.776649  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.199660  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.498927  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.518656  \n",
       "3                            [0.666666666]        0.519684  \n",
       "4                            [0.654867256]        0.530131  \n",
       "5               [0.637168141, 0.620689655]        0.467319  \n",
       "6                [0.48076923, 0.620689655]        0.467319  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.000000  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.000000  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.162913  \n",
       "3                            [0.666666666]        0.000000  \n",
       "4                            [0.654867256]        0.000000  \n",
       "5               [0.637168141, 0.620689655]        0.241480  \n",
       "6                [0.48076923, 0.620689655]        0.241480  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.987512  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.961903  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.961903  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.405431  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.806157  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.863034  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfResult = pd.concat([referenceresult, withoutverylowMI, withoutlowMI, withoutmediumMI, kmeansundersampling, SMOTERes])\n",
    "dfResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d7c6ddd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>The referencemax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 16:31:18.853308</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.461171</td>\n",
       "      <td>0.979557</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.661017</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.987512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>The referencen_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:31:22.707671</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.114752</td>\n",
       "      <td>0.938324</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.686567</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.961903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest ClassifierWeighted22</th>\n",
       "      <td>The referencen_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:33.443986</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.862324</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.654867</td>\n",
       "      <td>[0.703703703]</td>\n",
       "      <td>[0.654867256]</td>\n",
       "      <td>0.863034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest ClassifierWeighted500</th>\n",
       "      <td>The referencen_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:33.010695</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.862324</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>0.863034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifierUnderSampling</th>\n",
       "      <td>The referenceundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 16:30:34.949979</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>4.885998</td>\n",
       "      <td>0.824649</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.825239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifierUpperSampling</th>\n",
       "      <td>The referenceupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 16:30:34.208445</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>4.885998</td>\n",
       "      <td>0.824649</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.637168</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.825239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>The referencescale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 16:31:25.958940</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.114752</td>\n",
       "      <td>0.938324</td>\n",
       "      <td>0.711864</td>\n",
       "      <td>0.715447</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.961903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                         Description  \\\n",
       "Model                                                                                                  \n",
       "DecisionTreeClassifier                           The referencemax_leaf_nodes : 6 + with date columns   \n",
       "Random Forest Classifier                                    The referencen_estimators : 36 + Entropy   \n",
       "Random Forest ClassifierWeighted22                          The referencen_estimators : 36 + Entropy   \n",
       "Random Forest ClassifierWeighted500                         The referencen_estimators : 36 + Entropy   \n",
       "RandomForestClassifierUnderSampling  The referenceundersampled, n_estimators=36, criterion = entropy   \n",
       "RandomForestClassifierUpperSampling     The referenceupsampled, n_estimators=36, criterion = entropy   \n",
       "XGBClassifier                                                     The referencescale_pos_weight = 22   \n",
       "\n",
       "                                                          Date  Precision  \\\n",
       "Model                                                                       \n",
       "DecisionTreeClassifier              2023-05-07 16:31:18.853308   0.980392   \n",
       "Random Forest Classifier            2023-05-07 16:31:22.707671   0.979592   \n",
       "Random Forest ClassifierWeighted22  2023-05-07 16:30:33.443986   0.804348   \n",
       "Random Forest ClassifierWeighted500 2023-05-07 16:30:33.010695   0.804348   \n",
       "RandomForestClassifierUnderSampling 2023-05-07 16:30:34.949979   0.777778   \n",
       "RandomForestClassifierUpperSampling 2023-05-07 16:30:34.208445   0.777778   \n",
       "XGBClassifier                       2023-05-07 16:31:25.958940   0.979592   \n",
       "\n",
       "                                     Recall  F1-score   LogLoss       Mcc  \\\n",
       "Model                                                                       \n",
       "DecisionTreeClassifier                1.000  0.990099  0.461171  0.979557   \n",
       "Random Forest Classifier              0.960  0.969697  1.114752  0.938324   \n",
       "Random Forest ClassifierWeighted22    0.925  0.860465  0.060284  0.862324   \n",
       "Random Forest ClassifierWeighted500   0.925  0.860465  0.060284  0.862324   \n",
       "RandomForestClassifierUnderSampling   0.875  0.823529  4.885998  0.824649   \n",
       "RandomForestClassifierUpperSampling   0.875  0.823529  4.885998  0.824649   \n",
       "XGBClassifier                         0.960  0.969697  1.114752  0.938324   \n",
       "\n",
       "                                     PublicScore  PrivateScore  \\\n",
       "Model                                                            \n",
       "DecisionTreeClassifier                  0.666667      0.661017   \n",
       "Random Forest Classifier                0.709677      0.686567   \n",
       "Random Forest ClassifierWeighted22      0.703704      0.654867   \n",
       "Random Forest ClassifierWeighted500     0.678571      0.666667   \n",
       "RandomForestClassifierUnderSampling     0.642857      0.620690   \n",
       "RandomForestClassifierUpperSampling     0.678571      0.637168   \n",
       "XGBClassifier                           0.711864      0.715447   \n",
       "\n",
       "                                                              OldPublicScore  \\\n",
       "Model                                                                          \n",
       "DecisionTreeClassifier               [0.666666666, 0.666666666, 0.006575486]   \n",
       "Random Forest Classifier              [0.69090909, 0.666666666, 0.007513148]   \n",
       "Random Forest ClassifierWeighted22                             [0.703703703]   \n",
       "Random Forest ClassifierWeighted500                            [0.678571428]   \n",
       "RandomForestClassifierUnderSampling               [0.549019607, 0.642857142]   \n",
       "RandomForestClassifierUpperSampling               [0.678571428, 0.642857142]   \n",
       "XGBClassifier                        [0.677419354, 0.711864406, 0.092764378]   \n",
       "\n",
       "                                                             OldPrivateScore  \\\n",
       "Model                                                                          \n",
       "DecisionTreeClassifier               [0.661016949, 0.661016949, 0.006863327]   \n",
       "Random Forest Classifier             [0.649122807, 0.649122807, 0.007794933]   \n",
       "Random Forest ClassifierWeighted22                             [0.654867256]   \n",
       "Random Forest ClassifierWeighted500                            [0.666666666]   \n",
       "RandomForestClassifierUnderSampling                [0.48076923, 0.620689655]   \n",
       "RandomForestClassifierUpperSampling               [0.637168141, 0.620689655]   \n",
       "XGBClassifier                        [0.676923076, 0.715447154, 0.096564531]   \n",
       "\n",
       "                                     MeanOurMetrics  \n",
       "Model                                                \n",
       "DecisionTreeClassifier                     0.987512  \n",
       "Random Forest Classifier                   0.961903  \n",
       "Random Forest ClassifierWeighted22         0.863034  \n",
       "Random Forest ClassifierWeighted500        0.863034  \n",
       "RandomForestClassifierUnderSampling        0.825239  \n",
       "RandomForestClassifierUpperSampling        0.825239  \n",
       "XGBClassifier                              0.961903  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfResult.groupby(\"Model\").max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e425a7b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can only compare identically-labeled Series objects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dfResult[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDescription\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mloc[[\u001b[43mdfResult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPublicScore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdfResult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mModel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPublicScore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m]]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\AILab-ECAM4\\lib\\site-packages\\pandas\\core\\ops\\common.py:72\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     70\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\AILab-ECAM4\\lib\\site-packages\\pandas\\core\\arraylike.py:42\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\AILab-ECAM4\\lib\\site-packages\\pandas\\core\\series.py:6237\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   6234\u001b[0m res_name \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mget_op_result_name(\u001b[38;5;28mself\u001b[39m, other)\n\u001b[0;32m   6236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, Series) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indexed_same(other):\n\u001b[1;32m-> 6237\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only compare identically-labeled Series objects\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6239\u001b[0m lvalues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   6240\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mValueError\u001b[0m: Can only compare identically-labeled Series objects"
     ]
    }
   ],
   "source": [
    "dfResult[[\"Description\"]].loc[[dfResult['PublicScore'] == dfResult.groupby([\"Model\"])['PublicScore'].max()]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71d0234",
   "metadata": {},
   "source": [
    "# Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3ba35bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>La basemax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-06 20:37:01.701978</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>0.857566</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>[0.661016949]</td>\n",
       "      <td>0.857900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>La basen_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-06 20:37:02.891559</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.019592</td>\n",
       "      <td>0.848262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909]</td>\n",
       "      <td>[0.649122807]</td>\n",
       "      <td>0.848830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>La basescale_pos_weight = 22</td>\n",
       "      <td>2023-05-06 20:37:04.316049</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.881747</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354]</td>\n",
       "      <td>[0.676923076]</td>\n",
       "      <td>0.882152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>La baseupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-06 20:37:06.774426</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.022606</td>\n",
       "      <td>0.829975</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.637168141]</td>\n",
       "      <td>0.830880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>La baseundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-06 20:37:09.025865</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.022606</td>\n",
       "      <td>0.829975</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.549019607]</td>\n",
       "      <td>[0.48076923]</td>\n",
       "      <td>0.830880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Kmeans UnderSamplingn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:31:00.285578</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.114752</td>\n",
       "      <td>0.938324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.961903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Kmeans UnderSamplingon balanced data</td>\n",
       "      <td>2023-05-07 16:31:00.404309</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.114752</td>\n",
       "      <td>0.938324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.961903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>SMOTEmax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 16:31:18.853308</td>\n",
       "      <td>0.113372</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.203125</td>\n",
       "      <td>0.461171</td>\n",
       "      <td>0.330225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.405431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>SMOTEn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:31:22.707671</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.027128</td>\n",
       "      <td>0.804629</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.806157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>SMOTEon balanced data</td>\n",
       "      <td>2023-05-07 16:31:25.958940</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.862324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.863034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Model  \\\n",
       "0               Decision Tree Classifier   \n",
       "1               Random Forest Classifier   \n",
       "2                          XGBClassifier   \n",
       "3    RandomForestClassifierUpperSampling   \n",
       "4    RandomForestClassifierUnderSampling   \n",
       "..                                   ...   \n",
       "248             Random Forest Classifier   \n",
       "249                        XGBClassifier   \n",
       "250               DecisionTreeClassifier   \n",
       "251             Random Forest Classifier   \n",
       "252                        XGBClassifier   \n",
       "\n",
       "                                                   Description  \\\n",
       "0                La basemax_leaf_nodes : 6 + with date columns   \n",
       "1                           La basen_estimators : 36 + Entropy   \n",
       "2                                 La basescale_pos_weight = 22   \n",
       "3       La baseupsampled, n_estimators=36, criterion = entropy   \n",
       "4    La baseundersampled, n_estimators=36, criterion = entropy   \n",
       "..                                                         ...   \n",
       "248            Kmeans UnderSamplingn_estimators : 36 + Entropy   \n",
       "249                       Kmeans UnderSamplingon balanced data   \n",
       "250                SMOTEmax_leaf_nodes : 6 + with date columns   \n",
       "251                           SMOTEn_estimators : 36 + Entropy   \n",
       "252                                      SMOTEon balanced data   \n",
       "\n",
       "                           Date  Precision  Recall  F1-score   LogLoss  \\\n",
       "0    2023-05-06 20:37:01.701978   0.891892   0.825  0.857143  0.016578   \n",
       "1    2023-05-06 20:37:02.891559   0.800000   0.900  0.847059  0.019592   \n",
       "2    2023-05-06 20:37:04.316049   0.840909   0.925  0.880952  0.015071   \n",
       "3    2023-05-06 20:37:06.774426   0.765957   0.900  0.827586  0.022606   \n",
       "4    2023-05-06 20:37:09.025865   0.765957   0.900  0.827586  0.022606   \n",
       "..                          ...        ...     ...       ...       ...   \n",
       "248  2023-05-07 16:31:00.285578   0.979592   0.960  0.969697  1.114752   \n",
       "249  2023-05-07 16:31:00.404309   0.979592   0.960  0.969697  1.114752   \n",
       "250  2023-05-07 16:31:18.853308   0.113372   0.975  0.203125  0.461171   \n",
       "251  2023-05-07 16:31:22.707671   0.720000   0.900  0.800000  0.027128   \n",
       "252  2023-05-07 16:31:25.958940   0.804348   0.925  0.860465  0.018085   \n",
       "\n",
       "          Mcc  PublicScore  PrivateScore  \\\n",
       "0    0.857566          NaN           NaN   \n",
       "1    0.848262          NaN           NaN   \n",
       "2    0.881747          NaN           NaN   \n",
       "3    0.829975          NaN           NaN   \n",
       "4    0.829975          NaN           NaN   \n",
       "..        ...          ...           ...   \n",
       "248  0.938324          NaN           NaN   \n",
       "249  0.938324          NaN           NaN   \n",
       "250  0.330225          NaN           NaN   \n",
       "251  0.804629          NaN           NaN   \n",
       "252  0.862324          NaN           NaN   \n",
       "\n",
       "                              OldPublicScore  \\\n",
       "0                              [0.666666666]   \n",
       "1                               [0.69090909]   \n",
       "2                              [0.677419354]   \n",
       "3                              [0.678571428]   \n",
       "4                              [0.549019607]   \n",
       "..                                       ...   \n",
       "248   [0.69090909, 0.666666666, 0.007513148]   \n",
       "249  [0.677419354, 0.711864406, 0.092764378]   \n",
       "250  [0.666666666, 0.666666666, 0.006575486]   \n",
       "251   [0.69090909, 0.666666666, 0.007513148]   \n",
       "252  [0.677419354, 0.711864406, 0.092764378]   \n",
       "\n",
       "                             OldPrivateScore  MeanOurMetrics  \n",
       "0                              [0.661016949]        0.857900  \n",
       "1                              [0.649122807]        0.848830  \n",
       "2                              [0.676923076]        0.882152  \n",
       "3                              [0.637168141]        0.830880  \n",
       "4                               [0.48076923]        0.830880  \n",
       "..                                       ...             ...  \n",
       "248  [0.649122807, 0.649122807, 0.007794933]        0.961903  \n",
       "249  [0.676923076, 0.715447154, 0.096564531]        0.961903  \n",
       "250  [0.661016949, 0.661016949, 0.006863327]        0.405431  \n",
       "251  [0.649122807, 0.649122807, 0.007794933]        0.806157  \n",
       "252  [0.676923076, 0.715447154, 0.096564531]        0.863034  \n",
       "\n",
       "[253 rows x 13 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfresult  = pd.read_csv(\"output/resultatsTestEverything.csv\")\n",
    "dfresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b9a49624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les meilleurs résultat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarah\\AppData\\Local\\Temp\\ipykernel_2988\\2367281751.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  dfresult.groupby(['Model'])['Precision','Recall','F1-score','LogLoss','MeanOurMetrics'].max()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classifier</th>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.882409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.461171</td>\n",
       "      <td>0.987512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.114752</td>\n",
       "      <td>0.961903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest ClassifierWeighted</th>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.863034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest ClassifierWeighted22</th>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.863034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest ClassifierWeighted500</th>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.863034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifierUnderSampling</th>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>4.923675</td>\n",
       "      <td>0.839697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifierUpperSampling</th>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>4.923675</td>\n",
       "      <td>0.839697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.114752</td>\n",
       "      <td>0.961903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Precision  Recall  F1-score   LogLoss  \\\n",
       "Model                                                                        \n",
       "Decision Tree Classifier              0.942857   0.825  0.880000  0.060284   \n",
       "DecisionTreeClassifier                0.980392   1.000  0.990099  0.461171   \n",
       "Random Forest Classifier              0.979592   0.960  0.969697  1.114752   \n",
       "Random Forest ClassifierWeighted      0.804348   0.925  0.860465  0.018085   \n",
       "Random Forest ClassifierWeighted22    0.823529   0.925  0.860465  0.060284   \n",
       "Random Forest ClassifierWeighted500   0.804348   0.925  0.860465  0.060284   \n",
       "RandomForestClassifierUnderSampling   0.782609   0.900  0.837209  4.923675   \n",
       "RandomForestClassifierUpperSampling   0.782609   0.900  0.837209  4.923675   \n",
       "XGBClassifier                         0.979592   0.960  0.969697  1.114752   \n",
       "\n",
       "                                     MeanOurMetrics  \n",
       "Model                                                \n",
       "Decision Tree Classifier                   0.882409  \n",
       "DecisionTreeClassifier                     0.987512  \n",
       "Random Forest Classifier                   0.961903  \n",
       "Random Forest ClassifierWeighted           0.863034  \n",
       "Random Forest ClassifierWeighted22         0.863034  \n",
       "Random Forest ClassifierWeighted500        0.863034  \n",
       "RandomForestClassifierUnderSampling        0.839697  \n",
       "RandomForestClassifierUpperSampling        0.839697  \n",
       "XGBClassifier                              0.961903  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Les meilleurs résultat\")\n",
    "dfresult.groupby(['Model'])['Precision','Recall','F1-score','LogLoss','MeanOurMetrics'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6e794338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les pire résultat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarah\\AppData\\Local\\Temp\\ipykernel_2988\\2101499374.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  dfresult.groupby(['Model'])['Precision','Recall','F1-score','LogLoss','MeanOurMetrics'].min()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classifier</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.013564</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.113372</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.013564</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.019592</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest ClassifierWeighted</th>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.863034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest ClassifierWeighted22</th>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest ClassifierWeighted500</th>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifierUnderSampling</th>\n",
       "      <td>0.010398</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.020544</td>\n",
       "      <td>0.021099</td>\n",
       "      <td>0.241480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifierUpperSampling</th>\n",
       "      <td>0.010398</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.020544</td>\n",
       "      <td>0.021099</td>\n",
       "      <td>0.241480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.162791</td>\n",
       "      <td>0.013564</td>\n",
       "      <td>0.162913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Precision  Recall  F1-score   LogLoss  \\\n",
       "Model                                                                        \n",
       "Decision Tree Classifier              0.500000   0.000  0.090909  0.013564   \n",
       "DecisionTreeClassifier                0.113372   0.000  0.090909  0.013564   \n",
       "Random Forest Classifier              0.566667   0.000  0.484848  0.019592   \n",
       "Random Forest ClassifierWeighted      0.804348   0.925  0.860465  0.018085   \n",
       "Random Forest ClassifierWeighted22    0.653846   0.000  0.491228  0.018085   \n",
       "Random Forest ClassifierWeighted500   0.629630   0.000  0.482759  0.018085   \n",
       "RandomForestClassifierUnderSampling   0.010398   0.400  0.020544  0.021099   \n",
       "RandomForestClassifierUpperSampling   0.010398   0.400  0.020544  0.021099   \n",
       "XGBClassifier                         0.152174   0.175  0.162791  0.013564   \n",
       "\n",
       "                                     MeanOurMetrics  \n",
       "Model                                                \n",
       "Decision Tree Classifier                   0.000000  \n",
       "DecisionTreeClassifier                     0.000000  \n",
       "Random Forest Classifier                   0.000000  \n",
       "Random Forest ClassifierWeighted           0.863034  \n",
       "Random Forest ClassifierWeighted22         0.000000  \n",
       "Random Forest ClassifierWeighted500        0.000000  \n",
       "RandomForestClassifierUnderSampling        0.241480  \n",
       "RandomForestClassifierUpperSampling        0.241480  \n",
       "XGBClassifier                              0.162913  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Les pire résultat\")\n",
    "dfresult.groupby(['Model'])['Precision','Recall','F1-score','LogLoss','MeanOurMetrics'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "596a8536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_undersampled"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
