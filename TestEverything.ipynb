{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efcbf836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import resample\n",
    "from sklearn.cluster import KMeans \n",
    "import datetime as dt\n",
    "from math import ceil, sqrt\n",
    "from Utils import *\n",
    "pd.set_option('max_colwidth', None)\n",
    "from EvaluationMetric import *\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bae6abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparemodels(train_X, train_y, val_X, test_X, generaldescription, unbalanced = True):\n",
    "    res = []\n",
    "\n",
    "    model1 = DecisionTreeClassifier(max_leaf_nodes= 6, random_state=1)\n",
    "    model1.fit(train_X, train_y)\n",
    "    preds_val1 = model1.predict(val_X)\n",
    "    model_test1 = model1.predict(test_X)\n",
    "    description = generaldescription+\"max_leaf_nodes : 6 + with date columns\"\n",
    "    metrics1 = listmetrics(val_y, preds_val1, \"DecisionTreeClassifier\", description)\n",
    "    m1Public = [0.666666666, 0.666666666, 0.006575486]\n",
    "    m1Private = [0.661016949, 0.661016949, 0.006863327]\n",
    "    res.append(metrics1)\n",
    "    df1 = getscoreforcsv(index_val, model_test1, name_file = \"TreeClass5leaf.csv\")\n",
    "\n",
    "\n",
    "    model2 = RandomForestClassifier(n_estimators=36, criterion = 'entropy', random_state=1)\n",
    "    model2.fit(train_X, train_y)\n",
    "    preds_val2 = model2.predict(val_X)\n",
    "    model_test2 = model2.predict(test_X)\n",
    "    description = generaldescription+\"n_estimators : 36 + Entropy\"\n",
    "    metrics2 = listmetrics(val_y, preds_val2, \"Random Forest Classifier\", description)\n",
    "    m2Public = [0.690909090, 0.666666666, 0.007513148]\n",
    "    m2Private = [0.649122807, 0.649122807, 0.007794933]\n",
    "    res.append(metrics2)\n",
    "    df2 = getscoreforcsv(index_val, model_test2, name_file = \"RandomForestN36Entropy.csv\")\n",
    "\n",
    "\n",
    "    ##################ICi donne un 0.71 de scrore !!! mtn comprendre pq en diminuant les feature si bon score mais que pour lui !############\n",
    "    #Ne fonctionne pas bien quadn le training set est entier. \n",
    "    if (unbalanced) : \n",
    "        model2 = XGBClassifier(scale_pos_weight=22, random_state=1)\n",
    "        description = generaldescription+\"scale_pos_weight = 22\"\n",
    "    else : \n",
    "        model2 = XGBClassifier(random_state=1)\n",
    "        description = generaldescription+\"on balanced data\"\n",
    "    model2.fit(train_X, train_y)\n",
    "    preds_val2 = model2.predict(val_X)\n",
    "    model_test2 = model2.predict(test_X)\n",
    "    metrics2 = listmetrics(val_y, preds_val2, \"XGBClassifier\", description)\n",
    "    m3Public = [0.677419354, 0.711864406, 0.092764378]\n",
    "    m3Private = [0.676923076,  0.715447154, 0.096564531]\n",
    "    res.append(metrics2)\n",
    "    df2 = getscoreforcsv(index_val, model_test2, name_file = \"XGBClassifierW22.csv\")\n",
    "    \n",
    "    if (unbalanced) :\n",
    "        \n",
    "        model2 = RandomForestClassifier(n_estimators=36, criterion = 'entropy', class_weight = {0: 95469, 1 : 193}, random_state=1)\n",
    "        model2.fit(train_X, train_y)\n",
    "        preds_val2 = model2.predict(val_X)\n",
    "        model_test2 = model2.predict(test_X)\n",
    "        description = generaldescription+\"n_estimators : 36 + Entropy\"\n",
    "        metrics2 = listmetrics(val_y, preds_val2, \"Random Forest ClassifierWeighted500\", description)\n",
    "        m500Public = [0.678571428]\n",
    "        m500Private = [0.666666666]\n",
    "        res.append(metrics2)\n",
    "        df2 = getscoreforcsv(index_val, model_test2, name_file = \"RandomForestWeigthed500.csv\")\n",
    "\n",
    "        model2 = RandomForestClassifier(n_estimators=36, criterion = 'entropy', class_weight = {0: 22, 1 : 1}, random_state=1)\n",
    "        model2.fit(train_X, train_y)\n",
    "        preds_val2 = model2.predict(val_X)\n",
    "        model_test2 = model2.predict(test_X)\n",
    "        description = generaldescription+\"n_estimators : 36 + Entropy\"\n",
    "        metrics2 = listmetrics(val_y, preds_val2, \"Random Forest ClassifierWeighted22\", description)\n",
    "        m22Public = [0.703703703]\n",
    "        m22Private = [0.654867256]\n",
    "        res.append(metrics2)\n",
    "        df2 = getscoreforcsv(index_val, model_test2, name_file = \"RandomForestWeigthed22.csv\")\n",
    "\n",
    "        #oversamplesimple\n",
    "        X_con = pd.concat([train_X, train_y], axis=1) \n",
    "        not_fraud = X_con[X_con.FraudResult==0]\n",
    "        fraud = X_con[X_con.FraudResult==1]\n",
    "        fraud_upsampled = resample(fraud, replace=True, n_samples=len(not_fraud), # match number in majority class\n",
    "                                random_state=1) # reproducible results\n",
    "        upsampled = pd.concat([not_fraud, fraud_upsampled])\n",
    "        train_y_over_sampled = upsampled.FraudResult\n",
    "        train_X_over_sampled = upsampled.drop('FraudResult', axis=1)\n",
    "        upsampledmodel = RandomForestClassifier(n_estimators=36, criterion = 'entropy', random_state=1)\n",
    "        upsampledmodel.fit(train_X_over_sampled, train_y_over_sampled)\n",
    "        upsampled_pred = upsampledmodel.predict(val_X)\n",
    "        model_test = upsampledmodel.predict(test_X)\n",
    "        description = generaldescription+\"upsampled, n_estimators=36, criterion = entropy\"\n",
    "        metrics = listmetrics(val_y, upsampled_pred, \"RandomForestClassifierUpperSampling\", description)\n",
    "        m4Public = [0.678571428, 0.642857142]\n",
    "        m4Private = [0.637168141, 0.620689655]\n",
    "        res.append(metrics)\n",
    "        df = getscoreforcsv(index_val, model_test, name_file = \"RandomForestClassifierUpSample.csv\")\n",
    "\n",
    "        #Undersampling\n",
    "        not_fraud_downsampled  = resample(not_fraud, replace=False, n_samples=len(fraud), # match number in minority  class\n",
    "                                random_state=1) # reproducible results\n",
    "        downsampled  = pd.concat([not_fraud_downsampled , fraud])\n",
    "        train_y_undersampled = downsampled.FraudResult\n",
    "        train_X_undersampled = downsampled.drop('FraudResult', axis=1)\n",
    "        undersampled = RandomForestClassifier(n_estimators=36, criterion = 'entropy', random_state=1)\n",
    "        undersampled.fit(train_X_over_sampled, train_y_over_sampled)\n",
    "        undersampled_pred = undersampled.predict(val_X)\n",
    "        model_test = undersampled.predict(test_X)\n",
    "        description = generaldescription+\"undersampled, n_estimators=36, criterion = entropy\"\n",
    "        metrics = listmetrics(val_y, undersampled_pred, \"RandomForestClassifierUnderSampling\", description)\n",
    "        m5Public = [0.549019607, 0.642857142]\n",
    "        m5Private = [0.480769230, 0.620689655]\n",
    "        res.append(metrics)\n",
    "        df = getscoreforcsv(index_val, model_test, name_file = \"RandomForestClassifierUndersampled.csv\")\n",
    "        \n",
    "        loldPublics = [m1Public, m2Public, m3Public, m500Public,m22Public, m4Public, m5Public]\n",
    "        loldPrivate = [m1Private, m2Private, m3Private, m500Private, m22Private, m4Private, m5Private]\n",
    "        \n",
    "    else:\n",
    "        loldPublics = [m1Public, m2Public, m3Public]\n",
    "        loldPrivate = [m1Private, m2Private,  m3Private]\n",
    "        \n",
    "\n",
    "\n",
    "    dfres = listmetricsintodf(res)\n",
    "    dfres[\"OldPublicScore\"] = loldPublics\n",
    "    dfres[\"OldPrivateScore\"] = loldPrivate\n",
    "    dfres[\"MeanOurMetrics\"] = dfres[['Precision', 'Recall','F1-score','Mcc']].mean(axis=1)\n",
    "    dfres.to_csv('output/resultatsTestEverything.csv', mode='a',index=False,header = False) \n",
    "    return dfres"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5eab429b",
   "metadata": {},
   "source": [
    "# Test de different model with different Data Here\n",
    "## 1. The reference model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73a9d70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>The referencemax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 17:13:04.925314</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>0.857566</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.661017</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.857900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>The referencen_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 17:13:06.212309</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.843373</td>\n",
       "      <td>0.019592</td>\n",
       "      <td>0.843655</td>\n",
       "      <td>0.690909</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.843995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>The referencescale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 17:13:07.820313</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>0.871874</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.676923</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.872421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest ClassifierWeighted500</td>\n",
       "      <td>The referencen_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 17:13:09.089720</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.862324</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>0.863034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest ClassifierWeighted22</td>\n",
       "      <td>The referencen_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 17:13:10.306257</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.862324</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.654867</td>\n",
       "      <td>[0.703703703]</td>\n",
       "      <td>[0.654867256]</td>\n",
       "      <td>0.863034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>The referenceupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 17:13:12.948836</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.022606</td>\n",
       "      <td>0.824649</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.637168</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.825239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>The referenceundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 17:13:15.482278</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.022606</td>\n",
       "      <td>0.824649</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.825239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Model  \\\n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  Random Forest ClassifierWeighted500   \n",
       "4   Random Forest ClassifierWeighted22   \n",
       "5  RandomForestClassifierUpperSampling   \n",
       "6  RandomForestClassifierUnderSampling   \n",
       "\n",
       "                                                       Description  \\\n",
       "0              The referencemax_leaf_nodes : 6 + with date columns   \n",
       "1                         The referencen_estimators : 36 + Entropy   \n",
       "2                               The referencescale_pos_weight = 22   \n",
       "3                         The referencen_estimators : 36 + Entropy   \n",
       "4                         The referencen_estimators : 36 + Entropy   \n",
       "5     The referenceupsampled, n_estimators=36, criterion = entropy   \n",
       "6  The referenceundersampled, n_estimators=36, criterion = entropy   \n",
       "\n",
       "                        Date  Precision  Recall  F1-score   LogLoss       Mcc  \\\n",
       "0 2023-05-07 17:13:04.925314   0.891892   0.825  0.857143  0.016578  0.857566   \n",
       "1 2023-05-07 17:13:06.212309   0.813953   0.875  0.843373  0.019592  0.843655   \n",
       "2 2023-05-07 17:13:07.820313   0.822222   0.925  0.870588  0.016578  0.871874   \n",
       "3 2023-05-07 17:13:09.089720   0.804348   0.925  0.860465  0.018085  0.862324   \n",
       "4 2023-05-07 17:13:10.306257   0.804348   0.925  0.860465  0.018085  0.862324   \n",
       "5 2023-05-07 17:13:12.948836   0.777778   0.875  0.823529  0.022606  0.824649   \n",
       "6 2023-05-07 17:13:15.482278   0.777778   0.875  0.823529  0.022606  0.824649   \n",
       "\n",
       "   PublicScore  PrivateScore                           OldPublicScore  \\\n",
       "0     0.666667      0.661017  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1     0.690909      0.649123   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2     0.677419      0.676923  [0.677419354, 0.711864406, 0.092764378]   \n",
       "3     0.678571      0.666667                            [0.678571428]   \n",
       "4     0.703704      0.654867                            [0.703703703]   \n",
       "5     0.678571      0.637168               [0.678571428, 0.642857142]   \n",
       "6     0.549020      0.480769               [0.549019607, 0.642857142]   \n",
       "\n",
       "                           OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.857900  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.843995  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.872421  \n",
       "3                            [0.666666666]        0.863034  \n",
       "4                            [0.654867256]        0.863034  \n",
       "5               [0.637168141, 0.620689655]        0.825239  \n",
       "6                [0.48076923, 0.620689655]        0.825239  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def_feature = pd.read_csv(\"input/Xente_Variable_Definitions.csv\")\n",
    "raw_data = pd.read_csv(\"input/training.csv\")\n",
    "X_test = pd.read_csv(\"input/test.csv\")\n",
    "sample_submission = pd.read_csv(\"input/sample_submission.csv\")\n",
    "\n",
    "#attribut initialization\n",
    "cols_unique_value = [] #Will be droped\n",
    "for col in raw_data.columns : \n",
    "    if len(raw_data[col].unique()) == 1 :\n",
    "        cols_unique_value.append(col)\n",
    "\n",
    "medium_cardianlity_cols = [\"ProductId\"]\n",
    "\n",
    "#Data transformation\n",
    "raw_data['TransactionStartTime'] = pd.to_datetime(raw_data['TransactionStartTime'])\n",
    "X_test['TransactionStartTime'] = pd.to_datetime(X_test['TransactionStartTime'])\n",
    "\n",
    "#Data cleaning\n",
    "data = raw_data.copy()\n",
    "data = data.dropna(axis=0) #Drop observations/rows with missing values\n",
    "X_test=X_test.dropna(axis=0)\n",
    "data.drop(cols_unique_value, axis=1, inplace=True)\n",
    "X_test.drop(cols_unique_value, axis=1, inplace=True)\n",
    "\n",
    "#Prepare index for the submission\n",
    "index_val = list(X_test.TransactionId.values.tolist())\n",
    "\n",
    "#Set the df index to the Transction Id\n",
    "data = transactioId_to_index(data)\n",
    "X_test = transactioId_to_index(X_test)\n",
    "\n",
    "#Adding data\n",
    "data = adding_date_col(data, 'TransactionStartTime')\n",
    "X_test = adding_date_col(X_test, 'TransactionStartTime')\n",
    "\n",
    "\n",
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "low_cardinality_cols = [cname for cname in data.columns if data[cname].nunique() < 15 and \n",
    "                        data[cname].dtype == \"object\"]\n",
    "low_cardinality_cols.append('PricingStrategy')\n",
    "\n",
    "#transform columns BatchId_54 to number\n",
    "    #transform columns BatchId_54 to number\n",
    "id_cols = data.filter(like=\"Id\").columns.tolist()\n",
    "data[id_cols] = data[id_cols].astype(str).apply(lambda x: x.str.replace(x.name + \"_\", \"\")).astype(int)\n",
    "X_test[id_cols] = X_test[id_cols].astype(str).apply(lambda x: x.str.replace(x.name + \"_\", \"\")).astype(int)\n",
    "\n",
    "data['PricingStrategy'] = data['PricingStrategy'].astype('int')\n",
    "X_test['PricingStrategy'] = X_test['PricingStrategy'].astype('int')\n",
    "data['Value'] = data['Value'].astype('float')\n",
    "X_test['Value'] = X_test['Value'].astype('float')\n",
    "\n",
    "X_test['PricingStrategy'] = X_test['PricingStrategy'].astype('str')\n",
    "data['PricingStrategy'] = data['PricingStrategy'].astype('str')\n",
    "\n",
    "#Data splitting\n",
    "y = data.FraudResult #The target label\n",
    "X = data.copy()\n",
    "X.drop(['FraudResult'], axis=1, inplace=True) #Only the features data\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "cat_cols = [col for col in X.columns if X[col].dtype == \"object\"]#liste of obejct columns\n",
    "cat_cols.append(\"PricingStrategy\")#pcq mm si c'est un chiffre il faut le considérer comme une catégorie\n",
    "\n",
    "\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(train_X[low_cardinality_cols]))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(val_X[low_cardinality_cols]))\n",
    "OH_cols_test = pd.DataFrame(OH_encoder.transform(X_test[low_cardinality_cols]))\n",
    "OH_cols_train.columns = OH_encoder.get_feature_names_out()\n",
    "OH_cols_valid.columns = OH_encoder.get_feature_names_out()\n",
    "OH_cols_test.columns = OH_encoder.get_feature_names_out()\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_train.index = train_X.index\n",
    "OH_cols_valid.index = val_X.index\n",
    "OH_cols_test.index = X_test.index\n",
    "\n",
    "OH_cols_train[list(OH_cols_train.columns)] = OH_cols_train[list(OH_cols_train.columns)].astype(int)\n",
    "OH_cols_valid[list(OH_cols_valid.columns)] = OH_cols_valid[list(OH_cols_valid.columns)].astype(int)\n",
    "OH_cols_test[list(OH_cols_test.columns)] = OH_cols_test[list(OH_cols_test.columns)].astype(int)\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train = train_X.drop(low_cardinality_cols, axis=1)\n",
    "num_X_valid = val_X.drop(low_cardinality_cols, axis=1)\n",
    "num_X_test = X_test.drop(low_cardinality_cols, axis=1)\n",
    "\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
    "OH_X_test = pd.concat([num_X_test, OH_cols_test], axis=1)\n",
    "\n",
    "# Problème de string\n",
    "OH_X_train.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_valid.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_test.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_train.columns = OH_X_train.columns.astype(str)\n",
    "OH_X_valid.columns = OH_X_valid.columns.astype(str)\n",
    "OH_X_test.columns = OH_X_test.columns.astype(str)\n",
    "\n",
    "train_X = OH_X_train\n",
    "val_X = OH_X_valid\n",
    "test_X = OH_X_test\n",
    "X_entier = pd.concat([train_X, val_X])\n",
    "\n",
    "referenceresult = comparemodels(train_X, train_y, val_X, test_X, \"The reference\")\n",
    "referenceresult[\"PublicScore\"] = [0.666666666, 0.690909090, 0.677419354, 0.678571428, 0.703703703, 0.678571428, 0.549019607]\n",
    "referenceresult[\"PrivateScore\"] = [0.661016949, 0.649122807,  0.676923076,0.666666666, 0.654867256, 0.637168141, 0.480769230]\n",
    "referenceresult"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd22a8e6",
   "metadata": {},
   "source": [
    "# Niko Test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "84994fe9",
   "metadata": {},
   "source": [
    "# Small preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6fb17ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"input/training.csv\")\n",
    "data = df.copy()\n",
    "y_train = df[\"FraudResult\"]\n",
    "X_test = pd.read_csv(\"input/test.csv\")\n",
    "X_valid = X_test.copy()\n",
    "sample_submission = pd.read_csv(\"input/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "65b295ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping column with one unique values:  ['CurrencyCode', 'CountryCode']\n",
      "Converting columns with Id:  ['TransactionId', 'BatchId', 'AccountId', 'SubscriptionId', 'CustomerId', 'ProviderId', 'ProductId', 'ChannelId']\n"
     ]
    }
   ],
   "source": [
    "# Count the number of unique entries in each column\n",
    "unique_counts = data.nunique()\n",
    "\n",
    "# Select only columns with more than one unique entry\n",
    "drop_cols = unique_counts[unique_counts == 1].index.tolist()\n",
    "print(\"Dropping column with one unique values: \", drop_cols)\n",
    "\n",
    "# Drop the selected columns\n",
    "data = data.drop(columns=drop_cols)\n",
    "X_test = X_test.drop(columns=drop_cols)\n",
    "\n",
    "# Get a list of column names that contain the string \"id\" in their name\n",
    "id_cols = data.filter(like=\"Id\").columns.tolist()\n",
    "\n",
    "# Print the list of column names\n",
    "print(\"Converting columns with Id: \", id_cols)\n",
    "\n",
    "# Remove column name prefix and convert to integer data type\n",
    "data[id_cols] = (\n",
    "    data[id_cols]\n",
    "    .astype(str)\n",
    "    .apply(lambda x: x.str.replace(x.name + \"_\", \"\"))\n",
    "    .astype(int)\n",
    ")\n",
    "X_test[id_cols] = (\n",
    "    X_test[id_cols]\n",
    "    .astype(str)\n",
    "    .apply(lambda x: x.str.replace(x.name + \"_\", \"\"))\n",
    "    .astype(int)\n",
    ")\n",
    "\n",
    "# convert TransactionStartTime column to datetime format\n",
    "data[\"TransactionStartTime\"] = pd.to_datetime(\n",
    "    df[\"TransactionStartTime\"], format=\"%Y-%m-%dT%H:%M:%SZ\"\n",
    ")\n",
    "X_test[\"TransactionStartTime\"] = pd.to_datetime(\n",
    "    X_test[\"TransactionStartTime\"], format=\"%Y-%m-%dT%H:%M:%SZ\"\n",
    ")\n",
    "\n",
    "# extract date and time features\n",
    "data[\"TransactionDayOfWeek\"] = data[\"TransactionStartTime\"].dt.dayofweek\n",
    "data[\"TransactionDayOfMonth\"] = data[\"TransactionStartTime\"].dt.day\n",
    "data[\"TransactionHour\"] = data[\"TransactionStartTime\"].dt.hour\n",
    "data[\"TransactionMinute\"] = data[\"TransactionStartTime\"].dt.minute\n",
    "\n",
    "X_test[\"TransactionDayOfWeek\"] = X_test[\"TransactionStartTime\"].dt.dayofweek\n",
    "X_test[\"TransactionDayOfMonth\"] = X_test[\"TransactionStartTime\"].dt.day\n",
    "X_test[\"TransactionHour\"] = X_test[\"TransactionStartTime\"].dt.hour\n",
    "X_test[\"TransactionMinute\"] = X_test[\"TransactionStartTime\"].dt.minute\n",
    "\n",
    "# drop TransactionStartTime\n",
    "data = data.drop(\"TransactionStartTime\", axis=1)\n",
    "X_test = X_test.drop(\"TransactionStartTime\", axis=1)\n",
    "\n",
    "# Factorize the \"ProductCategory\" column\n",
    "data['ProductCategory'] = pd.factorize(data['ProductCategory'])[0] + 1\n",
    "X_test['ProductCategory'] = pd.factorize(X_test['ProductCategory'])[0] + 1\n",
    "# Convert the \"ProductCategory\" column to integer data type\n",
    "data['ProductCategory'] = data['ProductCategory'].astype(int)\n",
    "X_test['ProductCategory'] = X_test['ProductCategory'].astype(int)\n",
    "\n",
    "# Removing redundant data\n",
    "data[\"Expense\"] = data[\"Amount\"] < 0\n",
    "data.Expense = data.Expense.astype(int)\n",
    "data = data.drop(\"Amount\", axis=1)\n",
    "\n",
    "X_test[\"Expense\"] = X_test[\"Amount\"] < 0\n",
    "X_test.Expense = X_test.Expense.astype(int)\n",
    "X_test = X_test.drop(\"Amount\", axis=1)\n",
    "\n",
    "# Continous value should be float\n",
    "data[\"Value\"] = data[\"Value\"].astype(float)\n",
    "X_test[\"Value\"] = X_test[\"Value\"].astype(float)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a5113b99",
   "metadata": {},
   "source": [
    "# Scenario 1: With All columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f35e9b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>With All Columnsmax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 17:16:41.946094</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.013564</td>\n",
       "      <td>0.881780</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.882409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>With All Columnsn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 17:16:43.878173</td>\n",
       "      <td>0.760870</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.024113</td>\n",
       "      <td>0.815615</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.816359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>With All Columnsscale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 17:16:45.254960</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.881747</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.882152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest ClassifierWeighted500</td>\n",
       "      <td>With All Columnsn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 17:16:47.191652</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.873563</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>0.876185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>0.877065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest ClassifierWeighted22</td>\n",
       "      <td>With All Columnsn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 17:16:49.097936</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.022606</td>\n",
       "      <td>0.835448</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.703703703]</td>\n",
       "      <td>[0.654867256]</td>\n",
       "      <td>0.836753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>With All Columnsupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 17:16:52.740316</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.028635</td>\n",
       "      <td>0.790189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.791498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>With All Columnsundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 17:16:56.256509</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.028635</td>\n",
       "      <td>0.790189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.791498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Model  \\\n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  Random Forest ClassifierWeighted500   \n",
       "4   Random Forest ClassifierWeighted22   \n",
       "5  RandomForestClassifierUpperSampling   \n",
       "6  RandomForestClassifierUnderSampling   \n",
       "\n",
       "                                                          Description  \\\n",
       "0              With All Columnsmax_leaf_nodes : 6 + with date columns   \n",
       "1                         With All Columnsn_estimators : 36 + Entropy   \n",
       "2                               With All Columnsscale_pos_weight = 22   \n",
       "3                         With All Columnsn_estimators : 36 + Entropy   \n",
       "4                         With All Columnsn_estimators : 36 + Entropy   \n",
       "5     With All Columnsupsampled, n_estimators=36, criterion = entropy   \n",
       "6  With All Columnsundersampled, n_estimators=36, criterion = entropy   \n",
       "\n",
       "                        Date  Precision  Recall  F1-score   LogLoss       Mcc  \\\n",
       "0 2023-05-07 17:16:41.946094   0.942857   0.825  0.880000  0.013564  0.881780   \n",
       "1 2023-05-07 17:16:43.878173   0.760870   0.875  0.813953  0.024113  0.815615   \n",
       "2 2023-05-07 17:16:45.254960   0.840909   0.925  0.880952  0.015071  0.881747   \n",
       "3 2023-05-07 17:16:47.191652   0.808511   0.950  0.873563  0.016578  0.876185   \n",
       "4 2023-05-07 17:16:49.097936   0.755102   0.925  0.831461  0.022606  0.835448   \n",
       "5 2023-05-07 17:16:52.740316   0.714286   0.875  0.786517  0.028635  0.790189   \n",
       "6 2023-05-07 17:16:56.256509   0.714286   0.875  0.786517  0.028635  0.790189   \n",
       "\n",
       "   PublicScore  PrivateScore                           OldPublicScore  \\\n",
       "0          NaN           NaN  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1          NaN           NaN   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2          NaN           NaN  [0.677419354, 0.711864406, 0.092764378]   \n",
       "3          NaN           NaN                            [0.678571428]   \n",
       "4          NaN           NaN                            [0.703703703]   \n",
       "5          NaN           NaN               [0.678571428, 0.642857142]   \n",
       "6          NaN           NaN               [0.549019607, 0.642857142]   \n",
       "\n",
       "                           OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.882409  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.816359  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.882152  \n",
       "3                            [0.666666666]        0.877065  \n",
       "4                            [0.654867256]        0.836753  \n",
       "5               [0.637168141, 0.620689655]        0.791498  \n",
       "6                [0.48076923, 0.620689655]        0.791498  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate data (drop FraudResult before)\n",
    "X_1 = data.drop(\"FraudResult\", axis=1)\n",
    "# mi_score = make_mi_scores(data, y_train)\n",
    "train_X, val_X, train_y, val_y = train_test_split(X_1, y_train, random_state = 0)\n",
    "result1 = comparemodels(train_X, train_y, val_X, X_test, \"With All Columns\", unbalanced=True)\n",
    "result1[\"PublicScore\"] = [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "result1[\"PrivateScore\"] = [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "result1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d808c490",
   "metadata": {},
   "source": [
    "# Scenario 2: Dropping Unique ID columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "49a7bf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropping_cols = [\"TransactionId\", \"BatchId\", \"AccountId\", \"CustomerId\", \"SubscriptionId\"]\n",
    "\n",
    "for col in dropping_cols:\n",
    "    data = data.drop(col, axis=1)\n",
    "    X_test = X_test.drop(col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "17906ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>The referencemax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 17:16:56.569963</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.871873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.872101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>The referencen_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 17:16:57.410561</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.839506</td>\n",
       "      <td>0.019592</td>\n",
       "      <td>0.839298</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.839518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>The referenceon balanced data</td>\n",
       "      <td>2023-05-07 17:16:58.119599</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.012057</td>\n",
       "      <td>0.899832</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.899958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model  \\\n",
       "0    DecisionTreeClassifier   \n",
       "1  Random Forest Classifier   \n",
       "2             XGBClassifier   \n",
       "\n",
       "                                           Description  \\\n",
       "0  The referencemax_leaf_nodes : 6 + with date columns   \n",
       "1             The referencen_estimators : 36 + Entropy   \n",
       "2                        The referenceon balanced data   \n",
       "\n",
       "                        Date  Precision  Recall  F1-score   LogLoss       Mcc  \\\n",
       "0 2023-05-07 17:16:56.569963   0.894737    0.85  0.871795  0.015071  0.871873   \n",
       "1 2023-05-07 17:16:57.410561   0.829268    0.85  0.839506  0.019592  0.839298   \n",
       "2 2023-05-07 17:16:58.119599   0.900000    0.90  0.900000  0.012057  0.899832   \n",
       "\n",
       "   PublicScore  PrivateScore                           OldPublicScore  \\\n",
       "0          NaN           NaN  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1          NaN           NaN   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2          NaN           NaN  [0.677419354, 0.711864406, 0.092764378]   \n",
       "\n",
       "                           OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.872101  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.839518  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.899958  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate data (drop FraudResult before)\n",
    "X_2 = data.drop(\"FraudResult\", axis=1)\n",
    "# mi_score = make_mi_scores(data, y_train)\n",
    "train_X, val_X, train_y, val_y = train_test_split(X_2, y_train, random_state = 0)\n",
    "result2 = comparemodels(train_X, train_y, val_X, X_test, \"Dropping Unique ID columns\", unbalanced=True)\n",
    "result2[\"PublicScore\"] = [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "result2[\"PrivateScore\"] = [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "result2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "309e715a",
   "metadata": {},
   "source": [
    "# Scenario 3: Adding new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5a214b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_col = [\"ProviderId\", \"ProductCategory\", \"ChannelId\", \"PricingStrategy\"]\n",
    "mean_std_col = ['ProductId', 'Expense', \"ProviderId\", \"ProductCategory\", \"ChannelId\", \"PricingStrategy\"]\n",
    "\n",
    "# Compute mean and standard deviation for specific features\n",
    "for feature in mean_std_col:\n",
    "    # Compute the mean and standard deviation of transactions for each feature\n",
    "    feature_avg_values = data.groupby(feature)['Value'].mean()\n",
    "    feature_std_values = data.groupby(feature)['Value'].std()\n",
    "    data[f\"{feature}_mean_amount\"] = data[feature].apply(lambda x: feature_avg_values[x])\n",
    "    data[f\"{feature}_std_amount\"] = data[feature].apply(lambda x: feature_std_values[x])\n",
    "    \n",
    "for feature in mean_std_col:\n",
    "    # Compute the mean and standard deviation of transactions for each feature\n",
    "    feature_avg_values = X_test.groupby(feature)['Value'].mean()\n",
    "    feature_std_values = X_test.groupby(feature)['Value'].std()\n",
    "    X_test[f\"{feature}_mean_amount\"] = X_test[feature].apply(lambda x: feature_avg_values[x])\n",
    "    X_test[f\"{feature}_std_amount\"] = X_test[feature].apply(lambda x: feature_std_values[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "edbaa3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the rows that contain missing values\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "402f8b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHot Encode categorical features\n",
    "data = pd.get_dummies(data, columns=categorical_col)\n",
    "# Adding missing col\n",
    "data[\"ChannelId_4\"] = False\n",
    "data[\"PricingStrategy_3\"] = False\n",
    "X_test = pd.get_dummies(X_test, columns=categorical_col)\n",
    "# Adding missing col\n",
    "X_test[\"PricingStrategy_3\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5d42f1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the boolean columns to integer columns\n",
    "bool_cols = data.select_dtypes(include=bool).columns.tolist()\n",
    "data[bool_cols] = data[bool_cols].astype(int)\n",
    "\n",
    "bool_cols = X_test.select_dtypes(include=bool).columns.tolist()\n",
    "X_test[bool_cols] = X_test[bool_cols].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "661ded45",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = data.FraudResult\n",
    "data.drop(\"FraudResult\", inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c8fd8eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_score = make_mi_scores(data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1c37814f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(dpi=100, figsize=(10, 8))\n",
    "plot_mi_scores(mi_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9de337b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>The referencemax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 17:17:28.841039</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.848426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.849240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>The referencen_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 17:17:29.871232</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.784810</td>\n",
       "      <td>0.025621</td>\n",
       "      <td>0.786037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.786695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>The referenceon balanced data</td>\n",
       "      <td>2023-05-07 17:17:31.480443</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.853662</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.853914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model  \\\n",
       "0    DecisionTreeClassifier   \n",
       "1  Random Forest Classifier   \n",
       "2             XGBClassifier   \n",
       "\n",
       "                                           Description  \\\n",
       "0  The referencemax_leaf_nodes : 6 + with date columns   \n",
       "1             The referencen_estimators : 36 + Entropy   \n",
       "2                        The referenceon balanced data   \n",
       "\n",
       "                        Date  Precision    Recall  F1-score   LogLoss  \\\n",
       "0 2023-05-07 17:17:28.841039   0.916667  0.785714  0.846154  0.018085   \n",
       "1 2023-05-07 17:17:29.871232   0.837838  0.738095  0.784810  0.025621   \n",
       "2 2023-05-07 17:17:31.480443   0.875000  0.833333  0.853659  0.018085   \n",
       "\n",
       "        Mcc  PublicScore  PrivateScore  \\\n",
       "0  0.848426          NaN           NaN   \n",
       "1  0.786037          NaN           NaN   \n",
       "2  0.853662          NaN           NaN   \n",
       "\n",
       "                            OldPublicScore  \\\n",
       "0  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2  [0.677419354, 0.711864406, 0.092764378]   \n",
       "\n",
       "                           OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.849240  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.786695  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.853914  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reorder the columns in alphabetical order\n",
    "data = data.sort_index(axis=1)\n",
    "X_test = X_test.sort_index(axis=1)\n",
    "\n",
    "# Evaluate data\n",
    "X_3 = data.copy()\n",
    "X_test_3 = X_test.copy()\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(X_3, y_train, random_state = 0)\n",
    "result3 = comparemodels(train_X, train_y, val_X, X_test_3, \"AddingNewFeature Niko\")\n",
    "result3[\"PublicScore\"] = [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "result3[\"PrivateScore\"] = [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "result3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ade3d808",
   "metadata": {},
   "source": [
    "# Removing Low MI columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e22cbe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_scores = make_mi_scores(X_3 , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5d2fe0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mediumMI = list(mi_scores[mi_scores<0.01].index)\n",
    "X_3.drop(mediumMI, inplace=True, axis=1, errors='ignore')\n",
    "X_test_3.drop(mediumMI, inplace=True, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d996dc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>The referencemax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 17:17:50.719659</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>0.859335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.861068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>The referencen_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 17:17:51.340465</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.845369</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.847513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>The referenceon balanced data</td>\n",
       "      <td>2023-05-07 17:17:52.007003</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.868421</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.873080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.874451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model  \\\n",
       "0    DecisionTreeClassifier   \n",
       "1  Random Forest Classifier   \n",
       "2             XGBClassifier   \n",
       "\n",
       "                                           Description  \\\n",
       "0  The referencemax_leaf_nodes : 6 + with date columns   \n",
       "1             The referencen_estimators : 36 + Entropy   \n",
       "2                        The referenceon balanced data   \n",
       "\n",
       "                        Date  Precision    Recall  F1-score   LogLoss  \\\n",
       "0 2023-05-07 17:17:50.719659   0.969697  0.761905  0.853333  0.016578   \n",
       "1 2023-05-07 17:17:51.340465   0.968750  0.738095  0.837838  0.018085   \n",
       "2 2023-05-07 17:17:52.007003   0.970588  0.785714  0.868421  0.015071   \n",
       "\n",
       "        Mcc  PublicScore  PrivateScore  \\\n",
       "0  0.859335          NaN           NaN   \n",
       "1  0.845369          NaN           NaN   \n",
       "2  0.873080          NaN           NaN   \n",
       "\n",
       "                            OldPublicScore  \\\n",
       "0  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2  [0.677419354, 0.711864406, 0.092764378]   \n",
       "\n",
       "                           OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.861068  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.847513  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.874451  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X, val_X, train_y, val_y = train_test_split(X_3, y_train, random_state = 0)\n",
    "result4 = comparemodels(train_X, train_y, val_X, X_test_3, \"Adding Niko Features + Removing low medium MI\")\n",
    "result4[\"PublicScore\"] = [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "result4[\"PrivateScore\"] = [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "result4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d7d110a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_4 = data.copy()\n",
    "X_test_4 = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7d64cade",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowMI = list(mi_scores[mi_scores<0.001].index)\n",
    "X_4.drop(lowMI, inplace=True, axis=1)\n",
    "X_test_4.drop(lowMI, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bf97fb8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>The referencemax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 17:17:52.439715</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>0.860489</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.861551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>The referencen_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 17:17:53.353559</td>\n",
       "      <td>0.868421</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.021099</td>\n",
       "      <td>0.825744</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.826220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>The referenceon balanced data</td>\n",
       "      <td>2023-05-07 17:17:54.462625</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.853662</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.853914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model  \\\n",
       "0    DecisionTreeClassifier   \n",
       "1  Random Forest Classifier   \n",
       "2             XGBClassifier   \n",
       "\n",
       "                                           Description  \\\n",
       "0  The referencemax_leaf_nodes : 6 + with date columns   \n",
       "1             The referencen_estimators : 36 + Entropy   \n",
       "2                        The referenceon balanced data   \n",
       "\n",
       "                        Date  Precision    Recall  F1-score   LogLoss  \\\n",
       "0 2023-05-07 17:17:52.439715   0.942857  0.785714  0.857143  0.016578   \n",
       "1 2023-05-07 17:17:53.353559   0.868421  0.785714  0.825000  0.021099   \n",
       "2 2023-05-07 17:17:54.462625   0.875000  0.833333  0.853659  0.018085   \n",
       "\n",
       "        Mcc  PublicScore  PrivateScore  \\\n",
       "0  0.860489          NaN           NaN   \n",
       "1  0.825744          NaN           NaN   \n",
       "2  0.853662          NaN           NaN   \n",
       "\n",
       "                            OldPublicScore  \\\n",
       "0  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2  [0.677419354, 0.711864406, 0.092764378]   \n",
       "\n",
       "                           OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.861551  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.826220  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.853914  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X, val_X, train_y, val_y = train_test_split(X_4, y_train, random_state = 0)\n",
    "result5 = comparemodels(train_X, train_y, val_X, X_test_4, \"Delete only low + Niko Datas\")\n",
    "result5[\"PublicScore\"] = [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "result5[\"PrivateScore\"] = [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "result5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9d43a667",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_5 = data.copy()\n",
    "X_test_5 = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bb133429",
   "metadata": {},
   "outputs": [],
   "source": [
    "veryLowMI = list(mi_scores[mi_scores<0.0001].index)\n",
    "X_5.drop(veryLowMI, inplace=True, axis=1)\n",
    "X_test_5.drop(veryLowMI, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5871d9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Delete only very low + Niko Datasmax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 17:37:04.035864</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.848426</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.849240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Delete only very low + Niko Datasn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 17:37:05.403448</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.025621</td>\n",
       "      <td>0.790312</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.790713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Delete only very low + Niko Datasscale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 17:37:07.777684</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.856892</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.682540</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.857080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest ClassifierWeighted500</td>\n",
       "      <td>Delete only very low + Niko Datasn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 17:37:09.169817</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.810127</td>\n",
       "      <td>0.022606</td>\n",
       "      <td>0.811446</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>0.812086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest ClassifierWeighted22</td>\n",
       "      <td>Delete only very low + Niko Datasn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 17:37:10.826765</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.027128</td>\n",
       "      <td>0.780344</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.700855</td>\n",
       "      <td>[0.703703703]</td>\n",
       "      <td>[0.654867256]</td>\n",
       "      <td>0.780684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>Delete only very low + Niko Datasupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 17:37:15.007843</td>\n",
       "      <td>0.720930</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.729412</td>\n",
       "      <td>0.034663</td>\n",
       "      <td>0.728981</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.642202</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.729354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>Delete only very low + Niko Datasundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 17:37:19.221701</td>\n",
       "      <td>0.720930</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.729412</td>\n",
       "      <td>0.034663</td>\n",
       "      <td>0.728981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.729354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Model  \\\n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  Random Forest ClassifierWeighted500   \n",
       "4   Random Forest ClassifierWeighted22   \n",
       "5  RandomForestClassifierUpperSampling   \n",
       "6  RandomForestClassifierUnderSampling   \n",
       "\n",
       "                                                                           Description  \\\n",
       "0              Delete only very low + Niko Datasmax_leaf_nodes : 6 + with date columns   \n",
       "1                         Delete only very low + Niko Datasn_estimators : 36 + Entropy   \n",
       "2                               Delete only very low + Niko Datasscale_pos_weight = 22   \n",
       "3                         Delete only very low + Niko Datasn_estimators : 36 + Entropy   \n",
       "4                         Delete only very low + Niko Datasn_estimators : 36 + Entropy   \n",
       "5     Delete only very low + Niko Datasupsampled, n_estimators=36, criterion = entropy   \n",
       "6  Delete only very low + Niko Datasundersampled, n_estimators=36, criterion = entropy   \n",
       "\n",
       "                        Date  Precision    Recall  F1-score   LogLoss  \\\n",
       "0 2023-05-07 17:37:04.035864   0.916667  0.785714  0.846154  0.018085   \n",
       "1 2023-05-07 17:37:05.403448   0.820513  0.761905  0.790123  0.025621   \n",
       "2 2023-05-07 17:37:07.777684   0.857143  0.857143  0.857143  0.018085   \n",
       "3 2023-05-07 17:37:09.169817   0.864865  0.761905  0.810127  0.022606   \n",
       "4 2023-05-07 17:37:10.826765   0.800000  0.761905  0.780488  0.027128   \n",
       "5 2023-05-07 17:37:15.007843   0.720930  0.738095  0.729412  0.034663   \n",
       "6 2023-05-07 17:37:19.221701   0.720930  0.738095  0.729412  0.034663   \n",
       "\n",
       "        Mcc  PublicScore  PrivateScore  \\\n",
       "0  0.848426     0.642857      0.596491   \n",
       "1  0.790312     0.577778      0.577778   \n",
       "2  0.856892     0.666667      0.682540   \n",
       "3  0.811446          NaN           NaN   \n",
       "4  0.780344     0.689655      0.700855   \n",
       "5  0.728981     0.653846      0.642202   \n",
       "6  0.728981          NaN           NaN   \n",
       "\n",
       "                            OldPublicScore  \\\n",
       "0  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2  [0.677419354, 0.711864406, 0.092764378]   \n",
       "3                            [0.678571428]   \n",
       "4                            [0.703703703]   \n",
       "5               [0.678571428, 0.642857142]   \n",
       "6               [0.549019607, 0.642857142]   \n",
       "\n",
       "                           OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.849240  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.790713  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.857080  \n",
       "3                            [0.666666666]        0.812086  \n",
       "4                            [0.654867256]        0.780684  \n",
       "5               [0.637168141, 0.620689655]        0.729354  \n",
       "6                [0.48076923, 0.620689655]        0.729354  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X, val_X, train_y, val_y = train_test_split(X_5, y_train, random_state = 0)\n",
    "result6 = comparemodels(train_X, train_y, val_X, X_test_5, \"Delete only very low + Niko Datas\", unbalanced=True)\n",
    "result6[\"PublicScore\"] = [0.642857142, 0.577777777, 0.666666666, np.nan, 0.689655172, 0.653846153, np.nan]\n",
    "result6[\"PrivateScore\"] = [0.596491228, 0.577777777, 0.682539682, np.nan, 0.700854700, 0.642201834, np.nan]\n",
    "result6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "418bccbc",
   "metadata": {},
   "source": [
    "## 2. Play with deleting the low MI columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c1db32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supprimer les MI trop faible\n",
    "def_feature = pd.read_csv(\"input/Xente_Variable_Definitions.csv\")\n",
    "raw_data = pd.read_csv(\"input/training.csv\")\n",
    "X_test = pd.read_csv(\"input/test.csv\")\n",
    "sample_submission = pd.read_csv(\"input/sample_submission.csv\")\n",
    "\n",
    "#attribut initialization\n",
    "cols_unique_value = [] #Will be droped\n",
    "for col in raw_data.columns : \n",
    "    if len(raw_data[col].unique()) == 1 :\n",
    "        cols_unique_value.append(col)\n",
    "\n",
    "medium_cardianlity_cols = [\"ProductId\"]\n",
    "\n",
    "#Data transformation\n",
    "raw_data['TransactionStartTime'] = pd.to_datetime(raw_data['TransactionStartTime'])\n",
    "X_test['TransactionStartTime'] = pd.to_datetime(X_test['TransactionStartTime'])\n",
    "\n",
    "#Data cleaning\n",
    "data = raw_data.copy()\n",
    "data = data.dropna(axis=0) #Drop observations/rows with missing values\n",
    "X_test=X_test.dropna(axis=0)\n",
    "data.drop(cols_unique_value, axis=1, inplace=True)\n",
    "X_test.drop(cols_unique_value, axis=1, inplace=True)\n",
    "\n",
    "#Prepare index for the submission\n",
    "index_val = list(X_test.TransactionId.values.tolist())\n",
    "\n",
    "#Set the df index to the Transction Id\n",
    "data = transactioId_to_index(data)\n",
    "X_test = transactioId_to_index(X_test)\n",
    "\n",
    "#Adding data\n",
    "data = adding_date_col(data, 'TransactionStartTime')\n",
    "X_test = adding_date_col(X_test, 'TransactionStartTime')\n",
    "\n",
    "\n",
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "low_cardinality_cols = [cname for cname in data.columns if data[cname].nunique() < 15 and \n",
    "                        data[cname].dtype == \"object\"]\n",
    "low_cardinality_cols.append('PricingStrategy')\n",
    "\n",
    "#transform columns BatchId_54 to number\n",
    "    #transform columns BatchId_54 to number\n",
    "id_cols = data.filter(like=\"Id\").columns.tolist()\n",
    "data[id_cols] = data[id_cols].astype(str).apply(lambda x: x.str.replace(x.name + \"_\", \"\")).astype(int)\n",
    "X_test[id_cols] = X_test[id_cols].astype(str).apply(lambda x: x.str.replace(x.name + \"_\", \"\")).astype(int)\n",
    "\n",
    "data['PricingStrategy'] = data['PricingStrategy'].astype('int')\n",
    "X_test['PricingStrategy'] = X_test['PricingStrategy'].astype('int')\n",
    "data['Value'] = data['Value'].astype('float')\n",
    "X_test['Value'] = X_test['Value'].astype('float')\n",
    "\n",
    "X_test['PricingStrategy'] = X_test['PricingStrategy'].astype('str')\n",
    "data['PricingStrategy'] = data['PricingStrategy'].astype('str')\n",
    "\n",
    "#Data splitting\n",
    "y = data.FraudResult #The target label\n",
    "X = data.copy()\n",
    "X.drop(['FraudResult'], axis=1, inplace=True) #Only the features data\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "cat_cols = [col for col in X.columns if X[col].dtype == \"object\"]#liste of obejct columns\n",
    "cat_cols.append(\"PricingStrategy\")#pcq mm si c'est un chiffre il faut le considérer comme une catégorie\n",
    "\n",
    "\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(train_X[low_cardinality_cols]))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(val_X[low_cardinality_cols]))\n",
    "OH_cols_test = pd.DataFrame(OH_encoder.transform(X_test[low_cardinality_cols]))\n",
    "OH_cols_train.columns = OH_encoder.get_feature_names_out()\n",
    "OH_cols_valid.columns = OH_encoder.get_feature_names_out()\n",
    "OH_cols_test.columns = OH_encoder.get_feature_names_out()\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_train.index = train_X.index\n",
    "OH_cols_valid.index = val_X.index\n",
    "OH_cols_test.index = X_test.index\n",
    "\n",
    "OH_cols_train[list(OH_cols_train.columns)] = OH_cols_train[list(OH_cols_train.columns)].astype(int)\n",
    "OH_cols_valid[list(OH_cols_valid.columns)] = OH_cols_valid[list(OH_cols_valid.columns)].astype(int)\n",
    "OH_cols_test[list(OH_cols_test.columns)] = OH_cols_test[list(OH_cols_test.columns)].astype(int)\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train = train_X.drop(low_cardinality_cols, axis=1)\n",
    "num_X_valid = val_X.drop(low_cardinality_cols, axis=1)\n",
    "num_X_test = X_test.drop(low_cardinality_cols, axis=1)\n",
    "\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
    "OH_X_test = pd.concat([num_X_test, OH_cols_test], axis=1)\n",
    "\n",
    "# Problème de string\n",
    "OH_X_train.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_valid.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_test.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_train.columns = OH_X_train.columns.astype(str)\n",
    "OH_X_valid.columns = OH_X_valid.columns.astype(str)\n",
    "OH_X_test.columns = OH_X_test.columns.astype(str)\n",
    "\n",
    "train_X = OH_X_train\n",
    "val_X = OH_X_valid\n",
    "test_X = OH_X_test\n",
    "X_entier = pd.concat([train_X, val_X])\n",
    "\n",
    "mi_scores = make_mi_scores(X_entier , y)\n",
    "\n",
    "verylowMI = list(mi_scores[mi_scores<0.0001].index)\n",
    "lowMI = list(mi_scores[(mi_scores>=0.0001)&(mi_scores<0.001)].index)\n",
    "mediumMI = list(mi_scores[(mi_scores>=0.001)&(mi_scores<0.01)].index)\n",
    "highMI = list(mi_scores[mi_scores>=0.01].index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6da4602e",
   "metadata": {},
   "source": [
    "### 2.1 Delecte the very low MI columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df174abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Delete very low MImax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 16:30:13.941221</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.013564</td>\n",
       "      <td>0.881780</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.661017</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.882409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Delete very low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:15.122144</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.021099</td>\n",
       "      <td>0.838969</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.839697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Delete very low MIscale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 16:30:16.312527</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.891566</td>\n",
       "      <td>0.013564</td>\n",
       "      <td>0.891963</td>\n",
       "      <td>0.711864</td>\n",
       "      <td>0.715447</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.892249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest ClassifierWeighted500</td>\n",
       "      <td>Delete very low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:17.497220</td>\n",
       "      <td>0.760870</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.024113</td>\n",
       "      <td>0.815615</td>\n",
       "      <td>0.654545</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>0.816359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest ClassifierWeighted22</td>\n",
       "      <td>Delete very low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:18.625953</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.025621</td>\n",
       "      <td>0.801037</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.647619</td>\n",
       "      <td>[0.703703703]</td>\n",
       "      <td>[0.654867256]</td>\n",
       "      <td>0.801648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>Delete very low MIupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 16:30:21.059364</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.030142</td>\n",
       "      <td>0.775535</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.776649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>Delete very low MIundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 16:30:23.314014</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.030142</td>\n",
       "      <td>0.775535</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.776649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Model  \\\n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  Random Forest ClassifierWeighted500   \n",
       "4   Random Forest ClassifierWeighted22   \n",
       "5  RandomForestClassifierUpperSampling   \n",
       "6  RandomForestClassifierUnderSampling   \n",
       "\n",
       "                                                            Description  \\\n",
       "0              Delete very low MImax_leaf_nodes : 6 + with date columns   \n",
       "1                         Delete very low MIn_estimators : 36 + Entropy   \n",
       "2                               Delete very low MIscale_pos_weight = 22   \n",
       "3                         Delete very low MIn_estimators : 36 + Entropy   \n",
       "4                         Delete very low MIn_estimators : 36 + Entropy   \n",
       "5     Delete very low MIupsampled, n_estimators=36, criterion = entropy   \n",
       "6  Delete very low MIundersampled, n_estimators=36, criterion = entropy   \n",
       "\n",
       "                        Date  Precision  Recall  F1-score   LogLoss       Mcc  \\\n",
       "0 2023-05-07 16:30:13.941221   0.942857   0.825  0.880000  0.013564  0.881780   \n",
       "1 2023-05-07 16:30:15.122144   0.782609   0.900  0.837209  0.021099  0.838969   \n",
       "2 2023-05-07 16:30:16.312527   0.860465   0.925  0.891566  0.013564  0.891963   \n",
       "3 2023-05-07 16:30:17.497220   0.760870   0.875  0.813953  0.024113  0.815615   \n",
       "4 2023-05-07 16:30:18.625953   0.755556   0.850  0.800000  0.025621  0.801037   \n",
       "5 2023-05-07 16:30:21.059364   0.708333   0.850  0.772727  0.030142  0.775535   \n",
       "6 2023-05-07 16:30:23.314014   0.708333   0.850  0.772727  0.030142  0.775535   \n",
       "\n",
       "   PublicScore  PrivateScore                           OldPublicScore  \\\n",
       "0     0.666667      0.661017  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1     0.666667      0.649123   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2     0.711864      0.715447  [0.677419354, 0.711864406, 0.092764378]   \n",
       "3     0.654545      0.666667                            [0.678571428]   \n",
       "4     0.595745      0.647619                            [0.703703703]   \n",
       "5     0.642857      0.620690               [0.678571428, 0.642857142]   \n",
       "6     0.642857      0.620690               [0.549019607, 0.642857142]   \n",
       "\n",
       "                           OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.882409  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.839697  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.892249  \n",
       "3                            [0.666666666]        0.816359  \n",
       "4                            [0.654867256]        0.801648  \n",
       "5               [0.637168141, 0.620689655]        0.776649  \n",
       "6                [0.48076923, 0.620689655]        0.776649  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "val_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "test_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "X_entier.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "\n",
    "withoutverylowMI = comparemodels(train_X, train_y, val_X, test_X, \"Delete very low MI\")\n",
    "withoutverylowMI[\"PublicScore\"] = [0.666666666, 0.666666666, 0.711864406, 0.654545454, 0.595744680, 0.642857142, 0.642857142]\n",
    "withoutverylowMI[\"PrivateScore\"] = [0.661016949, 0.649122807, 0.715447154, 0.666666666, 0.647619047, 0.620689655, 0.620689655]\n",
    "withoutverylowMI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "073967ea",
   "metadata": {},
   "source": [
    "### 2.2 Delete low MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0235a795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Delete low MImax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 16:30:23.482611</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.157730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.199660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Delete low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:24.429001</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.051241</td>\n",
       "      <td>0.495474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.498927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Delete low MIscale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 16:30:25.364763</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.495413</td>\n",
       "      <td>0.082890</td>\n",
       "      <td>0.512908</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.518656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest ClassifierWeighted500</td>\n",
       "      <td>Delete low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:26.329033</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.507463</td>\n",
       "      <td>0.049734</td>\n",
       "      <td>0.516643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>0.519684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest ClassifierWeighted22</td>\n",
       "      <td>Delete low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:27.271725</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.048227</td>\n",
       "      <td>0.526526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.703703703]</td>\n",
       "      <td>[0.654867256]</td>\n",
       "      <td>0.530131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>Delete low MIupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 16:30:29.422086</td>\n",
       "      <td>0.358209</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.448598</td>\n",
       "      <td>0.088919</td>\n",
       "      <td>0.462470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.467319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>Delete low MIundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 16:30:31.531002</td>\n",
       "      <td>0.358209</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.448598</td>\n",
       "      <td>0.088919</td>\n",
       "      <td>0.462470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.467319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Model  \\\n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  Random Forest ClassifierWeighted500   \n",
       "4   Random Forest ClassifierWeighted22   \n",
       "5  RandomForestClassifierUpperSampling   \n",
       "6  RandomForestClassifierUnderSampling   \n",
       "\n",
       "                                                       Description  \\\n",
       "0              Delete low MImax_leaf_nodes : 6 + with date columns   \n",
       "1                         Delete low MIn_estimators : 36 + Entropy   \n",
       "2                               Delete low MIscale_pos_weight = 22   \n",
       "3                         Delete low MIn_estimators : 36 + Entropy   \n",
       "4                         Delete low MIn_estimators : 36 + Entropy   \n",
       "5     Delete low MIupsampled, n_estimators=36, criterion = entropy   \n",
       "6  Delete low MIundersampled, n_estimators=36, criterion = entropy   \n",
       "\n",
       "                        Date  Precision  Recall  F1-score   LogLoss       Mcc  \\\n",
       "0 2023-05-07 16:30:23.482611   0.500000   0.050  0.090909  0.060284  0.157730   \n",
       "1 2023-05-07 16:30:24.429001   0.615385   0.400  0.484848  0.051241  0.495474   \n",
       "2 2023-05-07 16:30:25.364763   0.391304   0.675  0.495413  0.082890  0.512908   \n",
       "3 2023-05-07 16:30:26.329033   0.629630   0.425  0.507463  0.049734  0.516643   \n",
       "4 2023-05-07 16:30:27.271725   0.653846   0.425  0.515152  0.048227  0.526526   \n",
       "5 2023-05-07 16:30:29.422086   0.358209   0.600  0.448598  0.088919  0.462470   \n",
       "6 2023-05-07 16:30:31.531002   0.358209   0.600  0.448598  0.088919  0.462470   \n",
       "\n",
       "   PublicScore  PrivateScore                           OldPublicScore  \\\n",
       "0          NaN           NaN  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1          NaN           NaN   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2          NaN           NaN  [0.677419354, 0.711864406, 0.092764378]   \n",
       "3          NaN           NaN                            [0.678571428]   \n",
       "4          NaN           NaN                            [0.703703703]   \n",
       "5          NaN           NaN               [0.678571428, 0.642857142]   \n",
       "6          NaN           NaN               [0.549019607, 0.642857142]   \n",
       "\n",
       "                           OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.199660  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.498927  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.518656  \n",
       "3                            [0.666666666]        0.519684  \n",
       "4                            [0.654867256]        0.530131  \n",
       "5               [0.637168141, 0.620689655]        0.467319  \n",
       "6                [0.48076923, 0.620689655]        0.467319  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "val_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "test_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "X_entier.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "train_X.drop(lowMI, inplace=True, axis=1, errors='ignore')\n",
    "val_X.drop(lowMI, inplace=True, axis=1, errors='ignore')\n",
    "test_X.drop(lowMI, inplace=True, axis=1, errors='ignore')\n",
    "X_entier.drop(lowMI, inplace=True, axis=1, errors='ignore')\n",
    "\n",
    "withoutlowMI = comparemodels(train_X, train_y, val_X, test_X, \"Delete low MI\")\n",
    "withoutlowMI[\"PublicScore\"] = [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "withoutlowMI[\"PrivateScore\"] = [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "withoutlowMI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "47fb5923",
   "metadata": {},
   "source": [
    "### 2.3 Delete medium MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463dd25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarah\\Documents\\ECAM_non_One_Drive\\Interligence artificiel\\Projet Niko\\AI5L_AILab_FraudDetection\\EvaluationMetric.py:8: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  metric = tp / (tp+fp)\n",
      "C:\\Users\\sarah\\Documents\\ECAM_non_One_Drive\\Interligence artificiel\\Projet Niko\\AI5L_AILab_FraudDetection\\EvaluationMetric.py:20: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = tp / (tp+fp)\n",
      "C:\\Users\\sarah\\Documents\\ECAM_non_One_Drive\\Interligence artificiel\\Projet Niko\\AI5L_AILab_FraudDetection\\EvaluationMetric.py:8: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  metric = tp / (tp+fp)\n",
      "C:\\Users\\sarah\\Documents\\ECAM_non_One_Drive\\Interligence artificiel\\Projet Niko\\AI5L_AILab_FraudDetection\\EvaluationMetric.py:20: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = tp / (tp+fp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarah\\Documents\\ECAM_non_One_Drive\\Interligence artificiel\\Projet Niko\\AI5L_AILab_FraudDetection\\EvaluationMetric.py:8: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  metric = tp / (tp+fp)\n",
      "C:\\Users\\sarah\\Documents\\ECAM_non_One_Drive\\Interligence artificiel\\Projet Niko\\AI5L_AILab_FraudDetection\\EvaluationMetric.py:20: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = tp / (tp+fp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarah\\Documents\\ECAM_non_One_Drive\\Interligence artificiel\\Projet Niko\\AI5L_AILab_FraudDetection\\EvaluationMetric.py:8: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  metric = tp / (tp+fp)\n",
      "C:\\Users\\sarah\\Documents\\ECAM_non_One_Drive\\Interligence artificiel\\Projet Niko\\AI5L_AILab_FraudDetection\\EvaluationMetric.py:20: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = tp / (tp+fp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Delete medium MImax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 16:30:31.663343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Delete medium MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:32.095585</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Delete medium MIscale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 16:30:32.543177</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.162791</td>\n",
       "      <td>0.108511</td>\n",
       "      <td>0.161685</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.162913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest ClassifierWeighted500</td>\n",
       "      <td>Delete medium MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:33.010695</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest ClassifierWeighted22</td>\n",
       "      <td>Delete medium MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:33.443986</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.703703703]</td>\n",
       "      <td>[0.654867256]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>Delete medium MIupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 16:30:34.208445</td>\n",
       "      <td>0.010398</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.020544</td>\n",
       "      <td>4.885998</td>\n",
       "      <td>0.084977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.241480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>Delete medium MIundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 16:30:34.949979</td>\n",
       "      <td>0.010398</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.020544</td>\n",
       "      <td>4.885998</td>\n",
       "      <td>0.084977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.241480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Model  \\\n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  Random Forest ClassifierWeighted500   \n",
       "4   Random Forest ClassifierWeighted22   \n",
       "5  RandomForestClassifierUpperSampling   \n",
       "6  RandomForestClassifierUnderSampling   \n",
       "\n",
       "                                                          Description  \\\n",
       "0              Delete medium MImax_leaf_nodes : 6 + with date columns   \n",
       "1                         Delete medium MIn_estimators : 36 + Entropy   \n",
       "2                               Delete medium MIscale_pos_weight = 22   \n",
       "3                         Delete medium MIn_estimators : 36 + Entropy   \n",
       "4                         Delete medium MIn_estimators : 36 + Entropy   \n",
       "5     Delete medium MIupsampled, n_estimators=36, criterion = entropy   \n",
       "6  Delete medium MIundersampled, n_estimators=36, criterion = entropy   \n",
       "\n",
       "                        Date  Precision  Recall  F1-score   LogLoss       Mcc  \\\n",
       "0 2023-05-07 16:30:31.663343        NaN   0.000       NaN  0.060284  0.000000   \n",
       "1 2023-05-07 16:30:32.095585        NaN   0.000       NaN  0.060284  0.000000   \n",
       "2 2023-05-07 16:30:32.543177   0.152174   0.175  0.162791  0.108511  0.161685   \n",
       "3 2023-05-07 16:30:33.010695        NaN   0.000       NaN  0.060284  0.000000   \n",
       "4 2023-05-07 16:30:33.443986        NaN   0.000       NaN  0.060284  0.000000   \n",
       "5 2023-05-07 16:30:34.208445   0.010398   0.850  0.020544  4.885998  0.084977   \n",
       "6 2023-05-07 16:30:34.949979   0.010398   0.850  0.020544  4.885998  0.084977   \n",
       "\n",
       "   PublicScore  PrivateScore                           OldPublicScore  \\\n",
       "0          NaN           NaN  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1          NaN           NaN   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2          NaN           NaN  [0.677419354, 0.711864406, 0.092764378]   \n",
       "3          NaN           NaN                            [0.678571428]   \n",
       "4          NaN           NaN                            [0.703703703]   \n",
       "5          NaN           NaN               [0.678571428, 0.642857142]   \n",
       "6          NaN           NaN               [0.549019607, 0.642857142]   \n",
       "\n",
       "                           OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.000000  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.000000  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.162913  \n",
       "3                            [0.666666666]        0.000000  \n",
       "4                            [0.654867256]        0.000000  \n",
       "5               [0.637168141, 0.620689655]        0.241480  \n",
       "6                [0.48076923, 0.620689655]        0.241480  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "val_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "test_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "X_entier.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "train_X.drop(lowMI, inplace=True, axis=1, errors='ignore')\n",
    "val_X.drop(lowMI, inplace=True, axis=1, errors='ignore')\n",
    "test_X.drop(lowMI, inplace=True, axis=1, errors='ignore')\n",
    "X_entier.drop(lowMI, inplace=True, axis=1, errors='ignore')\n",
    "\n",
    "train_X.drop(mediumMI, inplace=True, axis=1, errors='ignore')\n",
    "val_X.drop(mediumMI, inplace=True, axis=1, errors='ignore')\n",
    "test_X.drop(mediumMI, inplace=True, axis=1, errors='ignore')\n",
    "X_entier.drop(mediumMI, inplace=True, axis=1, errors='ignore')\n",
    "\n",
    "withoutmediumMI = comparemodels(train_X, train_y, val_X, test_X, \"Delete medium MI\")\n",
    "withoutmediumMI[\"PublicScore\"] = [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "withoutmediumMI[\"PrivateScore\"] = [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "withoutmediumMI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54f269ad",
   "metadata": {},
   "source": [
    "## 3 Undersampling with K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f58714f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarah\\anaconda3\\envs\\AILab-ECAM4\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Kmeans UnderSamplingmax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 16:31:00.117654</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.371584</td>\n",
       "      <td>0.979557</td>\n",
       "      <td>0.006575</td>\n",
       "      <td>0.006863</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.987512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Kmeans UnderSamplingn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:31:00.285578</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.114752</td>\n",
       "      <td>0.938324</td>\n",
       "      <td>0.007513</td>\n",
       "      <td>0.007795</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.961903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Kmeans UnderSamplingon balanced data</td>\n",
       "      <td>2023-05-07 16:31:00.404309</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.114752</td>\n",
       "      <td>0.938324</td>\n",
       "      <td>0.092764</td>\n",
       "      <td>0.096565</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.961903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model  \\\n",
       "0    DecisionTreeClassifier   \n",
       "1  Random Forest Classifier   \n",
       "2             XGBClassifier   \n",
       "\n",
       "                                                  Description  \\\n",
       "0  Kmeans UnderSamplingmax_leaf_nodes : 6 + with date columns   \n",
       "1             Kmeans UnderSamplingn_estimators : 36 + Entropy   \n",
       "2                        Kmeans UnderSamplingon balanced data   \n",
       "\n",
       "                        Date  Precision  Recall  F1-score   LogLoss       Mcc  \\\n",
       "0 2023-05-07 16:31:00.117654   0.980392    1.00  0.990099  0.371584  0.979557   \n",
       "1 2023-05-07 16:31:00.285578   0.979592    0.96  0.969697  1.114752  0.938324   \n",
       "2 2023-05-07 16:31:00.404309   0.979592    0.96  0.969697  1.114752  0.938324   \n",
       "\n",
       "   PublicScore  PrivateScore                           OldPublicScore  \\\n",
       "0     0.006575      0.006863  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1     0.007513      0.007795   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2     0.092764      0.096565  [0.677419354, 0.711864406, 0.092764378]   \n",
       "\n",
       "                           OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.987512  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.961903  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.961903  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans \n",
    "\n",
    "# K-means fait sur training set entier (et ensuite sur seuelement le train_X)\n",
    "def_feature = pd.read_csv(\"input/Xente_Variable_Definitions.csv\")\n",
    "raw_data = pd.read_csv(\"input/training.csv\")\n",
    "X_test = pd.read_csv(\"input/test.csv\")\n",
    "sample_submission = pd.read_csv(\"input/sample_submission.csv\")\n",
    "\n",
    "#attribut initialization\n",
    "cols_unique_value = [] #Will be droped\n",
    "for col in raw_data.columns : \n",
    "    if len(raw_data[col].unique()) == 1 :\n",
    "        cols_unique_value.append(col)\n",
    "\n",
    "medium_cardianlity_cols = [\"ProductId\"]\n",
    "\n",
    "#Data transformation\n",
    "raw_data['TransactionStartTime'] = pd.to_datetime(raw_data['TransactionStartTime'])\n",
    "X_test['TransactionStartTime'] = pd.to_datetime(X_test['TransactionStartTime'])\n",
    "\n",
    "#Data cleaning\n",
    "data = raw_data.copy()\n",
    "data = data.dropna(axis=0) #Drop observations/rows with missing values\n",
    "X_test=X_test.dropna(axis=0)\n",
    "data.drop(cols_unique_value, axis=1, inplace=True)\n",
    "X_test.drop(cols_unique_value, axis=1, inplace=True)\n",
    "\n",
    "#Prepare index for the submission\n",
    "index_val = list(X_test.TransactionId.values.tolist())\n",
    "\n",
    "#Set the df index to the Transction Id\n",
    "data = transactioId_to_index(data)\n",
    "X_test = transactioId_to_index(X_test)\n",
    "\n",
    "#Adding data\n",
    "data = adding_date_col(data, 'TransactionStartTime')\n",
    "X_test = adding_date_col(X_test, 'TransactionStartTime')\n",
    "\n",
    "\n",
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "low_cardinality_cols = [cname for cname in data.columns if data[cname].nunique() < 15 and \n",
    "                        data[cname].dtype == \"object\"]\n",
    "low_cardinality_cols.append('PricingStrategy')\n",
    "\n",
    "#transform columns BatchId_54 to number\n",
    "    #transform columns BatchId_54 to number\n",
    "id_cols = data.filter(like=\"Id\").columns.tolist()\n",
    "data[id_cols] = data[id_cols].astype(str).apply(lambda x: x.str.replace(x.name + \"_\", \"\")).astype(int)\n",
    "X_test[id_cols] = X_test[id_cols].astype(str).apply(lambda x: x.str.replace(x.name + \"_\", \"\")).astype(int)\n",
    "\n",
    "data['PricingStrategy'] = data['PricingStrategy'].astype('int')\n",
    "X_test['PricingStrategy'] = X_test['PricingStrategy'].astype('int')\n",
    "data['Value'] = data['Value'].astype('float')\n",
    "X_test['Value'] = X_test['Value'].astype('float')\n",
    "\n",
    "X_test['PricingStrategy'] = X_test['PricingStrategy'].astype('str')\n",
    "data['PricingStrategy'] = data['PricingStrategy'].astype('str')\n",
    "\n",
    "#Data splitting\n",
    "y = data.FraudResult #The target label\n",
    "X = data.copy()\n",
    "X.drop(['FraudResult'], axis=1, inplace=True) #Only the features data\n",
    "\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "OH_cols_X = pd.DataFrame(OH_encoder.fit_transform(X[low_cardinality_cols]))\n",
    "OH_cols_X.columns = OH_encoder.get_feature_names_out()\n",
    "OH_cols_test = pd.DataFrame(OH_encoder.transform(X_test[low_cardinality_cols]))\n",
    "OH_cols_test.columns = OH_encoder.get_feature_names_out()\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_X.index = X.index\n",
    "OH_cols_test.index = X_test.index\n",
    "\n",
    "OH_cols_X[list(OH_cols_X.columns)] = OH_cols_X[list(OH_cols_X.columns)].astype(int)\n",
    "OH_cols_test[list(OH_cols_test.columns)] = OH_cols_test[list(OH_cols_test.columns)].astype(int)\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X = X.drop(low_cardinality_cols, axis=1)\n",
    "num_X_test = X_test.drop(low_cardinality_cols, axis=1)\n",
    "\n",
    "OH_X = pd.concat([num_X, OH_cols_X], axis=1)\n",
    "OH_X_test = pd.concat([num_X_test, OH_cols_test], axis=1)\n",
    "\n",
    "# Problème de string\n",
    "OH_X.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_test.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X.columns = OH_X.columns.astype(str)\n",
    "OH_X_test.columns = OH_X_test.columns.astype(str)\n",
    "\n",
    "X = OH_X\n",
    "\n",
    "#####K-Means\n",
    "X_0 = X[y == 0] # instances avec FraudResult=0\n",
    "X_1 = X[y == 1] # instances avec FraudResult=1\n",
    "\n",
    "# Créer des \"centres\" pour KMeans\n",
    "n_clusters = 193\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(X_0)\n",
    "centers = kmeans.cluster_centers_\n",
    "\n",
    "# Trouver les indices des instances à garder dans la classe FraudResult=0\n",
    "labels = kmeans.predict(X_0)\n",
    "distances = np.sum((X_0 - centers[labels]) ** 2, axis=1)\n",
    "keep_indices = np.argsort(distances)[:n_clusters]\n",
    "\n",
    "df_filtré = X_0[X_0.index.isin(list(keep_indices.index))]\n",
    "\n",
    "# Combiner les instances sous-échantillonnées\n",
    "X_undersampled = pd.concat([df_filtré, X_1])\n",
    "y_undersampled = np.concatenate((np.zeros(n_clusters), np.ones(len(X_1))), axis=0)\n",
    "\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(X_undersampled, y_undersampled, random_state = 0)\n",
    "\n",
    "\n",
    "#train_X.drop(verylowMI, inplace=True, axis=1)\n",
    "#val_X.drop(verylowMI, inplace=True, axis=1)\n",
    "#test_X.drop(verylowMI, inplace=True, axis=1)\n",
    "#X_entier.drop(verylowMI, inplace=True, axis=1)\n",
    "\n",
    "kmeansundersampling = comparemodels(train_X, train_y, val_X, OH_X_test, \"Kmeans UnderSampling\", unbalanced = False)\n",
    "kmeansundersampling[\"PublicScore\"] = [0.006575486, 0.007513148, 0.092764378]\n",
    "kmeansundersampling[\"PrivateScore\"] = [0.006863327, 0.007794933, 0.096564531] ###Cest trop nulle \n",
    "kmeansundersampling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "789ddb0c",
   "metadata": {},
   "source": [
    "## 4. SMOTE (Synthetic Minority Oversampling Technique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3fa295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>SMOTEmax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 16:31:18.853308</td>\n",
       "      <td>0.113372</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.203125</td>\n",
       "      <td>0.461171</td>\n",
       "      <td>0.330225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.405431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>SMOTEn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:31:22.707671</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.027128</td>\n",
       "      <td>0.804629</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.686567</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.806157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>SMOTEon balanced data</td>\n",
       "      <td>2023-05-07 16:31:25.958940</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.862324</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.376068</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.863034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model                                  Description  \\\n",
       "0    DecisionTreeClassifier  SMOTEmax_leaf_nodes : 6 + with date columns   \n",
       "1  Random Forest Classifier             SMOTEn_estimators : 36 + Entropy   \n",
       "2             XGBClassifier                        SMOTEon balanced data   \n",
       "\n",
       "                        Date  Precision  Recall  F1-score   LogLoss       Mcc  \\\n",
       "0 2023-05-07 16:31:18.853308   0.113372   0.975  0.203125  0.461171  0.330225   \n",
       "1 2023-05-07 16:31:22.707671   0.720000   0.900  0.800000  0.027128  0.804629   \n",
       "2 2023-05-07 16:31:25.958940   0.804348   0.925  0.860465  0.018085  0.862324   \n",
       "\n",
       "   PublicScore  PrivateScore                           OldPublicScore  \\\n",
       "0          NaN           NaN  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1     0.709677      0.686567   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2     0.358974      0.376068  [0.677419354, 0.711864406, 0.092764378]   \n",
       "\n",
       "                           OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.405431  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.806157  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.863034  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SMOTE\n",
    "def_feature = pd.read_csv(\"input/Xente_Variable_Definitions.csv\")\n",
    "raw_data = pd.read_csv(\"input/training.csv\")\n",
    "X_test = pd.read_csv(\"input/test.csv\")\n",
    "sample_submission = pd.read_csv(\"input/sample_submission.csv\")\n",
    "\n",
    "#attribut initialization\n",
    "cols_unique_value = [] #Will be droped\n",
    "for col in raw_data.columns : \n",
    "    if len(raw_data[col].unique()) == 1 :\n",
    "        cols_unique_value.append(col)\n",
    "\n",
    "medium_cardianlity_cols = [\"ProductId\"]\n",
    "\n",
    "#Data transformation\n",
    "raw_data['TransactionStartTime'] = pd.to_datetime(raw_data['TransactionStartTime'])\n",
    "X_test['TransactionStartTime'] = pd.to_datetime(X_test['TransactionStartTime'])\n",
    "\n",
    "#Data cleaning\n",
    "data = raw_data.copy()\n",
    "data = data.dropna(axis=0) #Drop observations/rows with missing values\n",
    "X_test=X_test.dropna(axis=0)\n",
    "data.drop(cols_unique_value, axis=1, inplace=True)\n",
    "X_test.drop(cols_unique_value, axis=1, inplace=True)\n",
    "\n",
    "#Prepare index for the submission\n",
    "index_val = list(X_test.TransactionId.values.tolist())\n",
    "\n",
    "#Set the df index to the Transction Id\n",
    "data = transactioId_to_index(data)\n",
    "X_test = transactioId_to_index(X_test)\n",
    "\n",
    "#Adding data\n",
    "data = adding_date_col(data, 'TransactionStartTime')\n",
    "X_test = adding_date_col(X_test, 'TransactionStartTime')\n",
    "\n",
    "\n",
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "low_cardinality_cols = [cname for cname in data.columns if data[cname].nunique() < 15 and \n",
    "                        data[cname].dtype == \"object\"]\n",
    "low_cardinality_cols.append('PricingStrategy')\n",
    "\n",
    "#transform columns BatchId_54 to number\n",
    "    #transform columns BatchId_54 to number\n",
    "id_cols = data.filter(like=\"Id\").columns.tolist()\n",
    "data[id_cols] = data[id_cols].astype(str).apply(lambda x: x.str.replace(x.name + \"_\", \"\")).astype(int)\n",
    "X_test[id_cols] = X_test[id_cols].astype(str).apply(lambda x: x.str.replace(x.name + \"_\", \"\")).astype(int)\n",
    "\n",
    "data['PricingStrategy'] = data['PricingStrategy'].astype('int')\n",
    "X_test['PricingStrategy'] = X_test['PricingStrategy'].astype('int')\n",
    "data['Value'] = data['Value'].astype('float')\n",
    "X_test['Value'] = X_test['Value'].astype('float')\n",
    "\n",
    "X_test['PricingStrategy'] = X_test['PricingStrategy'].astype('str')\n",
    "data['PricingStrategy'] = data['PricingStrategy'].astype('str')\n",
    "\n",
    "#Data splitting\n",
    "y = data.FraudResult #The target label\n",
    "X = data.copy()\n",
    "X.drop(['FraudResult'], axis=1, inplace=True) #Only the features data\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "cat_cols = [col for col in X.columns if X[col].dtype == \"object\"]#liste of obejct columns\n",
    "cat_cols.append(\"PricingStrategy\")#pcq mm si c'est un chiffre il faut le considérer comme une catégorie\n",
    "\n",
    "\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(train_X[low_cardinality_cols]))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(val_X[low_cardinality_cols]))\n",
    "OH_cols_test = pd.DataFrame(OH_encoder.transform(X_test[low_cardinality_cols]))\n",
    "OH_cols_train.columns = OH_encoder.get_feature_names_out()\n",
    "OH_cols_valid.columns = OH_encoder.get_feature_names_out()\n",
    "OH_cols_test.columns = OH_encoder.get_feature_names_out()\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_train.index = train_X.index\n",
    "OH_cols_valid.index = val_X.index\n",
    "OH_cols_test.index = X_test.index\n",
    "\n",
    "OH_cols_train[list(OH_cols_train.columns)] = OH_cols_train[list(OH_cols_train.columns)].astype(int)\n",
    "OH_cols_valid[list(OH_cols_valid.columns)] = OH_cols_valid[list(OH_cols_valid.columns)].astype(int)\n",
    "OH_cols_test[list(OH_cols_test.columns)] = OH_cols_test[list(OH_cols_test.columns)].astype(int)\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train = train_X.drop(low_cardinality_cols, axis=1)\n",
    "num_X_valid = val_X.drop(low_cardinality_cols, axis=1)\n",
    "num_X_test = X_test.drop(low_cardinality_cols, axis=1)\n",
    "\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
    "OH_X_test = pd.concat([num_X_test, OH_cols_test], axis=1)\n",
    "\n",
    "# Problème de string\n",
    "OH_X_train.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_valid.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_test.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_train.columns = OH_X_train.columns.astype(str)\n",
    "OH_X_valid.columns = OH_X_valid.columns.astype(str)\n",
    "OH_X_test.columns = OH_X_test.columns.astype(str)\n",
    "\n",
    "train_X = OH_X_train\n",
    "val_X = OH_X_valid\n",
    "test_X = OH_X_test\n",
    "X_entier = pd.concat([train_X, val_X])\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(train_X, train_y)\n",
    "\n",
    "mi_scores = make_mi_scores(X_entier, y)\n",
    "\n",
    "verylowMI = list(mi_scores[mi_scores<0.0001].index)\n",
    "lowMI = list(mi_scores[(mi_scores>=0.0001)&(mi_scores<0.001)].index)\n",
    "mediumMI = list(mi_scores[(mi_scores>=0.001)&(mi_scores<0.01)].index)\n",
    "highMI = list(mi_scores[mi_scores>=0.01].index)\n",
    "\n",
    "\n",
    "#train_X.drop(verylowMI, inplace=True, axis=1)\n",
    "#val_X.drop(verylowMI, inplace=True, axis=1)\n",
    "#test_X.drop(verylowMI, inplace=True, axis=1)\n",
    "#X_entier.drop(verylowMI, inplace=True, axis=1)\n",
    "\n",
    "SMOTERes = comparemodels(X_res, y_res, val_X, test_X, \"SMOTE\", unbalanced = False)\n",
    "SMOTERes[\"PublicScore\"] = [np.nan, 0.709677419, 0.358974358] #ici voit que le RandomForest est mieux\n",
    "SMOTERes[\"PrivateScore\"] = [np.nan, 0.686567164, 0.376068376]  \n",
    "SMOTERes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb6650c6",
   "metadata": {},
   "source": [
    "# Compare result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78eddab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>The referencemax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 16:29:46.815175</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>0.857566</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.661017</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.857900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>The referencen_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:29:47.996356</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.843373</td>\n",
       "      <td>0.019592</td>\n",
       "      <td>0.843655</td>\n",
       "      <td>0.690909</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.843995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>The referencescale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 16:29:49.487206</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>0.871874</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.676923</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.872421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest ClassifierWeighted500</td>\n",
       "      <td>The referencen_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:29:50.689128</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.862324</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>0.863034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest ClassifierWeighted22</td>\n",
       "      <td>The referencen_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:29:51.854001</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.862324</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.654867</td>\n",
       "      <td>[0.703703703]</td>\n",
       "      <td>[0.654867256]</td>\n",
       "      <td>0.863034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>The referenceupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 16:29:54.212174</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.022606</td>\n",
       "      <td>0.824649</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.637168</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.825239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>The referenceundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 16:29:56.454271</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.022606</td>\n",
       "      <td>0.824649</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.825239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Delete very low MImax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 16:30:13.941221</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.013564</td>\n",
       "      <td>0.881780</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.661017</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.882409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Delete very low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:15.122144</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.021099</td>\n",
       "      <td>0.838969</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.839697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Delete very low MIscale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 16:30:16.312527</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.891566</td>\n",
       "      <td>0.013564</td>\n",
       "      <td>0.891963</td>\n",
       "      <td>0.711864</td>\n",
       "      <td>0.715447</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.892249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest ClassifierWeighted500</td>\n",
       "      <td>Delete very low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:17.497220</td>\n",
       "      <td>0.760870</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.024113</td>\n",
       "      <td>0.815615</td>\n",
       "      <td>0.654545</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>0.816359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest ClassifierWeighted22</td>\n",
       "      <td>Delete very low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:18.625953</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.025621</td>\n",
       "      <td>0.801037</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.647619</td>\n",
       "      <td>[0.703703703]</td>\n",
       "      <td>[0.654867256]</td>\n",
       "      <td>0.801648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>Delete very low MIupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 16:30:21.059364</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.030142</td>\n",
       "      <td>0.775535</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.776649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>Delete very low MIundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 16:30:23.314014</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.030142</td>\n",
       "      <td>0.775535</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.776649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Delete low MImax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 16:30:23.482611</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.157730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.199660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Delete low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:24.429001</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.051241</td>\n",
       "      <td>0.495474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.498927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Delete low MIscale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 16:30:25.364763</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.495413</td>\n",
       "      <td>0.082890</td>\n",
       "      <td>0.512908</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.518656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest ClassifierWeighted500</td>\n",
       "      <td>Delete low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:26.329033</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.507463</td>\n",
       "      <td>0.049734</td>\n",
       "      <td>0.516643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>0.519684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest ClassifierWeighted22</td>\n",
       "      <td>Delete low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:27.271725</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.048227</td>\n",
       "      <td>0.526526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.703703703]</td>\n",
       "      <td>[0.654867256]</td>\n",
       "      <td>0.530131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>Delete low MIupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 16:30:29.422086</td>\n",
       "      <td>0.358209</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.448598</td>\n",
       "      <td>0.088919</td>\n",
       "      <td>0.462470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.467319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>Delete low MIundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 16:30:31.531002</td>\n",
       "      <td>0.358209</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.448598</td>\n",
       "      <td>0.088919</td>\n",
       "      <td>0.462470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.467319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Delete medium MImax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 16:30:31.663343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Delete medium MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:32.095585</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Delete medium MIscale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 16:30:32.543177</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.162791</td>\n",
       "      <td>0.108511</td>\n",
       "      <td>0.161685</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.162913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest ClassifierWeighted500</td>\n",
       "      <td>Delete medium MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:33.010695</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest ClassifierWeighted22</td>\n",
       "      <td>Delete medium MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:33.443986</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.703703703]</td>\n",
       "      <td>[0.654867256]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>Delete medium MIupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 16:30:34.208445</td>\n",
       "      <td>0.010398</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.020544</td>\n",
       "      <td>4.885998</td>\n",
       "      <td>0.084977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.241480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>Delete medium MIundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 16:30:34.949979</td>\n",
       "      <td>0.010398</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.020544</td>\n",
       "      <td>4.885998</td>\n",
       "      <td>0.084977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.241480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Kmeans UnderSamplingmax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 16:31:00.117654</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.371584</td>\n",
       "      <td>0.979557</td>\n",
       "      <td>0.006575</td>\n",
       "      <td>0.006863</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.987512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Kmeans UnderSamplingn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:31:00.285578</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.114752</td>\n",
       "      <td>0.938324</td>\n",
       "      <td>0.007513</td>\n",
       "      <td>0.007795</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.961903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Kmeans UnderSamplingon balanced data</td>\n",
       "      <td>2023-05-07 16:31:00.404309</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.114752</td>\n",
       "      <td>0.938324</td>\n",
       "      <td>0.092764</td>\n",
       "      <td>0.096565</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.961903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>SMOTEmax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 16:31:18.853308</td>\n",
       "      <td>0.113372</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.203125</td>\n",
       "      <td>0.461171</td>\n",
       "      <td>0.330225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.405431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>SMOTEn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:31:22.707671</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.027128</td>\n",
       "      <td>0.804629</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.686567</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.806157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>SMOTEon balanced data</td>\n",
       "      <td>2023-05-07 16:31:25.958940</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.862324</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.376068</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.863034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Model  \\\n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  Random Forest ClassifierWeighted500   \n",
       "4   Random Forest ClassifierWeighted22   \n",
       "5  RandomForestClassifierUpperSampling   \n",
       "6  RandomForestClassifierUnderSampling   \n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  Random Forest ClassifierWeighted500   \n",
       "4   Random Forest ClassifierWeighted22   \n",
       "5  RandomForestClassifierUpperSampling   \n",
       "6  RandomForestClassifierUnderSampling   \n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  Random Forest ClassifierWeighted500   \n",
       "4   Random Forest ClassifierWeighted22   \n",
       "5  RandomForestClassifierUpperSampling   \n",
       "6  RandomForestClassifierUnderSampling   \n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  Random Forest ClassifierWeighted500   \n",
       "4   Random Forest ClassifierWeighted22   \n",
       "5  RandomForestClassifierUpperSampling   \n",
       "6  RandomForestClassifierUnderSampling   \n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "\n",
       "                                                            Description  \\\n",
       "0                   The referencemax_leaf_nodes : 6 + with date columns   \n",
       "1                              The referencen_estimators : 36 + Entropy   \n",
       "2                                    The referencescale_pos_weight = 22   \n",
       "3                              The referencen_estimators : 36 + Entropy   \n",
       "4                              The referencen_estimators : 36 + Entropy   \n",
       "5          The referenceupsampled, n_estimators=36, criterion = entropy   \n",
       "6       The referenceundersampled, n_estimators=36, criterion = entropy   \n",
       "0              Delete very low MImax_leaf_nodes : 6 + with date columns   \n",
       "1                         Delete very low MIn_estimators : 36 + Entropy   \n",
       "2                               Delete very low MIscale_pos_weight = 22   \n",
       "3                         Delete very low MIn_estimators : 36 + Entropy   \n",
       "4                         Delete very low MIn_estimators : 36 + Entropy   \n",
       "5     Delete very low MIupsampled, n_estimators=36, criterion = entropy   \n",
       "6  Delete very low MIundersampled, n_estimators=36, criterion = entropy   \n",
       "0                   Delete low MImax_leaf_nodes : 6 + with date columns   \n",
       "1                              Delete low MIn_estimators : 36 + Entropy   \n",
       "2                                    Delete low MIscale_pos_weight = 22   \n",
       "3                              Delete low MIn_estimators : 36 + Entropy   \n",
       "4                              Delete low MIn_estimators : 36 + Entropy   \n",
       "5          Delete low MIupsampled, n_estimators=36, criterion = entropy   \n",
       "6       Delete low MIundersampled, n_estimators=36, criterion = entropy   \n",
       "0                Delete medium MImax_leaf_nodes : 6 + with date columns   \n",
       "1                           Delete medium MIn_estimators : 36 + Entropy   \n",
       "2                                 Delete medium MIscale_pos_weight = 22   \n",
       "3                           Delete medium MIn_estimators : 36 + Entropy   \n",
       "4                           Delete medium MIn_estimators : 36 + Entropy   \n",
       "5       Delete medium MIupsampled, n_estimators=36, criterion = entropy   \n",
       "6    Delete medium MIundersampled, n_estimators=36, criterion = entropy   \n",
       "0            Kmeans UnderSamplingmax_leaf_nodes : 6 + with date columns   \n",
       "1                       Kmeans UnderSamplingn_estimators : 36 + Entropy   \n",
       "2                                  Kmeans UnderSamplingon balanced data   \n",
       "0                           SMOTEmax_leaf_nodes : 6 + with date columns   \n",
       "1                                      SMOTEn_estimators : 36 + Entropy   \n",
       "2                                                 SMOTEon balanced data   \n",
       "\n",
       "                        Date  Precision  Recall  F1-score   LogLoss       Mcc  \\\n",
       "0 2023-05-07 16:29:46.815175   0.891892   0.825  0.857143  0.016578  0.857566   \n",
       "1 2023-05-07 16:29:47.996356   0.813953   0.875  0.843373  0.019592  0.843655   \n",
       "2 2023-05-07 16:29:49.487206   0.822222   0.925  0.870588  0.016578  0.871874   \n",
       "3 2023-05-07 16:29:50.689128   0.804348   0.925  0.860465  0.018085  0.862324   \n",
       "4 2023-05-07 16:29:51.854001   0.804348   0.925  0.860465  0.018085  0.862324   \n",
       "5 2023-05-07 16:29:54.212174   0.777778   0.875  0.823529  0.022606  0.824649   \n",
       "6 2023-05-07 16:29:56.454271   0.777778   0.875  0.823529  0.022606  0.824649   \n",
       "0 2023-05-07 16:30:13.941221   0.942857   0.825  0.880000  0.013564  0.881780   \n",
       "1 2023-05-07 16:30:15.122144   0.782609   0.900  0.837209  0.021099  0.838969   \n",
       "2 2023-05-07 16:30:16.312527   0.860465   0.925  0.891566  0.013564  0.891963   \n",
       "3 2023-05-07 16:30:17.497220   0.760870   0.875  0.813953  0.024113  0.815615   \n",
       "4 2023-05-07 16:30:18.625953   0.755556   0.850  0.800000  0.025621  0.801037   \n",
       "5 2023-05-07 16:30:21.059364   0.708333   0.850  0.772727  0.030142  0.775535   \n",
       "6 2023-05-07 16:30:23.314014   0.708333   0.850  0.772727  0.030142  0.775535   \n",
       "0 2023-05-07 16:30:23.482611   0.500000   0.050  0.090909  0.060284  0.157730   \n",
       "1 2023-05-07 16:30:24.429001   0.615385   0.400  0.484848  0.051241  0.495474   \n",
       "2 2023-05-07 16:30:25.364763   0.391304   0.675  0.495413  0.082890  0.512908   \n",
       "3 2023-05-07 16:30:26.329033   0.629630   0.425  0.507463  0.049734  0.516643   \n",
       "4 2023-05-07 16:30:27.271725   0.653846   0.425  0.515152  0.048227  0.526526   \n",
       "5 2023-05-07 16:30:29.422086   0.358209   0.600  0.448598  0.088919  0.462470   \n",
       "6 2023-05-07 16:30:31.531002   0.358209   0.600  0.448598  0.088919  0.462470   \n",
       "0 2023-05-07 16:30:31.663343        NaN   0.000       NaN  0.060284  0.000000   \n",
       "1 2023-05-07 16:30:32.095585        NaN   0.000       NaN  0.060284  0.000000   \n",
       "2 2023-05-07 16:30:32.543177   0.152174   0.175  0.162791  0.108511  0.161685   \n",
       "3 2023-05-07 16:30:33.010695        NaN   0.000       NaN  0.060284  0.000000   \n",
       "4 2023-05-07 16:30:33.443986        NaN   0.000       NaN  0.060284  0.000000   \n",
       "5 2023-05-07 16:30:34.208445   0.010398   0.850  0.020544  4.885998  0.084977   \n",
       "6 2023-05-07 16:30:34.949979   0.010398   0.850  0.020544  4.885998  0.084977   \n",
       "0 2023-05-07 16:31:00.117654   0.980392   1.000  0.990099  0.371584  0.979557   \n",
       "1 2023-05-07 16:31:00.285578   0.979592   0.960  0.969697  1.114752  0.938324   \n",
       "2 2023-05-07 16:31:00.404309   0.979592   0.960  0.969697  1.114752  0.938324   \n",
       "0 2023-05-07 16:31:18.853308   0.113372   0.975  0.203125  0.461171  0.330225   \n",
       "1 2023-05-07 16:31:22.707671   0.720000   0.900  0.800000  0.027128  0.804629   \n",
       "2 2023-05-07 16:31:25.958940   0.804348   0.925  0.860465  0.018085  0.862324   \n",
       "\n",
       "   PublicScore  PrivateScore                           OldPublicScore  \\\n",
       "0     0.666667      0.661017  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1     0.690909      0.649123   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2     0.677419      0.676923  [0.677419354, 0.711864406, 0.092764378]   \n",
       "3     0.678571      0.666667                            [0.678571428]   \n",
       "4     0.703704      0.654867                            [0.703703703]   \n",
       "5     0.678571      0.637168               [0.678571428, 0.642857142]   \n",
       "6     0.549020      0.480769               [0.549019607, 0.642857142]   \n",
       "0     0.666667      0.661017  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1     0.666667      0.649123   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2     0.711864      0.715447  [0.677419354, 0.711864406, 0.092764378]   \n",
       "3     0.654545      0.666667                            [0.678571428]   \n",
       "4     0.595745      0.647619                            [0.703703703]   \n",
       "5     0.642857      0.620690               [0.678571428, 0.642857142]   \n",
       "6     0.642857      0.620690               [0.549019607, 0.642857142]   \n",
       "0          NaN           NaN  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1          NaN           NaN   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2          NaN           NaN  [0.677419354, 0.711864406, 0.092764378]   \n",
       "3          NaN           NaN                            [0.678571428]   \n",
       "4          NaN           NaN                            [0.703703703]   \n",
       "5          NaN           NaN               [0.678571428, 0.642857142]   \n",
       "6          NaN           NaN               [0.549019607, 0.642857142]   \n",
       "0          NaN           NaN  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1          NaN           NaN   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2          NaN           NaN  [0.677419354, 0.711864406, 0.092764378]   \n",
       "3          NaN           NaN                            [0.678571428]   \n",
       "4          NaN           NaN                            [0.703703703]   \n",
       "5          NaN           NaN               [0.678571428, 0.642857142]   \n",
       "6          NaN           NaN               [0.549019607, 0.642857142]   \n",
       "0     0.006575      0.006863  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1     0.007513      0.007795   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2     0.092764      0.096565  [0.677419354, 0.711864406, 0.092764378]   \n",
       "0          NaN           NaN  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1     0.709677      0.686567   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2     0.358974      0.376068  [0.677419354, 0.711864406, 0.092764378]   \n",
       "\n",
       "                           OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.857900  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.843995  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.872421  \n",
       "3                            [0.666666666]        0.863034  \n",
       "4                            [0.654867256]        0.863034  \n",
       "5               [0.637168141, 0.620689655]        0.825239  \n",
       "6                [0.48076923, 0.620689655]        0.825239  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.882409  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.839697  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.892249  \n",
       "3                            [0.666666666]        0.816359  \n",
       "4                            [0.654867256]        0.801648  \n",
       "5               [0.637168141, 0.620689655]        0.776649  \n",
       "6                [0.48076923, 0.620689655]        0.776649  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.199660  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.498927  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.518656  \n",
       "3                            [0.666666666]        0.519684  \n",
       "4                            [0.654867256]        0.530131  \n",
       "5               [0.637168141, 0.620689655]        0.467319  \n",
       "6                [0.48076923, 0.620689655]        0.467319  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.000000  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.000000  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.162913  \n",
       "3                            [0.666666666]        0.000000  \n",
       "4                            [0.654867256]        0.000000  \n",
       "5               [0.637168141, 0.620689655]        0.241480  \n",
       "6                [0.48076923, 0.620689655]        0.241480  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.987512  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.961903  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.961903  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.405431  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.806157  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.863034  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfResult = pd.concat([referenceresult, withoutverylowMI, withoutlowMI, withoutmediumMI, kmeansundersampling, SMOTERes,\n",
    "                        result1, result2, result3, result4, result5])\n",
    "dfResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c6ddd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>The referencemax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 16:31:18.853308</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.461171</td>\n",
       "      <td>0.979557</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.661017</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.987512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>The referencen_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:31:22.707671</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.114752</td>\n",
       "      <td>0.938324</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.686567</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.961903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest ClassifierWeighted22</th>\n",
       "      <td>The referencen_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:33.443986</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.862324</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.654867</td>\n",
       "      <td>[0.703703703]</td>\n",
       "      <td>[0.654867256]</td>\n",
       "      <td>0.863034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest ClassifierWeighted500</th>\n",
       "      <td>The referencen_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:30:33.010695</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.862324</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>0.863034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifierUnderSampling</th>\n",
       "      <td>The referenceundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 16:30:34.949979</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>4.885998</td>\n",
       "      <td>0.824649</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.825239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifierUpperSampling</th>\n",
       "      <td>The referenceupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 16:30:34.208445</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>4.885998</td>\n",
       "      <td>0.824649</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.637168</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.825239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>The referencescale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 16:31:25.958940</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.114752</td>\n",
       "      <td>0.938324</td>\n",
       "      <td>0.711864</td>\n",
       "      <td>0.715447</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.961903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                         Description  \\\n",
       "Model                                                                                                  \n",
       "DecisionTreeClassifier                           The referencemax_leaf_nodes : 6 + with date columns   \n",
       "Random Forest Classifier                                    The referencen_estimators : 36 + Entropy   \n",
       "Random Forest ClassifierWeighted22                          The referencen_estimators : 36 + Entropy   \n",
       "Random Forest ClassifierWeighted500                         The referencen_estimators : 36 + Entropy   \n",
       "RandomForestClassifierUnderSampling  The referenceundersampled, n_estimators=36, criterion = entropy   \n",
       "RandomForestClassifierUpperSampling     The referenceupsampled, n_estimators=36, criterion = entropy   \n",
       "XGBClassifier                                                     The referencescale_pos_weight = 22   \n",
       "\n",
       "                                                          Date  Precision  \\\n",
       "Model                                                                       \n",
       "DecisionTreeClassifier              2023-05-07 16:31:18.853308   0.980392   \n",
       "Random Forest Classifier            2023-05-07 16:31:22.707671   0.979592   \n",
       "Random Forest ClassifierWeighted22  2023-05-07 16:30:33.443986   0.804348   \n",
       "Random Forest ClassifierWeighted500 2023-05-07 16:30:33.010695   0.804348   \n",
       "RandomForestClassifierUnderSampling 2023-05-07 16:30:34.949979   0.777778   \n",
       "RandomForestClassifierUpperSampling 2023-05-07 16:30:34.208445   0.777778   \n",
       "XGBClassifier                       2023-05-07 16:31:25.958940   0.979592   \n",
       "\n",
       "                                     Recall  F1-score   LogLoss       Mcc  \\\n",
       "Model                                                                       \n",
       "DecisionTreeClassifier                1.000  0.990099  0.461171  0.979557   \n",
       "Random Forest Classifier              0.960  0.969697  1.114752  0.938324   \n",
       "Random Forest ClassifierWeighted22    0.925  0.860465  0.060284  0.862324   \n",
       "Random Forest ClassifierWeighted500   0.925  0.860465  0.060284  0.862324   \n",
       "RandomForestClassifierUnderSampling   0.875  0.823529  4.885998  0.824649   \n",
       "RandomForestClassifierUpperSampling   0.875  0.823529  4.885998  0.824649   \n",
       "XGBClassifier                         0.960  0.969697  1.114752  0.938324   \n",
       "\n",
       "                                     PublicScore  PrivateScore  \\\n",
       "Model                                                            \n",
       "DecisionTreeClassifier                  0.666667      0.661017   \n",
       "Random Forest Classifier                0.709677      0.686567   \n",
       "Random Forest ClassifierWeighted22      0.703704      0.654867   \n",
       "Random Forest ClassifierWeighted500     0.678571      0.666667   \n",
       "RandomForestClassifierUnderSampling     0.642857      0.620690   \n",
       "RandomForestClassifierUpperSampling     0.678571      0.637168   \n",
       "XGBClassifier                           0.711864      0.715447   \n",
       "\n",
       "                                                              OldPublicScore  \\\n",
       "Model                                                                          \n",
       "DecisionTreeClassifier               [0.666666666, 0.666666666, 0.006575486]   \n",
       "Random Forest Classifier              [0.69090909, 0.666666666, 0.007513148]   \n",
       "Random Forest ClassifierWeighted22                             [0.703703703]   \n",
       "Random Forest ClassifierWeighted500                            [0.678571428]   \n",
       "RandomForestClassifierUnderSampling               [0.549019607, 0.642857142]   \n",
       "RandomForestClassifierUpperSampling               [0.678571428, 0.642857142]   \n",
       "XGBClassifier                        [0.677419354, 0.711864406, 0.092764378]   \n",
       "\n",
       "                                                             OldPrivateScore  \\\n",
       "Model                                                                          \n",
       "DecisionTreeClassifier               [0.661016949, 0.661016949, 0.006863327]   \n",
       "Random Forest Classifier             [0.649122807, 0.649122807, 0.007794933]   \n",
       "Random Forest ClassifierWeighted22                             [0.654867256]   \n",
       "Random Forest ClassifierWeighted500                            [0.666666666]   \n",
       "RandomForestClassifierUnderSampling                [0.48076923, 0.620689655]   \n",
       "RandomForestClassifierUpperSampling               [0.637168141, 0.620689655]   \n",
       "XGBClassifier                        [0.676923076, 0.715447154, 0.096564531]   \n",
       "\n",
       "                                     MeanOurMetrics  \n",
       "Model                                                \n",
       "DecisionTreeClassifier                     0.987512  \n",
       "Random Forest Classifier                   0.961903  \n",
       "Random Forest ClassifierWeighted22         0.863034  \n",
       "Random Forest ClassifierWeighted500        0.863034  \n",
       "RandomForestClassifierUnderSampling        0.825239  \n",
       "RandomForestClassifierUpperSampling        0.825239  \n",
       "XGBClassifier                              0.961903  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfResult.groupby(\"Model\").max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e425a7b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can only compare identically-labeled Series objects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dfResult[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDescription\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mloc[[\u001b[43mdfResult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPublicScore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdfResult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mModel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPublicScore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m]]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\AILab-ECAM4\\lib\\site-packages\\pandas\\core\\ops\\common.py:72\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     70\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\AILab-ECAM4\\lib\\site-packages\\pandas\\core\\arraylike.py:42\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\AILab-ECAM4\\lib\\site-packages\\pandas\\core\\series.py:6237\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   6234\u001b[0m res_name \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mget_op_result_name(\u001b[38;5;28mself\u001b[39m, other)\n\u001b[0;32m   6236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, Series) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indexed_same(other):\n\u001b[1;32m-> 6237\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only compare identically-labeled Series objects\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6239\u001b[0m lvalues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   6240\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mValueError\u001b[0m: Can only compare identically-labeled Series objects"
     ]
    }
   ],
   "source": [
    "dfResult[[\"Description\"]].loc[[dfResult['PublicScore'] == dfResult.groupby([\"Model\"])['PublicScore'].max()]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f71d0234",
   "metadata": {},
   "source": [
    "# Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba35bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>La basemax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-06 20:37:01.701978</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>0.857566</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>[0.661016949]</td>\n",
       "      <td>0.857900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>La basen_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-06 20:37:02.891559</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.019592</td>\n",
       "      <td>0.848262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909]</td>\n",
       "      <td>[0.649122807]</td>\n",
       "      <td>0.848830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>La basescale_pos_weight = 22</td>\n",
       "      <td>2023-05-06 20:37:04.316049</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.881747</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354]</td>\n",
       "      <td>[0.676923076]</td>\n",
       "      <td>0.882152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>La baseupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-06 20:37:06.774426</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.022606</td>\n",
       "      <td>0.829975</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.637168141]</td>\n",
       "      <td>0.830880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>La baseundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-06 20:37:09.025865</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.022606</td>\n",
       "      <td>0.829975</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.549019607]</td>\n",
       "      <td>[0.48076923]</td>\n",
       "      <td>0.830880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Kmeans UnderSamplingn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:31:00.285578</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.114752</td>\n",
       "      <td>0.938324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.961903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Kmeans UnderSamplingon balanced data</td>\n",
       "      <td>2023-05-07 16:31:00.404309</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.114752</td>\n",
       "      <td>0.938324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.961903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>SMOTEmax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 16:31:18.853308</td>\n",
       "      <td>0.113372</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.203125</td>\n",
       "      <td>0.461171</td>\n",
       "      <td>0.330225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.405431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>SMOTEn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 16:31:22.707671</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.027128</td>\n",
       "      <td>0.804629</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.806157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>SMOTEon balanced data</td>\n",
       "      <td>2023-05-07 16:31:25.958940</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.862324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.863034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Model  \\\n",
       "0               Decision Tree Classifier   \n",
       "1               Random Forest Classifier   \n",
       "2                          XGBClassifier   \n",
       "3    RandomForestClassifierUpperSampling   \n",
       "4    RandomForestClassifierUnderSampling   \n",
       "..                                   ...   \n",
       "248             Random Forest Classifier   \n",
       "249                        XGBClassifier   \n",
       "250               DecisionTreeClassifier   \n",
       "251             Random Forest Classifier   \n",
       "252                        XGBClassifier   \n",
       "\n",
       "                                                   Description  \\\n",
       "0                La basemax_leaf_nodes : 6 + with date columns   \n",
       "1                           La basen_estimators : 36 + Entropy   \n",
       "2                                 La basescale_pos_weight = 22   \n",
       "3       La baseupsampled, n_estimators=36, criterion = entropy   \n",
       "4    La baseundersampled, n_estimators=36, criterion = entropy   \n",
       "..                                                         ...   \n",
       "248            Kmeans UnderSamplingn_estimators : 36 + Entropy   \n",
       "249                       Kmeans UnderSamplingon balanced data   \n",
       "250                SMOTEmax_leaf_nodes : 6 + with date columns   \n",
       "251                           SMOTEn_estimators : 36 + Entropy   \n",
       "252                                      SMOTEon balanced data   \n",
       "\n",
       "                           Date  Precision  Recall  F1-score   LogLoss  \\\n",
       "0    2023-05-06 20:37:01.701978   0.891892   0.825  0.857143  0.016578   \n",
       "1    2023-05-06 20:37:02.891559   0.800000   0.900  0.847059  0.019592   \n",
       "2    2023-05-06 20:37:04.316049   0.840909   0.925  0.880952  0.015071   \n",
       "3    2023-05-06 20:37:06.774426   0.765957   0.900  0.827586  0.022606   \n",
       "4    2023-05-06 20:37:09.025865   0.765957   0.900  0.827586  0.022606   \n",
       "..                          ...        ...     ...       ...       ...   \n",
       "248  2023-05-07 16:31:00.285578   0.979592   0.960  0.969697  1.114752   \n",
       "249  2023-05-07 16:31:00.404309   0.979592   0.960  0.969697  1.114752   \n",
       "250  2023-05-07 16:31:18.853308   0.113372   0.975  0.203125  0.461171   \n",
       "251  2023-05-07 16:31:22.707671   0.720000   0.900  0.800000  0.027128   \n",
       "252  2023-05-07 16:31:25.958940   0.804348   0.925  0.860465  0.018085   \n",
       "\n",
       "          Mcc  PublicScore  PrivateScore  \\\n",
       "0    0.857566          NaN           NaN   \n",
       "1    0.848262          NaN           NaN   \n",
       "2    0.881747          NaN           NaN   \n",
       "3    0.829975          NaN           NaN   \n",
       "4    0.829975          NaN           NaN   \n",
       "..        ...          ...           ...   \n",
       "248  0.938324          NaN           NaN   \n",
       "249  0.938324          NaN           NaN   \n",
       "250  0.330225          NaN           NaN   \n",
       "251  0.804629          NaN           NaN   \n",
       "252  0.862324          NaN           NaN   \n",
       "\n",
       "                              OldPublicScore  \\\n",
       "0                              [0.666666666]   \n",
       "1                               [0.69090909]   \n",
       "2                              [0.677419354]   \n",
       "3                              [0.678571428]   \n",
       "4                              [0.549019607]   \n",
       "..                                       ...   \n",
       "248   [0.69090909, 0.666666666, 0.007513148]   \n",
       "249  [0.677419354, 0.711864406, 0.092764378]   \n",
       "250  [0.666666666, 0.666666666, 0.006575486]   \n",
       "251   [0.69090909, 0.666666666, 0.007513148]   \n",
       "252  [0.677419354, 0.711864406, 0.092764378]   \n",
       "\n",
       "                             OldPrivateScore  MeanOurMetrics  \n",
       "0                              [0.661016949]        0.857900  \n",
       "1                              [0.649122807]        0.848830  \n",
       "2                              [0.676923076]        0.882152  \n",
       "3                              [0.637168141]        0.830880  \n",
       "4                               [0.48076923]        0.830880  \n",
       "..                                       ...             ...  \n",
       "248  [0.649122807, 0.649122807, 0.007794933]        0.961903  \n",
       "249  [0.676923076, 0.715447154, 0.096564531]        0.961903  \n",
       "250  [0.661016949, 0.661016949, 0.006863327]        0.405431  \n",
       "251  [0.649122807, 0.649122807, 0.007794933]        0.806157  \n",
       "252  [0.676923076, 0.715447154, 0.096564531]        0.863034  \n",
       "\n",
       "[253 rows x 13 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfresult  = pd.read_csv(\"output/resultatsTestEverything.csv\")\n",
    "dfresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a49624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les meilleurs résultat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarah\\AppData\\Local\\Temp\\ipykernel_2988\\2367281751.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  dfresult.groupby(['Model'])['Precision','Recall','F1-score','LogLoss','MeanOurMetrics'].max()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classifier</th>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.882409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.461171</td>\n",
       "      <td>0.987512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.114752</td>\n",
       "      <td>0.961903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest ClassifierWeighted</th>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.863034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest ClassifierWeighted22</th>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.863034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest ClassifierWeighted500</th>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.863034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifierUnderSampling</th>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>4.923675</td>\n",
       "      <td>0.839697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifierUpperSampling</th>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>4.923675</td>\n",
       "      <td>0.839697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.114752</td>\n",
       "      <td>0.961903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Precision  Recall  F1-score   LogLoss  \\\n",
       "Model                                                                        \n",
       "Decision Tree Classifier              0.942857   0.825  0.880000  0.060284   \n",
       "DecisionTreeClassifier                0.980392   1.000  0.990099  0.461171   \n",
       "Random Forest Classifier              0.979592   0.960  0.969697  1.114752   \n",
       "Random Forest ClassifierWeighted      0.804348   0.925  0.860465  0.018085   \n",
       "Random Forest ClassifierWeighted22    0.823529   0.925  0.860465  0.060284   \n",
       "Random Forest ClassifierWeighted500   0.804348   0.925  0.860465  0.060284   \n",
       "RandomForestClassifierUnderSampling   0.782609   0.900  0.837209  4.923675   \n",
       "RandomForestClassifierUpperSampling   0.782609   0.900  0.837209  4.923675   \n",
       "XGBClassifier                         0.979592   0.960  0.969697  1.114752   \n",
       "\n",
       "                                     MeanOurMetrics  \n",
       "Model                                                \n",
       "Decision Tree Classifier                   0.882409  \n",
       "DecisionTreeClassifier                     0.987512  \n",
       "Random Forest Classifier                   0.961903  \n",
       "Random Forest ClassifierWeighted           0.863034  \n",
       "Random Forest ClassifierWeighted22         0.863034  \n",
       "Random Forest ClassifierWeighted500        0.863034  \n",
       "RandomForestClassifierUnderSampling        0.839697  \n",
       "RandomForestClassifierUpperSampling        0.839697  \n",
       "XGBClassifier                              0.961903  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Les meilleurs résultat\")\n",
    "dfresult.groupby(['Model'])['Precision','Recall','F1-score','LogLoss','MeanOurMetrics'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e794338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les pire résultat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarah\\AppData\\Local\\Temp\\ipykernel_2988\\2101499374.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  dfresult.groupby(['Model'])['Precision','Recall','F1-score','LogLoss','MeanOurMetrics'].min()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classifier</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.013564</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.113372</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.013564</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.019592</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest ClassifierWeighted</th>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.863034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest ClassifierWeighted22</th>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest ClassifierWeighted500</th>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifierUnderSampling</th>\n",
       "      <td>0.010398</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.020544</td>\n",
       "      <td>0.021099</td>\n",
       "      <td>0.241480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifierUpperSampling</th>\n",
       "      <td>0.010398</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.020544</td>\n",
       "      <td>0.021099</td>\n",
       "      <td>0.241480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.162791</td>\n",
       "      <td>0.013564</td>\n",
       "      <td>0.162913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Precision  Recall  F1-score   LogLoss  \\\n",
       "Model                                                                        \n",
       "Decision Tree Classifier              0.500000   0.000  0.090909  0.013564   \n",
       "DecisionTreeClassifier                0.113372   0.000  0.090909  0.013564   \n",
       "Random Forest Classifier              0.566667   0.000  0.484848  0.019592   \n",
       "Random Forest ClassifierWeighted      0.804348   0.925  0.860465  0.018085   \n",
       "Random Forest ClassifierWeighted22    0.653846   0.000  0.491228  0.018085   \n",
       "Random Forest ClassifierWeighted500   0.629630   0.000  0.482759  0.018085   \n",
       "RandomForestClassifierUnderSampling   0.010398   0.400  0.020544  0.021099   \n",
       "RandomForestClassifierUpperSampling   0.010398   0.400  0.020544  0.021099   \n",
       "XGBClassifier                         0.152174   0.175  0.162791  0.013564   \n",
       "\n",
       "                                     MeanOurMetrics  \n",
       "Model                                                \n",
       "Decision Tree Classifier                   0.000000  \n",
       "DecisionTreeClassifier                     0.000000  \n",
       "Random Forest Classifier                   0.000000  \n",
       "Random Forest ClassifierWeighted           0.863034  \n",
       "Random Forest ClassifierWeighted22         0.000000  \n",
       "Random Forest ClassifierWeighted500        0.000000  \n",
       "RandomForestClassifierUnderSampling        0.241480  \n",
       "RandomForestClassifierUpperSampling        0.241480  \n",
       "XGBClassifier                              0.162913  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Les pire résultat\")\n",
    "dfresult.groupby(['Model'])['Precision','Recall','F1-score','LogLoss','MeanOurMetrics'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596a8536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_undersampled"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
