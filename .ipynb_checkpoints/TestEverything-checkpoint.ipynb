{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ce6dff4",
   "metadata": {},
   "source": [
    "# TestEverything\n",
    "\n",
    "This script allow us to test all the models and explore those with different feature engineering and ways to deal with the unbalanced data. To compare the models, we use a function. If the dataset provided is unbalanced, 7 models will be evaluated : \n",
    "1. Decision Tree Classifier\n",
    "2. Random Forest Classifier\n",
    "3. XGBoost Classifier with a positive weight of 22\n",
    "4. Random Forest Classifier with a positive weight of 500\n",
    "5. Random Forest Classifier with a positive weight of 22\n",
    "6. Random Forest Classifier with random oversampling\n",
    "7. Random Forest Classifier with random undersampling\n",
    "\n",
    "If the dataset given to the function is balanced, it will only evaluate the first, second models and also a XGBoost Classifier without the 22 positive weight. A table at the end of the script compare those models. \n",
    "\n",
    "\n",
    "First, we had to make basic preprocessing to train a model and have references performances metrics. (1. Small preprocessing). After that, we tested 5 scenarios : \n",
    "- Scenario 1: With All columns\n",
    "- Scenario 2: Dropping Unique ID columns\n",
    "- Scenario 3: Adding new features\n",
    "- Scenario 4 : Removing Low MI columns\n",
    "- Scenario 5 : The optimal dataset\n",
    "Those scenarios add columns and feature and then evaluate them to discover which one is the better.\n",
    "\n",
    "In the second part (2. Test de different model with the basic features), we are evaluating several models but without the additional features : \n",
    "\n",
    "- 2.1. The reference model\n",
    "- 2.2. Play with deleting the low MI columns\n",
    "    - 2.2.1 Delecte the very low MI columns\n",
    "    - 2.2.2 Delete low MI\n",
    "    - 2.2.3 Delete medium MI\n",
    "- 2.3 Undersampling with K-means\n",
    "- 2.4. SMOTE (Synthetic Minority Oversampling Technique)\n",
    "\n",
    "We finish this script with a comparison. We highlight the models with the best public score and the best mean of our performance metric.  (We know that the mean of our performance metrics is not an ideal way to evaluate a model but it is just to give an idea)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddf72aa",
   "metadata": {},
   "source": [
    "### Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "efcbf836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import resample\n",
    "from sklearn.cluster import KMeans \n",
    "import datetime as dt\n",
    "from math import ceil, sqrt\n",
    "from Utils import *\n",
    "pd.set_option('max_colwidth', None)\n",
    "from EvaluationMetric import *\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad107488",
   "metadata": {},
   "source": [
    "#### Function used to compare the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5bae6abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparemodels(train_X, train_y, val_X, test_X, generaldescription, unbalanced = True):\n",
    "    res = []\n",
    "\n",
    "    model1 = DecisionTreeClassifier(max_leaf_nodes= 6, random_state=1)\n",
    "    model1.fit(train_X, train_y)\n",
    "    preds_val1 = model1.predict(val_X)\n",
    "    model_test1 = model1.predict(test_X)\n",
    "    description = generaldescription+\"max_leaf_nodes : 6 + with date columns\"\n",
    "    metrics1 = listmetrics(val_y, preds_val1, \"DecisionTreeClassifier\", description)\n",
    "    m1Public = [0.666666666, 0.666666666, 0.006575486]\n",
    "    m1Private = [0.661016949, 0.661016949, 0.006863327]\n",
    "    res.append(metrics1)\n",
    "    df1 = getscoreforcsv(index_val, model_test1, name_file = \"TreeClass5leaf.csv\")\n",
    "\n",
    "\n",
    "    model2 = RandomForestClassifier(n_estimators=36, criterion = 'entropy', random_state=1)\n",
    "    model2.fit(train_X, train_y)\n",
    "    preds_val2 = model2.predict(val_X)\n",
    "    model_test2 = model2.predict(test_X)\n",
    "    description = generaldescription+\"n_estimators : 36 + Entropy\"\n",
    "    metrics2 = listmetrics(val_y, preds_val2, \"Random Forest Classifier\", description)\n",
    "    m2Public = [0.690909090, 0.666666666, 0.007513148]\n",
    "    m2Private = [0.649122807, 0.649122807, 0.007794933]\n",
    "    res.append(metrics2)\n",
    "    df2 = getscoreforcsv(index_val, model_test2, name_file = \"RandomForestN36Entropy.csv\")\n",
    "\n",
    "\n",
    "    ##################ICi donne un 0.71 de scrore !!! mtn comprendre pq en diminuant les feature si bon score mais que pour lui !############\n",
    "    #Ne fonctionne pas bien quadn le training set est entier. \n",
    "    if (unbalanced) : \n",
    "        model2 = XGBClassifier(scale_pos_weight=22, random_state=1)\n",
    "        description = generaldescription+\"scale_pos_weight = 22\"\n",
    "    else : \n",
    "        model2 = XGBClassifier(random_state=1)\n",
    "        description = generaldescription+\"on balanced data\"\n",
    "    model2.fit(train_X, train_y)\n",
    "    preds_val2 = model2.predict(val_X)\n",
    "    model_test2 = model2.predict(test_X)\n",
    "    metrics2 = listmetrics(val_y, preds_val2, \"XGBClassifier\", description)\n",
    "    m3Public = [0.677419354, 0.711864406, 0.092764378]\n",
    "    m3Private = [0.676923076,  0.715447154, 0.096564531]\n",
    "    res.append(metrics2)\n",
    "    df2 = getscoreforcsv(index_val, model_test2, name_file = \"XGBClassifierW22.csv\")\n",
    "    \n",
    "    if (unbalanced) :\n",
    "        \n",
    "        model2 = RandomForestClassifier(n_estimators=36, criterion = 'entropy', class_weight = {0: 95469, 1 : 193}, random_state=1)\n",
    "        model2.fit(train_X, train_y)\n",
    "        preds_val2 = model2.predict(val_X)\n",
    "        model_test2 = model2.predict(test_X)\n",
    "        description = generaldescription+\"n_estimators : 36 + Entropy\"\n",
    "        metrics2 = listmetrics(val_y, preds_val2, \"Random Forest ClassifierWeighted500\", description)\n",
    "        m500Public = [0.678571428]\n",
    "        m500Private = [0.666666666]\n",
    "        res.append(metrics2)\n",
    "        df2 = getscoreforcsv(index_val, model_test2, name_file = \"RandomForestWeigthed500.csv\")\n",
    "\n",
    "        model2 = RandomForestClassifier(n_estimators=36, criterion = 'entropy', class_weight = {0: 22, 1 : 1}, random_state=1)\n",
    "        model2.fit(train_X, train_y)\n",
    "        preds_val2 = model2.predict(val_X)\n",
    "        model_test2 = model2.predict(test_X)\n",
    "        description = generaldescription+\"n_estimators : 36 + Entropy\"\n",
    "        metrics2 = listmetrics(val_y, preds_val2, \"Random Forest ClassifierWeighted22\", description)\n",
    "        m22Public = [0.703703703]\n",
    "        m22Private = [0.654867256]\n",
    "        res.append(metrics2)\n",
    "        df2 = getscoreforcsv(index_val, model_test2, name_file = \"RandomForestWeigthed22.csv\")\n",
    "\n",
    "        #oversamplesimple\n",
    "        X_con = pd.concat([train_X, train_y], axis=1) \n",
    "        not_fraud = X_con[X_con.FraudResult==0]\n",
    "        fraud = X_con[X_con.FraudResult==1]\n",
    "        fraud_upsampled = resample(fraud, replace=True, n_samples=len(not_fraud), # match number in majority class\n",
    "                                random_state=1) # reproducible results\n",
    "        upsampled = pd.concat([not_fraud, fraud_upsampled])\n",
    "        train_y_over_sampled = upsampled.FraudResult\n",
    "        train_X_over_sampled = upsampled.drop('FraudResult', axis=1)\n",
    "        upsampledmodel = RandomForestClassifier(n_estimators=36, criterion = 'entropy', random_state=1)\n",
    "        upsampledmodel.fit(train_X_over_sampled, train_y_over_sampled)\n",
    "        upsampled_pred = upsampledmodel.predict(val_X)\n",
    "        model_test = upsampledmodel.predict(test_X)\n",
    "        description = generaldescription+\"upsampled, n_estimators=36, criterion = entropy\"\n",
    "        metrics = listmetrics(val_y, upsampled_pred, \"RandomForestClassifierUpperSampling\", description)\n",
    "        m4Public = [0.678571428, 0.642857142]\n",
    "        m4Private = [0.637168141, 0.620689655]\n",
    "        res.append(metrics)\n",
    "        df = getscoreforcsv(index_val, model_test, name_file = \"RandomForestClassifierUpSample.csv\")\n",
    "\n",
    "        #Undersampling\n",
    "        not_fraud_downsampled  = resample(not_fraud, replace=False, n_samples=len(fraud), # match number in minority  class\n",
    "                                random_state=1) # reproducible results\n",
    "        downsampled  = pd.concat([not_fraud_downsampled , fraud])\n",
    "        train_y_undersampled = downsampled.FraudResult\n",
    "        train_X_undersampled = downsampled.drop('FraudResult', axis=1)\n",
    "        undersampled = RandomForestClassifier(n_estimators=36, criterion = 'entropy', random_state=1)\n",
    "        undersampled.fit(train_X_over_sampled, train_y_over_sampled)\n",
    "        undersampled_pred = undersampled.predict(val_X)\n",
    "        model_test = undersampled.predict(test_X)\n",
    "        description = generaldescription+\"undersampled, n_estimators=36, criterion = entropy\"\n",
    "        metrics = listmetrics(val_y, undersampled_pred, \"RandomForestClassifierUnderSampling\", description)\n",
    "        m5Public = [0.549019607, 0.642857142]\n",
    "        m5Private = [0.480769230, 0.620689655]\n",
    "        res.append(metrics)\n",
    "        df = getscoreforcsv(index_val, model_test, name_file = \"RandomForestClassifierUndersampled.csv\")\n",
    "        \n",
    "        loldPublics = [m1Public, m2Public, m3Public, m500Public,m22Public, m4Public, m5Public]\n",
    "        loldPrivate = [m1Private, m2Private, m3Private, m500Private, m22Private, m4Private, m5Private]\n",
    "        \n",
    "    else:\n",
    "        loldPublics = [m1Public, m2Public, m3Public]\n",
    "        loldPrivate = [m1Private, m2Private,  m3Private]\n",
    "        \n",
    "\n",
    "\n",
    "    dfres = listmetricsintodf(res)\n",
    "    dfres[\"OldPublicScore\"] = loldPublics\n",
    "    dfres[\"OldPrivateScore\"] = loldPrivate\n",
    "    dfres[\"MeanOurMetrics\"] = dfres[['Precision', 'Recall','F1-score','Mcc']].mean(axis=1)\n",
    "    dfres.to_csv('output/resultatsTestEverything.csv', mode='a',index=False,header = False) \n",
    "    return dfres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84994fe9",
   "metadata": {},
   "source": [
    "# 1. Preprocessing and adding features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6fb17ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"input/training.csv\")\n",
    "data = df.copy()\n",
    "y_train = df[\"FraudResult\"]\n",
    "X_test = pd.read_csv(\"input/test.csv\")\n",
    "X_valid = X_test.copy()\n",
    "sample_submission = pd.read_csv(\"input/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "65b295ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping column with one unique values:  ['CurrencyCode', 'CountryCode']\n",
      "Converting columns with Id:  ['TransactionId', 'BatchId', 'AccountId', 'SubscriptionId', 'CustomerId', 'ProviderId', 'ProductId', 'ChannelId']\n"
     ]
    }
   ],
   "source": [
    "# Count the number of unique entries in each column\n",
    "unique_counts = data.nunique()\n",
    "\n",
    "# Select only columns with more than one unique entry\n",
    "drop_cols = unique_counts[unique_counts == 1].index.tolist()\n",
    "print(\"Dropping column with one unique values: \", drop_cols)\n",
    "\n",
    "# Drop the selected columns\n",
    "data = data.drop(columns=drop_cols)\n",
    "X_test = X_test.drop(columns=drop_cols)\n",
    "\n",
    "# Get a list of column names that contain the string \"id\" in their name\n",
    "id_cols = data.filter(like=\"Id\").columns.tolist()\n",
    "\n",
    "# Print the list of column names\n",
    "print(\"Converting columns with Id: \", id_cols)\n",
    "\n",
    "# Remove column name prefix and convert to integer data type\n",
    "data[id_cols] = (\n",
    "    data[id_cols]\n",
    "    .astype(str)\n",
    "    .apply(lambda x: x.str.replace(x.name + \"_\", \"\"))\n",
    "    .astype(int)\n",
    ")\n",
    "X_test[id_cols] = (\n",
    "    X_test[id_cols]\n",
    "    .astype(str)\n",
    "    .apply(lambda x: x.str.replace(x.name + \"_\", \"\"))\n",
    "    .astype(int)\n",
    ")\n",
    "\n",
    "# convert TransactionStartTime column to datetime format\n",
    "data[\"TransactionStartTime\"] = pd.to_datetime(\n",
    "    df[\"TransactionStartTime\"], format=\"%Y-%m-%dT%H:%M:%SZ\"\n",
    ")\n",
    "X_test[\"TransactionStartTime\"] = pd.to_datetime(\n",
    "    X_test[\"TransactionStartTime\"], format=\"%Y-%m-%dT%H:%M:%SZ\"\n",
    ")\n",
    "\n",
    "# extract date and time features\n",
    "data[\"TransactionDayOfWeek\"] = data[\"TransactionStartTime\"].dt.dayofweek\n",
    "data[\"TransactionDayOfMonth\"] = data[\"TransactionStartTime\"].dt.day\n",
    "data[\"TransactionHour\"] = data[\"TransactionStartTime\"].dt.hour\n",
    "data[\"TransactionMinute\"] = data[\"TransactionStartTime\"].dt.minute\n",
    "\n",
    "X_test[\"TransactionDayOfWeek\"] = X_test[\"TransactionStartTime\"].dt.dayofweek\n",
    "X_test[\"TransactionDayOfMonth\"] = X_test[\"TransactionStartTime\"].dt.day\n",
    "X_test[\"TransactionHour\"] = X_test[\"TransactionStartTime\"].dt.hour\n",
    "X_test[\"TransactionMinute\"] = X_test[\"TransactionStartTime\"].dt.minute\n",
    "\n",
    "# drop TransactionStartTime\n",
    "data = data.drop(\"TransactionStartTime\", axis=1)\n",
    "X_test = X_test.drop(\"TransactionStartTime\", axis=1)\n",
    "\n",
    "# Factorize the \"ProductCategory\" column\n",
    "data['ProductCategory'] = pd.factorize(data['ProductCategory'])[0] + 1\n",
    "X_test['ProductCategory'] = pd.factorize(X_test['ProductCategory'])[0] + 1\n",
    "# Convert the \"ProductCategory\" column to integer data type\n",
    "data['ProductCategory'] = data['ProductCategory'].astype(int)\n",
    "X_test['ProductCategory'] = X_test['ProductCategory'].astype(int)\n",
    "\n",
    "# Removing redundant data\n",
    "data[\"Expense\"] = data[\"Amount\"] < 0\n",
    "data.Expense = data.Expense.astype(int)\n",
    "data = data.drop(\"Amount\", axis=1)\n",
    "\n",
    "X_test[\"Expense\"] = X_test[\"Amount\"] < 0\n",
    "X_test.Expense = X_test.Expense.astype(int)\n",
    "X_test = X_test.drop(\"Amount\", axis=1)\n",
    "\n",
    "# Continous value should be float\n",
    "data[\"Value\"] = data[\"Value\"].astype(float)\n",
    "X_test[\"Value\"] = X_test[\"Value\"].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5113b99",
   "metadata": {},
   "source": [
    "## Scenario 1: With All columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f35e9b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>With All Columnsmax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 17:57:02.136138</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.013564</td>\n",
       "      <td>0.881780</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.882409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>With All Columnsn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 17:57:04.957171</td>\n",
       "      <td>0.760870</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.024113</td>\n",
       "      <td>0.815615</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.816359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>With All Columnsscale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 17:57:07.102768</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.881747</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.882152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest ClassifierWeighted500</td>\n",
       "      <td>With All Columnsn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 17:57:09.669936</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.873563</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>0.876185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>0.877065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest ClassifierWeighted22</td>\n",
       "      <td>With All Columnsn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 17:57:12.309765</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.022606</td>\n",
       "      <td>0.835448</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.703703703]</td>\n",
       "      <td>[0.654867256]</td>\n",
       "      <td>0.836753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>With All Columnsupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 17:57:17.652641</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.028635</td>\n",
       "      <td>0.790189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.791498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>With All Columnsundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 17:57:23.282157</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.028635</td>\n",
       "      <td>0.790189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.791498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Model  \\\n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  Random Forest ClassifierWeighted500   \n",
       "4   Random Forest ClassifierWeighted22   \n",
       "5  RandomForestClassifierUpperSampling   \n",
       "6  RandomForestClassifierUnderSampling   \n",
       "\n",
       "                                                          Description  \\\n",
       "0              With All Columnsmax_leaf_nodes : 6 + with date columns   \n",
       "1                         With All Columnsn_estimators : 36 + Entropy   \n",
       "2                               With All Columnsscale_pos_weight = 22   \n",
       "3                         With All Columnsn_estimators : 36 + Entropy   \n",
       "4                         With All Columnsn_estimators : 36 + Entropy   \n",
       "5     With All Columnsupsampled, n_estimators=36, criterion = entropy   \n",
       "6  With All Columnsundersampled, n_estimators=36, criterion = entropy   \n",
       "\n",
       "                        Date  Precision  Recall  F1-score   LogLoss       Mcc  \\\n",
       "0 2023-05-07 17:57:02.136138   0.942857   0.825  0.880000  0.013564  0.881780   \n",
       "1 2023-05-07 17:57:04.957171   0.760870   0.875  0.813953  0.024113  0.815615   \n",
       "2 2023-05-07 17:57:07.102768   0.840909   0.925  0.880952  0.015071  0.881747   \n",
       "3 2023-05-07 17:57:09.669936   0.808511   0.950  0.873563  0.016578  0.876185   \n",
       "4 2023-05-07 17:57:12.309765   0.755102   0.925  0.831461  0.022606  0.835448   \n",
       "5 2023-05-07 17:57:17.652641   0.714286   0.875  0.786517  0.028635  0.790189   \n",
       "6 2023-05-07 17:57:23.282157   0.714286   0.875  0.786517  0.028635  0.790189   \n",
       "\n",
       "   PublicScore  PrivateScore                           OldPublicScore  \\\n",
       "0          NaN           NaN  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1          NaN           NaN   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2          NaN           NaN  [0.677419354, 0.711864406, 0.092764378]   \n",
       "3          NaN           NaN                            [0.678571428]   \n",
       "4          NaN           NaN                            [0.703703703]   \n",
       "5          NaN           NaN               [0.678571428, 0.642857142]   \n",
       "6          NaN           NaN               [0.549019607, 0.642857142]   \n",
       "\n",
       "                           OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.882409  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.816359  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.882152  \n",
       "3                            [0.666666666]        0.877065  \n",
       "4                            [0.654867256]        0.836753  \n",
       "5               [0.637168141, 0.620689655]        0.791498  \n",
       "6                [0.48076923, 0.620689655]        0.791498  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate data (drop FraudResult before)\n",
    "X_1 = data.drop(\"FraudResult\", axis=1)\n",
    "# mi_score = make_mi_scores(data, y_train)\n",
    "train_X, val_X, train_y, val_y = train_test_split(X_1, y_train, random_state = 0)\n",
    "result1 = comparemodels(train_X, train_y, val_X, X_test, \"With All Columns\", unbalanced=True)\n",
    "result1[\"PublicScore\"] = [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "result1[\"PrivateScore\"] = [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "result1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d808c490",
   "metadata": {},
   "source": [
    "## Scenario 2: Dropping Unique ID columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "49a7bf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropping_cols = [\"TransactionId\", \"BatchId\", \"AccountId\", \"CustomerId\", \"SubscriptionId\"]\n",
    "\n",
    "for col in dropping_cols:\n",
    "    data = data.drop(col, axis=1)\n",
    "    X_test = X_test.drop(col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "17906ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Dropping Unique ID columnsmax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 17:57:24.856839</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.871873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.872101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Dropping Unique ID columnsn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 17:57:26.093747</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.839506</td>\n",
       "      <td>0.019592</td>\n",
       "      <td>0.839298</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.839518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Dropping Unique ID columnsscale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 17:57:27.716393</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.874791</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.874948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest ClassifierWeighted500</td>\n",
       "      <td>Dropping Unique ID columnsn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 17:57:29.004512</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.864198</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>0.864033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>0.864222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest ClassifierWeighted22</td>\n",
       "      <td>Dropping Unique ID columnsn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 17:57:30.392655</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>0.857566</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.703703703]</td>\n",
       "      <td>[0.654867256]</td>\n",
       "      <td>0.857900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>Dropping Unique ID columnsupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 17:57:33.849408</td>\n",
       "      <td>0.760870</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.024113</td>\n",
       "      <td>0.815615</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.816359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>Dropping Unique ID columnsundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 17:57:37.365005</td>\n",
       "      <td>0.760870</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.024113</td>\n",
       "      <td>0.815615</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.816359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Model  \\\n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  Random Forest ClassifierWeighted500   \n",
       "4   Random Forest ClassifierWeighted22   \n",
       "5  RandomForestClassifierUpperSampling   \n",
       "6  RandomForestClassifierUnderSampling   \n",
       "\n",
       "                                                                    Description  \\\n",
       "0              Dropping Unique ID columnsmax_leaf_nodes : 6 + with date columns   \n",
       "1                         Dropping Unique ID columnsn_estimators : 36 + Entropy   \n",
       "2                               Dropping Unique ID columnsscale_pos_weight = 22   \n",
       "3                         Dropping Unique ID columnsn_estimators : 36 + Entropy   \n",
       "4                         Dropping Unique ID columnsn_estimators : 36 + Entropy   \n",
       "5     Dropping Unique ID columnsupsampled, n_estimators=36, criterion = entropy   \n",
       "6  Dropping Unique ID columnsundersampled, n_estimators=36, criterion = entropy   \n",
       "\n",
       "                        Date  Precision  Recall  F1-score   LogLoss       Mcc  \\\n",
       "0 2023-05-07 17:57:24.856839   0.894737   0.850  0.871795  0.015071  0.871873   \n",
       "1 2023-05-07 17:57:26.093747   0.829268   0.850  0.839506  0.019592  0.839298   \n",
       "2 2023-05-07 17:57:27.716393   0.875000   0.875  0.875000  0.015071  0.874791   \n",
       "3 2023-05-07 17:57:29.004512   0.853659   0.875  0.864198  0.016578  0.864033   \n",
       "4 2023-05-07 17:57:30.392655   0.891892   0.825  0.857143  0.016578  0.857566   \n",
       "5 2023-05-07 17:57:33.849408   0.760870   0.875  0.813953  0.024113  0.815615   \n",
       "6 2023-05-07 17:57:37.365005   0.760870   0.875  0.813953  0.024113  0.815615   \n",
       "\n",
       "   PublicScore  PrivateScore                           OldPublicScore  \\\n",
       "0          NaN           NaN  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1          NaN           NaN   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2          NaN           NaN  [0.677419354, 0.711864406, 0.092764378]   \n",
       "3          NaN           NaN                            [0.678571428]   \n",
       "4          NaN           NaN                            [0.703703703]   \n",
       "5          NaN           NaN               [0.678571428, 0.642857142]   \n",
       "6          NaN           NaN               [0.549019607, 0.642857142]   \n",
       "\n",
       "                           OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.872101  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.839518  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.874948  \n",
       "3                            [0.666666666]        0.864222  \n",
       "4                            [0.654867256]        0.857900  \n",
       "5               [0.637168141, 0.620689655]        0.816359  \n",
       "6                [0.48076923, 0.620689655]        0.816359  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate data (drop FraudResult before)\n",
    "X_2 = data.drop(\"FraudResult\", axis=1)\n",
    "# mi_score = make_mi_scores(data, y_train)\n",
    "train_X, val_X, train_y, val_y = train_test_split(X_2, y_train, random_state = 0)\n",
    "result2 = comparemodels(train_X, train_y, val_X, X_test, \"Dropping Unique ID columns\", unbalanced=True)\n",
    "result2[\"PublicScore\"] = [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "result2[\"PrivateScore\"] = [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "result2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309e715a",
   "metadata": {},
   "source": [
    "## Scenario 3: Adding new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5a214b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_col = [\"ProviderId\", \"ProductCategory\", \"ChannelId\", \"PricingStrategy\"]\n",
    "mean_std_col = ['ProductId', 'Expense', \"ProviderId\", \"ProductCategory\", \"ChannelId\", \"PricingStrategy\"]\n",
    "\n",
    "# Compute mean and standard deviation for specific features\n",
    "for feature in mean_std_col:\n",
    "    # Compute the mean and standard deviation of transactions for each feature\n",
    "    feature_avg_values = data.groupby(feature)['Value'].mean()\n",
    "    feature_std_values = data.groupby(feature)['Value'].std()\n",
    "    data[f\"{feature}_mean_amount\"] = data[feature].apply(lambda x: feature_avg_values[x])\n",
    "    data[f\"{feature}_std_amount\"] = data[feature].apply(lambda x: feature_std_values[x])\n",
    "    \n",
    "for feature in mean_std_col:\n",
    "    # Compute the mean and standard deviation of transactions for each feature\n",
    "    feature_avg_values = X_test.groupby(feature)['Value'].mean()\n",
    "    feature_std_values = X_test.groupby(feature)['Value'].std()\n",
    "    X_test[f\"{feature}_mean_amount\"] = X_test[feature].apply(lambda x: feature_avg_values[x])\n",
    "    X_test[f\"{feature}_std_amount\"] = X_test[feature].apply(lambda x: feature_std_values[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "edbaa3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the rows that contain missing values\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "402f8b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHot Encode categorical features\n",
    "data = pd.get_dummies(data, columns=categorical_col)\n",
    "# Adding missing col\n",
    "data[\"ChannelId_4\"] = False\n",
    "data[\"PricingStrategy_3\"] = False\n",
    "X_test = pd.get_dummies(X_test, columns=categorical_col)\n",
    "# Adding missing col\n",
    "X_test[\"PricingStrategy_3\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5d42f1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the boolean columns to integer columns\n",
    "bool_cols = data.select_dtypes(include=bool).columns.tolist()\n",
    "data[bool_cols] = data[bool_cols].astype(int)\n",
    "\n",
    "bool_cols = X_test.select_dtypes(include=bool).columns.tolist()\n",
    "X_test[bool_cols] = X_test[bool_cols].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "661ded45",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = data.FraudResult\n",
    "data.drop(\"FraudResult\", inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c8fd8eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_score = make_mi_scores(data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1c37814f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(dpi=100, figsize=(10, 8))\n",
    "plot_mi_scores(mi_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9de337b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>AddingNewFeature Nikomax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 17:58:21.325377</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.848426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.849240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>AddingNewFeature Nikon_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 17:58:22.794096</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.784810</td>\n",
       "      <td>0.025621</td>\n",
       "      <td>0.786037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.786695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>AddingNewFeature Nikoscale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 17:58:26.266350</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.856892</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.857080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest ClassifierWeighted500</td>\n",
       "      <td>AddingNewFeature Nikon_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 17:58:27.993469</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.024113</td>\n",
       "      <td>0.796908</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>0.797746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest ClassifierWeighted22</td>\n",
       "      <td>AddingNewFeature Nikon_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 17:58:29.502326</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.784810</td>\n",
       "      <td>0.025621</td>\n",
       "      <td>0.786037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.703703703]</td>\n",
       "      <td>[0.654867256]</td>\n",
       "      <td>0.786695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>AddingNewFeature Nikoupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 17:58:33.735677</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.716049</td>\n",
       "      <td>0.034663</td>\n",
       "      <td>0.716061</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.716544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>AddingNewFeature Nikoundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 17:58:37.999466</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.716049</td>\n",
       "      <td>0.034663</td>\n",
       "      <td>0.716061</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.716544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Model  \\\n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  Random Forest ClassifierWeighted500   \n",
       "4   Random Forest ClassifierWeighted22   \n",
       "5  RandomForestClassifierUpperSampling   \n",
       "6  RandomForestClassifierUnderSampling   \n",
       "\n",
       "                                                               Description  \\\n",
       "0              AddingNewFeature Nikomax_leaf_nodes : 6 + with date columns   \n",
       "1                         AddingNewFeature Nikon_estimators : 36 + Entropy   \n",
       "2                               AddingNewFeature Nikoscale_pos_weight = 22   \n",
       "3                         AddingNewFeature Nikon_estimators : 36 + Entropy   \n",
       "4                         AddingNewFeature Nikon_estimators : 36 + Entropy   \n",
       "5     AddingNewFeature Nikoupsampled, n_estimators=36, criterion = entropy   \n",
       "6  AddingNewFeature Nikoundersampled, n_estimators=36, criterion = entropy   \n",
       "\n",
       "                        Date  Precision    Recall  F1-score   LogLoss  \\\n",
       "0 2023-05-07 17:58:21.325377   0.916667  0.785714  0.846154  0.018085   \n",
       "1 2023-05-07 17:58:22.794096   0.837838  0.738095  0.784810  0.025621   \n",
       "2 2023-05-07 17:58:26.266350   0.857143  0.857143  0.857143  0.018085   \n",
       "3 2023-05-07 17:58:27.993469   0.861111  0.738095  0.794872  0.024113   \n",
       "4 2023-05-07 17:58:29.502326   0.837838  0.738095  0.784810  0.025621   \n",
       "5 2023-05-07 17:58:33.735677   0.743590  0.690476  0.716049  0.034663   \n",
       "6 2023-05-07 17:58:37.999466   0.743590  0.690476  0.716049  0.034663   \n",
       "\n",
       "        Mcc  PublicScore  PrivateScore  \\\n",
       "0  0.848426          NaN           NaN   \n",
       "1  0.786037          NaN           NaN   \n",
       "2  0.856892          NaN           NaN   \n",
       "3  0.796908          NaN           NaN   \n",
       "4  0.786037          NaN           NaN   \n",
       "5  0.716061          NaN           NaN   \n",
       "6  0.716061          NaN           NaN   \n",
       "\n",
       "                            OldPublicScore  \\\n",
       "0  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2  [0.677419354, 0.711864406, 0.092764378]   \n",
       "3                            [0.678571428]   \n",
       "4                            [0.703703703]   \n",
       "5               [0.678571428, 0.642857142]   \n",
       "6               [0.549019607, 0.642857142]   \n",
       "\n",
       "                           OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.849240  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.786695  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.857080  \n",
       "3                            [0.666666666]        0.797746  \n",
       "4                            [0.654867256]        0.786695  \n",
       "5               [0.637168141, 0.620689655]        0.716544  \n",
       "6                [0.48076923, 0.620689655]        0.716544  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reorder the columns in alphabetical order\n",
    "data = data.sort_index(axis=1)\n",
    "X_test = X_test.sort_index(axis=1)\n",
    "\n",
    "# Evaluate data\n",
    "X_3 = data.copy()\n",
    "X_test_3 = X_test.copy()\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(X_3, y_train, random_state = 0)\n",
    "result3 = comparemodels(train_X, train_y, val_X, X_test_3, \"AddingNewFeature Niko\")\n",
    "result3[\"PublicScore\"] = [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "result3[\"PrivateScore\"] = [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "result3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade3d808",
   "metadata": {},
   "source": [
    "## Scenario 4 : Removing Low MI columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e22cbe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_scores = make_mi_scores(X_3 , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5d2fe0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mediumMI = list(mi_scores[mi_scores<0.01].index)\n",
    "X_3.drop(mediumMI, inplace=True, axis=1, errors='ignore')\n",
    "X_test_3.drop(mediumMI, inplace=True, axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d996dc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Adding Niko Features + Removing low medium MImax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 17:59:09.104887</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>0.859335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.861068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Adding Niko Features + Removing low medium MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 17:59:10.092958</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.845369</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.847513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Adding Niko Features + Removing low medium MIscale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 17:59:12.849053</td>\n",
       "      <td>0.457831</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.608000</td>\n",
       "      <td>0.073848</td>\n",
       "      <td>0.642817</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.653353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest ClassifierWeighted500</td>\n",
       "      <td>Adding Niko Features + Removing low medium MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 17:59:14.004969</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.845369</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>0.847513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest ClassifierWeighted22</td>\n",
       "      <td>Adding Niko Features + Removing low medium MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 17:59:14.878662</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.845369</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.703703703]</td>\n",
       "      <td>[0.654867256]</td>\n",
       "      <td>0.847513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>Adding Niko Features + Removing low medium MIupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 17:59:17.111020</td>\n",
       "      <td>0.203125</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.235107</td>\n",
       "      <td>0.432663</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.474423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>Adding Niko Features + Removing low medium MIundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 17:59:19.329176</td>\n",
       "      <td>0.203125</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.235107</td>\n",
       "      <td>0.432663</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.474423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Model  \\\n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  Random Forest ClassifierWeighted500   \n",
       "4   Random Forest ClassifierWeighted22   \n",
       "5  RandomForestClassifierUpperSampling   \n",
       "6  RandomForestClassifierUnderSampling   \n",
       "\n",
       "                                                                                       Description  \\\n",
       "0              Adding Niko Features + Removing low medium MImax_leaf_nodes : 6 + with date columns   \n",
       "1                         Adding Niko Features + Removing low medium MIn_estimators : 36 + Entropy   \n",
       "2                               Adding Niko Features + Removing low medium MIscale_pos_weight = 22   \n",
       "3                         Adding Niko Features + Removing low medium MIn_estimators : 36 + Entropy   \n",
       "4                         Adding Niko Features + Removing low medium MIn_estimators : 36 + Entropy   \n",
       "5     Adding Niko Features + Removing low medium MIupsampled, n_estimators=36, criterion = entropy   \n",
       "6  Adding Niko Features + Removing low medium MIundersampled, n_estimators=36, criterion = entropy   \n",
       "\n",
       "                        Date  Precision    Recall  F1-score   LogLoss  \\\n",
       "0 2023-05-07 17:59:09.104887   0.969697  0.761905  0.853333  0.016578   \n",
       "1 2023-05-07 17:59:10.092958   0.968750  0.738095  0.837838  0.018085   \n",
       "2 2023-05-07 17:59:12.849053   0.457831  0.904762  0.608000  0.073848   \n",
       "3 2023-05-07 17:59:14.004969   0.968750  0.738095  0.837838  0.018085   \n",
       "4 2023-05-07 17:59:14.878662   0.968750  0.738095  0.837838  0.018085   \n",
       "5 2023-05-07 17:59:17.111020   0.203125  0.928571  0.333333  0.235107   \n",
       "6 2023-05-07 17:59:19.329176   0.203125  0.928571  0.333333  0.235107   \n",
       "\n",
       "        Mcc  PublicScore  PrivateScore  \\\n",
       "0  0.859335          NaN           NaN   \n",
       "1  0.845369          NaN           NaN   \n",
       "2  0.642817          NaN           NaN   \n",
       "3  0.845369          NaN           NaN   \n",
       "4  0.845369          NaN           NaN   \n",
       "5  0.432663          NaN           NaN   \n",
       "6  0.432663          NaN           NaN   \n",
       "\n",
       "                            OldPublicScore  \\\n",
       "0  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2  [0.677419354, 0.711864406, 0.092764378]   \n",
       "3                            [0.678571428]   \n",
       "4                            [0.703703703]   \n",
       "5               [0.678571428, 0.642857142]   \n",
       "6               [0.549019607, 0.642857142]   \n",
       "\n",
       "                           OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.861068  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.847513  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.653353  \n",
       "3                            [0.666666666]        0.847513  \n",
       "4                            [0.654867256]        0.847513  \n",
       "5               [0.637168141, 0.620689655]        0.474423  \n",
       "6                [0.48076923, 0.620689655]        0.474423  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X, val_X, train_y, val_y = train_test_split(X_3, y_train, random_state = 0)\n",
    "result4 = comparemodels(train_X, train_y, val_X, X_test_3, \"Adding Niko Features + Removing low medium MI\")\n",
    "result4[\"PublicScore\"] = [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "result4[\"PrivateScore\"] = [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "result4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d7d110a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_4 = data.copy()\n",
    "X_test_4 = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7d64cade",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowMI = list(mi_scores[mi_scores<0.001].index)\n",
    "X_4.drop(lowMI, inplace=True, axis=1)\n",
    "X_test_4.drop(lowMI, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bf97fb8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Delete only low + Niko Datasmax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 17:59:21.581532</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>0.860489</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.861551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Delete only low + Niko Datasn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 17:59:22.863245</td>\n",
       "      <td>0.868421</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.021099</td>\n",
       "      <td>0.825744</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.826220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Delete only low + Niko Datasscale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 17:59:25.475257</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.867470</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>0.867303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.867491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest ClassifierWeighted500</td>\n",
       "      <td>Delete only low + Niko Datasn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 17:59:26.983833</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.024113</td>\n",
       "      <td>0.800671</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>0.801170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest ClassifierWeighted22</td>\n",
       "      <td>Delete only low + Niko Datasn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 17:59:28.807381</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.021099</td>\n",
       "      <td>0.822667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.703703703]</td>\n",
       "      <td>[0.654867256]</td>\n",
       "      <td>0.823493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>Delete only low + Niko Datasupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 17:59:32.539051</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.030142</td>\n",
       "      <td>0.761486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.761800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>Delete only low + Niko Datasundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 17:59:36.196091</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.030142</td>\n",
       "      <td>0.761486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.761800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Model  \\\n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  Random Forest ClassifierWeighted500   \n",
       "4   Random Forest ClassifierWeighted22   \n",
       "5  RandomForestClassifierUpperSampling   \n",
       "6  RandomForestClassifierUnderSampling   \n",
       "\n",
       "                                                                      Description  \\\n",
       "0              Delete only low + Niko Datasmax_leaf_nodes : 6 + with date columns   \n",
       "1                         Delete only low + Niko Datasn_estimators : 36 + Entropy   \n",
       "2                               Delete only low + Niko Datasscale_pos_weight = 22   \n",
       "3                         Delete only low + Niko Datasn_estimators : 36 + Entropy   \n",
       "4                         Delete only low + Niko Datasn_estimators : 36 + Entropy   \n",
       "5     Delete only low + Niko Datasupsampled, n_estimators=36, criterion = entropy   \n",
       "6  Delete only low + Niko Datasundersampled, n_estimators=36, criterion = entropy   \n",
       "\n",
       "                        Date  Precision    Recall  F1-score   LogLoss  \\\n",
       "0 2023-05-07 17:59:21.581532   0.942857  0.785714  0.857143  0.016578   \n",
       "1 2023-05-07 17:59:22.863245   0.868421  0.785714  0.825000  0.021099   \n",
       "2 2023-05-07 17:59:25.475257   0.878049  0.857143  0.867470  0.016578   \n",
       "3 2023-05-07 17:59:26.983833   0.842105  0.761905  0.800000  0.024113   \n",
       "4 2023-05-07 17:59:28.807381   0.888889  0.761905  0.820513  0.021099   \n",
       "5 2023-05-07 17:59:32.539051   0.761905  0.761905  0.761905  0.030142   \n",
       "6 2023-05-07 17:59:36.196091   0.761905  0.761905  0.761905  0.030142   \n",
       "\n",
       "        Mcc  PublicScore  PrivateScore  \\\n",
       "0  0.860489          NaN           NaN   \n",
       "1  0.825744          NaN           NaN   \n",
       "2  0.867303          NaN           NaN   \n",
       "3  0.800671          NaN           NaN   \n",
       "4  0.822667          NaN           NaN   \n",
       "5  0.761486          NaN           NaN   \n",
       "6  0.761486          NaN           NaN   \n",
       "\n",
       "                            OldPublicScore  \\\n",
       "0  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2  [0.677419354, 0.711864406, 0.092764378]   \n",
       "3                            [0.678571428]   \n",
       "4                            [0.703703703]   \n",
       "5               [0.678571428, 0.642857142]   \n",
       "6               [0.549019607, 0.642857142]   \n",
       "\n",
       "                           OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.861551  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.826220  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.867491  \n",
       "3                            [0.666666666]        0.801170  \n",
       "4                            [0.654867256]        0.823493  \n",
       "5               [0.637168141, 0.620689655]        0.761800  \n",
       "6                [0.48076923, 0.620689655]        0.761800  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X, val_X, train_y, val_y = train_test_split(X_4, y_train, random_state = 0)\n",
    "result5 = comparemodels(train_X, train_y, val_X, X_test_4, \"Delete only low + Niko Datas\")\n",
    "result5[\"PublicScore\"] = [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "result5[\"PrivateScore\"] = [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "result5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062264cc",
   "metadata": {},
   "source": [
    "## Scenario 5 : The optimal dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9d43a667",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_5 = data.copy()\n",
    "X_test_5 = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bb133429",
   "metadata": {},
   "outputs": [],
   "source": [
    "veryLowMI = list(mi_scores[mi_scores<0.0001].index)\n",
    "X_5.drop(veryLowMI, inplace=True, axis=1)\n",
    "X_test_5.drop(veryLowMI, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5871d9b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Delete only very low + Niko Datasmax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 17:59:38.762849</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.848426</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.849240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Delete only very low + Niko Datasn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 17:59:40.109606</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.027128</td>\n",
       "      <td>0.780344</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.780684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Delete only very low + Niko Datasscale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 17:59:42.660223</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.880743</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.682540</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.880900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest ClassifierWeighted500</td>\n",
       "      <td>Delete only very low + Niko Datasn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 17:59:44.264327</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.795181</td>\n",
       "      <td>0.025621</td>\n",
       "      <td>0.794883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>0.795164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest ClassifierWeighted22</td>\n",
       "      <td>Delete only very low + Niko Datasn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 17:59:45.730578</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>0.024113</td>\n",
       "      <td>0.804783</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.700855</td>\n",
       "      <td>[0.703703703]</td>\n",
       "      <td>[0.654867256]</td>\n",
       "      <td>0.805094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>Delete only very low + Niko Datasupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 17:59:49.774612</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.707317</td>\n",
       "      <td>0.036170</td>\n",
       "      <td>0.707026</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.642202</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.707455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>Delete only very low + Niko Datasundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 17:59:53.402777</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.707317</td>\n",
       "      <td>0.036170</td>\n",
       "      <td>0.707026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.707455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Model  \\\n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  Random Forest ClassifierWeighted500   \n",
       "4   Random Forest ClassifierWeighted22   \n",
       "5  RandomForestClassifierUpperSampling   \n",
       "6  RandomForestClassifierUnderSampling   \n",
       "\n",
       "                                                                           Description  \\\n",
       "0              Delete only very low + Niko Datasmax_leaf_nodes : 6 + with date columns   \n",
       "1                         Delete only very low + Niko Datasn_estimators : 36 + Entropy   \n",
       "2                               Delete only very low + Niko Datasscale_pos_weight = 22   \n",
       "3                         Delete only very low + Niko Datasn_estimators : 36 + Entropy   \n",
       "4                         Delete only very low + Niko Datasn_estimators : 36 + Entropy   \n",
       "5     Delete only very low + Niko Datasupsampled, n_estimators=36, criterion = entropy   \n",
       "6  Delete only very low + Niko Datasundersampled, n_estimators=36, criterion = entropy   \n",
       "\n",
       "                        Date  Precision    Recall  F1-score   LogLoss  \\\n",
       "0 2023-05-07 17:59:38.762849   0.916667  0.785714  0.846154  0.018085   \n",
       "1 2023-05-07 17:59:40.109606   0.800000  0.761905  0.780488  0.027128   \n",
       "2 2023-05-07 17:59:42.660223   0.880952  0.880952  0.880952  0.015071   \n",
       "3 2023-05-07 17:59:44.264327   0.804878  0.785714  0.795181  0.025621   \n",
       "4 2023-05-07 17:59:45.730578   0.825000  0.785714  0.804878  0.024113   \n",
       "5 2023-05-07 17:59:49.774612   0.725000  0.690476  0.707317  0.036170   \n",
       "6 2023-05-07 17:59:53.402777   0.725000  0.690476  0.707317  0.036170   \n",
       "\n",
       "        Mcc  PublicScore  PrivateScore  \\\n",
       "0  0.848426     0.642857      0.596491   \n",
       "1  0.780344     0.577778      0.577778   \n",
       "2  0.880743     0.666667      0.682540   \n",
       "3  0.794883          NaN           NaN   \n",
       "4  0.804783     0.689655      0.700855   \n",
       "5  0.707026     0.653846      0.642202   \n",
       "6  0.707026          NaN           NaN   \n",
       "\n",
       "                            OldPublicScore  \\\n",
       "0  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2  [0.677419354, 0.711864406, 0.092764378]   \n",
       "3                            [0.678571428]   \n",
       "4                            [0.703703703]   \n",
       "5               [0.678571428, 0.642857142]   \n",
       "6               [0.549019607, 0.642857142]   \n",
       "\n",
       "                           OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.849240  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.780684  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.880900  \n",
       "3                            [0.666666666]        0.795164  \n",
       "4                            [0.654867256]        0.805094  \n",
       "5               [0.637168141, 0.620689655]        0.707455  \n",
       "6                [0.48076923, 0.620689655]        0.707455  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X, val_X, train_y, val_y = train_test_split(X_5, y_train, random_state = 0)\n",
    "result6 = comparemodels(train_X, train_y, val_X, X_test_5, \"Delete only very low + Niko Datas\", unbalanced=True)\n",
    "result6[\"PublicScore\"] = [0.642857142, 0.577777777, 0.666666666, np.nan, 0.689655172, 0.653846153, np.nan]\n",
    "result6[\"PrivateScore\"] = [0.596491228, 0.577777777, 0.682539682, np.nan, 0.700854700, 0.642201834, np.nan]\n",
    "result6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eab429b",
   "metadata": {},
   "source": [
    "# 2. Test de different model with the basic features\n",
    "## 2.1. The reference model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "73a9d70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>The referencemax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 17:56:40.979441</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>0.857566</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.661017</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.857900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>The referencen_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 17:56:42.813669</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.843373</td>\n",
       "      <td>0.019592</td>\n",
       "      <td>0.843655</td>\n",
       "      <td>0.690909</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.843995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>The referencescale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 17:56:45.360445</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>0.871874</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.676923</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.872421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest ClassifierWeighted500</td>\n",
       "      <td>The referencen_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 17:56:47.342506</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.862324</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>0.863034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest ClassifierWeighted22</td>\n",
       "      <td>The referencen_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 17:56:49.369181</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.862324</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.654867</td>\n",
       "      <td>[0.703703703]</td>\n",
       "      <td>[0.654867256]</td>\n",
       "      <td>0.863034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>The referenceupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 17:56:53.301001</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.022606</td>\n",
       "      <td>0.824649</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.637168</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.825239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>The referenceundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 17:56:57.065217</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.022606</td>\n",
       "      <td>0.824649</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.825239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Model  \\\n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  Random Forest ClassifierWeighted500   \n",
       "4   Random Forest ClassifierWeighted22   \n",
       "5  RandomForestClassifierUpperSampling   \n",
       "6  RandomForestClassifierUnderSampling   \n",
       "\n",
       "                                                       Description  \\\n",
       "0              The referencemax_leaf_nodes : 6 + with date columns   \n",
       "1                         The referencen_estimators : 36 + Entropy   \n",
       "2                               The referencescale_pos_weight = 22   \n",
       "3                         The referencen_estimators : 36 + Entropy   \n",
       "4                         The referencen_estimators : 36 + Entropy   \n",
       "5     The referenceupsampled, n_estimators=36, criterion = entropy   \n",
       "6  The referenceundersampled, n_estimators=36, criterion = entropy   \n",
       "\n",
       "                        Date  Precision  Recall  F1-score   LogLoss       Mcc  \\\n",
       "0 2023-05-07 17:56:40.979441   0.891892   0.825  0.857143  0.016578  0.857566   \n",
       "1 2023-05-07 17:56:42.813669   0.813953   0.875  0.843373  0.019592  0.843655   \n",
       "2 2023-05-07 17:56:45.360445   0.822222   0.925  0.870588  0.016578  0.871874   \n",
       "3 2023-05-07 17:56:47.342506   0.804348   0.925  0.860465  0.018085  0.862324   \n",
       "4 2023-05-07 17:56:49.369181   0.804348   0.925  0.860465  0.018085  0.862324   \n",
       "5 2023-05-07 17:56:53.301001   0.777778   0.875  0.823529  0.022606  0.824649   \n",
       "6 2023-05-07 17:56:57.065217   0.777778   0.875  0.823529  0.022606  0.824649   \n",
       "\n",
       "   PublicScore  PrivateScore                           OldPublicScore  \\\n",
       "0     0.666667      0.661017  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1     0.690909      0.649123   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2     0.677419      0.676923  [0.677419354, 0.711864406, 0.092764378]   \n",
       "3     0.678571      0.666667                            [0.678571428]   \n",
       "4     0.703704      0.654867                            [0.703703703]   \n",
       "5     0.678571      0.637168               [0.678571428, 0.642857142]   \n",
       "6     0.549020      0.480769               [0.549019607, 0.642857142]   \n",
       "\n",
       "                           OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.857900  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.843995  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.872421  \n",
       "3                            [0.666666666]        0.863034  \n",
       "4                            [0.654867256]        0.863034  \n",
       "5               [0.637168141, 0.620689655]        0.825239  \n",
       "6                [0.48076923, 0.620689655]        0.825239  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def_feature = pd.read_csv(\"input/Xente_Variable_Definitions.csv\")\n",
    "raw_data = pd.read_csv(\"input/training.csv\")\n",
    "X_test = pd.read_csv(\"input/test.csv\")\n",
    "sample_submission = pd.read_csv(\"input/sample_submission.csv\")\n",
    "\n",
    "#attribut initialization\n",
    "cols_unique_value = [] #Will be droped\n",
    "for col in raw_data.columns : \n",
    "    if len(raw_data[col].unique()) == 1 :\n",
    "        cols_unique_value.append(col)\n",
    "\n",
    "medium_cardianlity_cols = [\"ProductId\"]\n",
    "\n",
    "#Data transformation\n",
    "raw_data['TransactionStartTime'] = pd.to_datetime(raw_data['TransactionStartTime'])\n",
    "X_test['TransactionStartTime'] = pd.to_datetime(X_test['TransactionStartTime'])\n",
    "\n",
    "#Data cleaning\n",
    "data = raw_data.copy()\n",
    "data = data.dropna(axis=0) #Drop observations/rows with missing values\n",
    "X_test=X_test.dropna(axis=0)\n",
    "data.drop(cols_unique_value, axis=1, inplace=True)\n",
    "X_test.drop(cols_unique_value, axis=1, inplace=True)\n",
    "\n",
    "#Prepare index for the submission\n",
    "index_val = list(X_test.TransactionId.values.tolist())\n",
    "\n",
    "#Set the df index to the Transction Id\n",
    "data = transactioId_to_index(data)\n",
    "X_test = transactioId_to_index(X_test)\n",
    "\n",
    "#Adding data\n",
    "data = adding_date_col(data, 'TransactionStartTime')\n",
    "X_test = adding_date_col(X_test, 'TransactionStartTime')\n",
    "\n",
    "\n",
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "low_cardinality_cols = [cname for cname in data.columns if data[cname].nunique() < 15 and \n",
    "                        data[cname].dtype == \"object\"]\n",
    "low_cardinality_cols.append('PricingStrategy')\n",
    "\n",
    "#transform columns BatchId_54 to number\n",
    "    #transform columns BatchId_54 to number\n",
    "id_cols = data.filter(like=\"Id\").columns.tolist()\n",
    "data[id_cols] = data[id_cols].astype(str).apply(lambda x: x.str.replace(x.name + \"_\", \"\")).astype(int)\n",
    "X_test[id_cols] = X_test[id_cols].astype(str).apply(lambda x: x.str.replace(x.name + \"_\", \"\")).astype(int)\n",
    "\n",
    "data['PricingStrategy'] = data['PricingStrategy'].astype('int')\n",
    "X_test['PricingStrategy'] = X_test['PricingStrategy'].astype('int')\n",
    "data['Value'] = data['Value'].astype('float')\n",
    "X_test['Value'] = X_test['Value'].astype('float')\n",
    "\n",
    "X_test['PricingStrategy'] = X_test['PricingStrategy'].astype('str')\n",
    "data['PricingStrategy'] = data['PricingStrategy'].astype('str')\n",
    "\n",
    "#Data splitting\n",
    "y = data.FraudResult #The target label\n",
    "X = data.copy()\n",
    "X.drop(['FraudResult'], axis=1, inplace=True) #Only the features data\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "cat_cols = [col for col in X.columns if X[col].dtype == \"object\"]#liste of obejct columns\n",
    "cat_cols.append(\"PricingStrategy\")#pcq mm si c'est un chiffre il faut le considrer comme une catgorie\n",
    "\n",
    "\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(train_X[low_cardinality_cols]))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(val_X[low_cardinality_cols]))\n",
    "OH_cols_test = pd.DataFrame(OH_encoder.transform(X_test[low_cardinality_cols]))\n",
    "OH_cols_train.columns = OH_encoder.get_feature_names_out()\n",
    "OH_cols_valid.columns = OH_encoder.get_feature_names_out()\n",
    "OH_cols_test.columns = OH_encoder.get_feature_names_out()\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_train.index = train_X.index\n",
    "OH_cols_valid.index = val_X.index\n",
    "OH_cols_test.index = X_test.index\n",
    "\n",
    "OH_cols_train[list(OH_cols_train.columns)] = OH_cols_train[list(OH_cols_train.columns)].astype(int)\n",
    "OH_cols_valid[list(OH_cols_valid.columns)] = OH_cols_valid[list(OH_cols_valid.columns)].astype(int)\n",
    "OH_cols_test[list(OH_cols_test.columns)] = OH_cols_test[list(OH_cols_test.columns)].astype(int)\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train = train_X.drop(low_cardinality_cols, axis=1)\n",
    "num_X_valid = val_X.drop(low_cardinality_cols, axis=1)\n",
    "num_X_test = X_test.drop(low_cardinality_cols, axis=1)\n",
    "\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
    "OH_X_test = pd.concat([num_X_test, OH_cols_test], axis=1)\n",
    "\n",
    "# Problme de string\n",
    "OH_X_train.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_valid.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_test.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_train.columns = OH_X_train.columns.astype(str)\n",
    "OH_X_valid.columns = OH_X_valid.columns.astype(str)\n",
    "OH_X_test.columns = OH_X_test.columns.astype(str)\n",
    "\n",
    "train_X = OH_X_train\n",
    "val_X = OH_X_valid\n",
    "test_X = OH_X_test\n",
    "X_entier = pd.concat([train_X, val_X])\n",
    "\n",
    "referenceresult = comparemodels(train_X, train_y, val_X, test_X, \"The reference\")\n",
    "referenceresult[\"PublicScore\"] = [0.666666666, 0.690909090, 0.677419354, 0.678571428, 0.703703703, 0.678571428, 0.549019607]\n",
    "referenceresult[\"PrivateScore\"] = [0.661016949, 0.649122807,  0.676923076,0.666666666, 0.654867256, 0.637168141, 0.480769230]\n",
    "referenceresult"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418bccbc",
   "metadata": {},
   "source": [
    "## 2.2. Play with deleting the low MI columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "46c1db32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supprimer les MI trop faible\n",
    "def_feature = pd.read_csv(\"input/Xente_Variable_Definitions.csv\")\n",
    "raw_data = pd.read_csv(\"input/training.csv\")\n",
    "X_test = pd.read_csv(\"input/test.csv\")\n",
    "sample_submission = pd.read_csv(\"input/sample_submission.csv\")\n",
    "\n",
    "#attribut initialization\n",
    "cols_unique_value = [] #Will be droped\n",
    "for col in raw_data.columns : \n",
    "    if len(raw_data[col].unique()) == 1 :\n",
    "        cols_unique_value.append(col)\n",
    "\n",
    "medium_cardianlity_cols = [\"ProductId\"]\n",
    "\n",
    "#Data transformation\n",
    "raw_data['TransactionStartTime'] = pd.to_datetime(raw_data['TransactionStartTime'])\n",
    "X_test['TransactionStartTime'] = pd.to_datetime(X_test['TransactionStartTime'])\n",
    "\n",
    "#Data cleaning\n",
    "data = raw_data.copy()\n",
    "data = data.dropna(axis=0) #Drop observations/rows with missing values\n",
    "X_test=X_test.dropna(axis=0)\n",
    "data.drop(cols_unique_value, axis=1, inplace=True)\n",
    "X_test.drop(cols_unique_value, axis=1, inplace=True)\n",
    "\n",
    "#Prepare index for the submission\n",
    "index_val = list(X_test.TransactionId.values.tolist())\n",
    "\n",
    "#Set the df index to the Transction Id\n",
    "data = transactioId_to_index(data)\n",
    "X_test = transactioId_to_index(X_test)\n",
    "\n",
    "#Adding data\n",
    "data = adding_date_col(data, 'TransactionStartTime')\n",
    "X_test = adding_date_col(X_test, 'TransactionStartTime')\n",
    "\n",
    "\n",
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "low_cardinality_cols = [cname for cname in data.columns if data[cname].nunique() < 15 and \n",
    "                        data[cname].dtype == \"object\"]\n",
    "low_cardinality_cols.append('PricingStrategy')\n",
    "\n",
    "#transform columns BatchId_54 to number\n",
    "    #transform columns BatchId_54 to number\n",
    "id_cols = data.filter(like=\"Id\").columns.tolist()\n",
    "data[id_cols] = data[id_cols].astype(str).apply(lambda x: x.str.replace(x.name + \"_\", \"\")).astype(int)\n",
    "X_test[id_cols] = X_test[id_cols].astype(str).apply(lambda x: x.str.replace(x.name + \"_\", \"\")).astype(int)\n",
    "\n",
    "data['PricingStrategy'] = data['PricingStrategy'].astype('int')\n",
    "X_test['PricingStrategy'] = X_test['PricingStrategy'].astype('int')\n",
    "data['Value'] = data['Value'].astype('float')\n",
    "X_test['Value'] = X_test['Value'].astype('float')\n",
    "\n",
    "X_test['PricingStrategy'] = X_test['PricingStrategy'].astype('str')\n",
    "data['PricingStrategy'] = data['PricingStrategy'].astype('str')\n",
    "\n",
    "#Data splitting\n",
    "y = data.FraudResult #The target label\n",
    "X = data.copy()\n",
    "X.drop(['FraudResult'], axis=1, inplace=True) #Only the features data\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "cat_cols = [col for col in X.columns if X[col].dtype == \"object\"]#liste of obejct columns\n",
    "cat_cols.append(\"PricingStrategy\")#pcq mm si c'est un chiffre il faut le considrer comme une catgorie\n",
    "\n",
    "\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(train_X[low_cardinality_cols]))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(val_X[low_cardinality_cols]))\n",
    "OH_cols_test = pd.DataFrame(OH_encoder.transform(X_test[low_cardinality_cols]))\n",
    "OH_cols_train.columns = OH_encoder.get_feature_names_out()\n",
    "OH_cols_valid.columns = OH_encoder.get_feature_names_out()\n",
    "OH_cols_test.columns = OH_encoder.get_feature_names_out()\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_train.index = train_X.index\n",
    "OH_cols_valid.index = val_X.index\n",
    "OH_cols_test.index = X_test.index\n",
    "\n",
    "OH_cols_train[list(OH_cols_train.columns)] = OH_cols_train[list(OH_cols_train.columns)].astype(int)\n",
    "OH_cols_valid[list(OH_cols_valid.columns)] = OH_cols_valid[list(OH_cols_valid.columns)].astype(int)\n",
    "OH_cols_test[list(OH_cols_test.columns)] = OH_cols_test[list(OH_cols_test.columns)].astype(int)\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train = train_X.drop(low_cardinality_cols, axis=1)\n",
    "num_X_valid = val_X.drop(low_cardinality_cols, axis=1)\n",
    "num_X_test = X_test.drop(low_cardinality_cols, axis=1)\n",
    "\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
    "OH_X_test = pd.concat([num_X_test, OH_cols_test], axis=1)\n",
    "\n",
    "# Problme de string\n",
    "OH_X_train.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_valid.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_test.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_train.columns = OH_X_train.columns.astype(str)\n",
    "OH_X_valid.columns = OH_X_valid.columns.astype(str)\n",
    "OH_X_test.columns = OH_X_test.columns.astype(str)\n",
    "\n",
    "train_X = OH_X_train\n",
    "val_X = OH_X_valid\n",
    "test_X = OH_X_test\n",
    "X_entier = pd.concat([train_X, val_X])\n",
    "\n",
    "mi_scores = make_mi_scores(X_entier , y)\n",
    "\n",
    "verylowMI = list(mi_scores[mi_scores<0.0001].index)\n",
    "lowMI = list(mi_scores[(mi_scores>=0.0001)&(mi_scores<0.001)].index)\n",
    "mediumMI = list(mi_scores[(mi_scores>=0.001)&(mi_scores<0.01)].index)\n",
    "highMI = list(mi_scores[mi_scores>=0.01].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da4602e",
   "metadata": {},
   "source": [
    "### 2.2.1 Delecte the very low MI columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "df174abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Delete very low MImax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 18:00:23.002639</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.057270</td>\n",
       "      <td>0.257799</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.661017</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.299595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Delete very low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 18:00:25.465609</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.048227</td>\n",
       "      <td>0.515792</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.520615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Delete very low MIscale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 18:00:29.500942</td>\n",
       "      <td>0.465116</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.481928</td>\n",
       "      <td>0.064805</td>\n",
       "      <td>0.481344</td>\n",
       "      <td>0.711864</td>\n",
       "      <td>0.715447</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.482097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest ClassifierWeighted500</td>\n",
       "      <td>Delete very low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 18:00:32.293789</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.051241</td>\n",
       "      <td>0.483474</td>\n",
       "      <td>0.654545</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>0.488056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest ClassifierWeighted22</td>\n",
       "      <td>Delete very low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 18:00:34.910663</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.045213</td>\n",
       "      <td>0.567141</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.647619</td>\n",
       "      <td>[0.703703703]</td>\n",
       "      <td>[0.654867256]</td>\n",
       "      <td>0.569884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>Delete very low MIupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 18:00:41.141346</td>\n",
       "      <td>0.459459</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.441558</td>\n",
       "      <td>0.064805</td>\n",
       "      <td>0.440995</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.441753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>Delete very low MIundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 18:00:46.876165</td>\n",
       "      <td>0.459459</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.441558</td>\n",
       "      <td>0.064805</td>\n",
       "      <td>0.440995</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.441753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Model  \\\n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  Random Forest ClassifierWeighted500   \n",
       "4   Random Forest ClassifierWeighted22   \n",
       "5  RandomForestClassifierUpperSampling   \n",
       "6  RandomForestClassifierUnderSampling   \n",
       "\n",
       "                                                            Description  \\\n",
       "0              Delete very low MImax_leaf_nodes : 6 + with date columns   \n",
       "1                         Delete very low MIn_estimators : 36 + Entropy   \n",
       "2                               Delete very low MIscale_pos_weight = 22   \n",
       "3                         Delete very low MIn_estimators : 36 + Entropy   \n",
       "4                         Delete very low MIn_estimators : 36 + Entropy   \n",
       "5     Delete very low MIupsampled, n_estimators=36, criterion = entropy   \n",
       "6  Delete very low MIundersampled, n_estimators=36, criterion = entropy   \n",
       "\n",
       "                        Date  Precision  Recall  F1-score   LogLoss       Mcc  \\\n",
       "0 2023-05-07 18:00:23.002639   0.666667   0.100  0.173913  0.057270  0.257799   \n",
       "1 2023-05-07 18:00:25.465609   0.666667   0.400  0.500000  0.048227  0.515792   \n",
       "2 2023-05-07 18:00:29.500942   0.465116   0.500  0.481928  0.064805  0.481344   \n",
       "3 2023-05-07 18:00:32.293789   0.625000   0.375  0.468750  0.051241  0.483474   \n",
       "4 2023-05-07 18:00:34.910663   0.678571   0.475  0.558824  0.045213  0.567141   \n",
       "5 2023-05-07 18:00:41.141346   0.459459   0.425  0.441558  0.064805  0.440995   \n",
       "6 2023-05-07 18:00:46.876165   0.459459   0.425  0.441558  0.064805  0.440995   \n",
       "\n",
       "   PublicScore  PrivateScore                           OldPublicScore  \\\n",
       "0     0.666667      0.661017  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1     0.666667      0.649123   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2     0.711864      0.715447  [0.677419354, 0.711864406, 0.092764378]   \n",
       "3     0.654545      0.666667                            [0.678571428]   \n",
       "4     0.595745      0.647619                            [0.703703703]   \n",
       "5     0.642857      0.620690               [0.678571428, 0.642857142]   \n",
       "6     0.642857      0.620690               [0.549019607, 0.642857142]   \n",
       "\n",
       "                           OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.299595  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.520615  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.482097  \n",
       "3                            [0.666666666]        0.488056  \n",
       "4                            [0.654867256]        0.569884  \n",
       "5               [0.637168141, 0.620689655]        0.441753  \n",
       "6                [0.48076923, 0.620689655]        0.441753  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "val_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "test_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "X_entier.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "\n",
    "withoutverylowMI = comparemodels(train_X, train_y, val_X, test_X, \"Delete very low MI\")\n",
    "withoutverylowMI[\"PublicScore\"] = [0.666666666, 0.666666666, 0.711864406, 0.654545454, 0.595744680, 0.642857142, 0.642857142]\n",
    "withoutverylowMI[\"PrivateScore\"] = [0.661016949, 0.649122807, 0.715447154, 0.666666666, 0.647619047, 0.620689655, 0.620689655]\n",
    "withoutverylowMI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073967ea",
   "metadata": {},
   "source": [
    "### 2.2.2 Delete low MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0235a795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Delete low MImax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 18:00:47.881547</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.157730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.199660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Delete low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 18:00:49.647358</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.051241</td>\n",
       "      <td>0.495474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.498927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Delete low MIscale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 18:00:51.693401</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.495413</td>\n",
       "      <td>0.082890</td>\n",
       "      <td>0.512908</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.518656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest ClassifierWeighted500</td>\n",
       "      <td>Delete low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 18:00:53.330085</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.507463</td>\n",
       "      <td>0.049734</td>\n",
       "      <td>0.516643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>0.519684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest ClassifierWeighted22</td>\n",
       "      <td>Delete low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 18:00:54.755584</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.048227</td>\n",
       "      <td>0.526526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.703703703]</td>\n",
       "      <td>[0.654867256]</td>\n",
       "      <td>0.530131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>Delete low MIupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 18:00:58.676986</td>\n",
       "      <td>0.358209</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.448598</td>\n",
       "      <td>0.088919</td>\n",
       "      <td>0.462470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.467319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>Delete low MIundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 18:01:02.620683</td>\n",
       "      <td>0.358209</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.448598</td>\n",
       "      <td>0.088919</td>\n",
       "      <td>0.462470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.467319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Model  \\\n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  Random Forest ClassifierWeighted500   \n",
       "4   Random Forest ClassifierWeighted22   \n",
       "5  RandomForestClassifierUpperSampling   \n",
       "6  RandomForestClassifierUnderSampling   \n",
       "\n",
       "                                                       Description  \\\n",
       "0              Delete low MImax_leaf_nodes : 6 + with date columns   \n",
       "1                         Delete low MIn_estimators : 36 + Entropy   \n",
       "2                               Delete low MIscale_pos_weight = 22   \n",
       "3                         Delete low MIn_estimators : 36 + Entropy   \n",
       "4                         Delete low MIn_estimators : 36 + Entropy   \n",
       "5     Delete low MIupsampled, n_estimators=36, criterion = entropy   \n",
       "6  Delete low MIundersampled, n_estimators=36, criterion = entropy   \n",
       "\n",
       "                        Date  Precision  Recall  F1-score   LogLoss       Mcc  \\\n",
       "0 2023-05-07 18:00:47.881547   0.500000   0.050  0.090909  0.060284  0.157730   \n",
       "1 2023-05-07 18:00:49.647358   0.615385   0.400  0.484848  0.051241  0.495474   \n",
       "2 2023-05-07 18:00:51.693401   0.391304   0.675  0.495413  0.082890  0.512908   \n",
       "3 2023-05-07 18:00:53.330085   0.629630   0.425  0.507463  0.049734  0.516643   \n",
       "4 2023-05-07 18:00:54.755584   0.653846   0.425  0.515152  0.048227  0.526526   \n",
       "5 2023-05-07 18:00:58.676986   0.358209   0.600  0.448598  0.088919  0.462470   \n",
       "6 2023-05-07 18:01:02.620683   0.358209   0.600  0.448598  0.088919  0.462470   \n",
       "\n",
       "   PublicScore  PrivateScore                           OldPublicScore  \\\n",
       "0          NaN           NaN  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1          NaN           NaN   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2          NaN           NaN  [0.677419354, 0.711864406, 0.092764378]   \n",
       "3          NaN           NaN                            [0.678571428]   \n",
       "4          NaN           NaN                            [0.703703703]   \n",
       "5          NaN           NaN               [0.678571428, 0.642857142]   \n",
       "6          NaN           NaN               [0.549019607, 0.642857142]   \n",
       "\n",
       "                           OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.199660  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.498927  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.518656  \n",
       "3                            [0.666666666]        0.519684  \n",
       "4                            [0.654867256]        0.530131  \n",
       "5               [0.637168141, 0.620689655]        0.467319  \n",
       "6                [0.48076923, 0.620689655]        0.467319  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "val_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "test_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "X_entier.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "train_X.drop(lowMI, inplace=True, axis=1, errors='ignore')\n",
    "val_X.drop(lowMI, inplace=True, axis=1, errors='ignore')\n",
    "test_X.drop(lowMI, inplace=True, axis=1, errors='ignore')\n",
    "X_entier.drop(lowMI, inplace=True, axis=1, errors='ignore')\n",
    "\n",
    "withoutlowMI = comparemodels(train_X, train_y, val_X, test_X, \"Delete low MI\")\n",
    "withoutlowMI[\"PublicScore\"] = [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "withoutlowMI[\"PrivateScore\"] = [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "withoutlowMI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fb5923",
   "metadata": {},
   "source": [
    "### 2.2.3 Delete medium MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "463dd25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sarah\\Documents\\ECAM_non_One_Drive\\Interligence artificiel\\Projet Niko\\AI5L_AILab_FraudDetection\\EvaluationMetric.py:8: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  metric = tp / (tp+fp)\n",
      "c:\\Users\\sarah\\Documents\\ECAM_non_One_Drive\\Interligence artificiel\\Projet Niko\\AI5L_AILab_FraudDetection\\EvaluationMetric.py:20: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = tp / (tp+fp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sarah\\Documents\\ECAM_non_One_Drive\\Interligence artificiel\\Projet Niko\\AI5L_AILab_FraudDetection\\EvaluationMetric.py:8: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  metric = tp / (tp+fp)\n",
      "c:\\Users\\sarah\\Documents\\ECAM_non_One_Drive\\Interligence artificiel\\Projet Niko\\AI5L_AILab_FraudDetection\\EvaluationMetric.py:20: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = tp / (tp+fp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sarah\\Documents\\ECAM_non_One_Drive\\Interligence artificiel\\Projet Niko\\AI5L_AILab_FraudDetection\\EvaluationMetric.py:8: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  metric = tp / (tp+fp)\n",
      "c:\\Users\\sarah\\Documents\\ECAM_non_One_Drive\\Interligence artificiel\\Projet Niko\\AI5L_AILab_FraudDetection\\EvaluationMetric.py:20: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = tp / (tp+fp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sarah\\Documents\\ECAM_non_One_Drive\\Interligence artificiel\\Projet Niko\\AI5L_AILab_FraudDetection\\EvaluationMetric.py:8: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  metric = tp / (tp+fp)\n",
      "c:\\Users\\sarah\\Documents\\ECAM_non_One_Drive\\Interligence artificiel\\Projet Niko\\AI5L_AILab_FraudDetection\\EvaluationMetric.py:20: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = tp / (tp+fp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Delete medium MImax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 18:01:03.544888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Delete medium MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 18:01:04.249490</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Delete medium MIscale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 18:01:05.325770</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.162791</td>\n",
       "      <td>0.108511</td>\n",
       "      <td>0.161685</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.162913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest ClassifierWeighted500</td>\n",
       "      <td>Delete medium MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 18:01:06.079859</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest ClassifierWeighted22</td>\n",
       "      <td>Delete medium MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 18:01:06.860320</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.703703703]</td>\n",
       "      <td>[0.654867256]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>Delete medium MIupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 18:01:08.112083</td>\n",
       "      <td>0.010398</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.020544</td>\n",
       "      <td>4.885998</td>\n",
       "      <td>0.084977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.241480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>Delete medium MIundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 18:01:09.284477</td>\n",
       "      <td>0.010398</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.020544</td>\n",
       "      <td>4.885998</td>\n",
       "      <td>0.084977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.241480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Model  \\\n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  Random Forest ClassifierWeighted500   \n",
       "4   Random Forest ClassifierWeighted22   \n",
       "5  RandomForestClassifierUpperSampling   \n",
       "6  RandomForestClassifierUnderSampling   \n",
       "\n",
       "                                                          Description  \\\n",
       "0              Delete medium MImax_leaf_nodes : 6 + with date columns   \n",
       "1                         Delete medium MIn_estimators : 36 + Entropy   \n",
       "2                               Delete medium MIscale_pos_weight = 22   \n",
       "3                         Delete medium MIn_estimators : 36 + Entropy   \n",
       "4                         Delete medium MIn_estimators : 36 + Entropy   \n",
       "5     Delete medium MIupsampled, n_estimators=36, criterion = entropy   \n",
       "6  Delete medium MIundersampled, n_estimators=36, criterion = entropy   \n",
       "\n",
       "                        Date  Precision  Recall  F1-score   LogLoss       Mcc  \\\n",
       "0 2023-05-07 18:01:03.544888        NaN   0.000       NaN  0.060284  0.000000   \n",
       "1 2023-05-07 18:01:04.249490        NaN   0.000       NaN  0.060284  0.000000   \n",
       "2 2023-05-07 18:01:05.325770   0.152174   0.175  0.162791  0.108511  0.161685   \n",
       "3 2023-05-07 18:01:06.079859        NaN   0.000       NaN  0.060284  0.000000   \n",
       "4 2023-05-07 18:01:06.860320        NaN   0.000       NaN  0.060284  0.000000   \n",
       "5 2023-05-07 18:01:08.112083   0.010398   0.850  0.020544  4.885998  0.084977   \n",
       "6 2023-05-07 18:01:09.284477   0.010398   0.850  0.020544  4.885998  0.084977   \n",
       "\n",
       "   PublicScore  PrivateScore                           OldPublicScore  \\\n",
       "0          NaN           NaN  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1          NaN           NaN   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2          NaN           NaN  [0.677419354, 0.711864406, 0.092764378]   \n",
       "3          NaN           NaN                            [0.678571428]   \n",
       "4          NaN           NaN                            [0.703703703]   \n",
       "5          NaN           NaN               [0.678571428, 0.642857142]   \n",
       "6          NaN           NaN               [0.549019607, 0.642857142]   \n",
       "\n",
       "                           OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.000000  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.000000  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.162913  \n",
       "3                            [0.666666666]        0.000000  \n",
       "4                            [0.654867256]        0.000000  \n",
       "5               [0.637168141, 0.620689655]        0.241480  \n",
       "6                [0.48076923, 0.620689655]        0.241480  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "val_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "test_X.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "X_entier.drop(verylowMI, inplace=True, axis=1, errors='ignore')\n",
    "train_X.drop(lowMI, inplace=True, axis=1, errors='ignore')\n",
    "val_X.drop(lowMI, inplace=True, axis=1, errors='ignore')\n",
    "test_X.drop(lowMI, inplace=True, axis=1, errors='ignore')\n",
    "X_entier.drop(lowMI, inplace=True, axis=1, errors='ignore')\n",
    "\n",
    "train_X.drop(mediumMI, inplace=True, axis=1, errors='ignore')\n",
    "val_X.drop(mediumMI, inplace=True, axis=1, errors='ignore')\n",
    "test_X.drop(mediumMI, inplace=True, axis=1, errors='ignore')\n",
    "X_entier.drop(mediumMI, inplace=True, axis=1, errors='ignore')\n",
    "\n",
    "withoutmediumMI = comparemodels(train_X, train_y, val_X, test_X, \"Delete medium MI\")\n",
    "withoutmediumMI[\"PublicScore\"] = [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "withoutmediumMI[\"PrivateScore\"] = [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "withoutmediumMI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f269ad",
   "metadata": {},
   "source": [
    "## 2.3 Undersampling with K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0f58714f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sarah\\anaconda3\\envs\\AILab-ECAM4\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Kmeans UnderSamplingmax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 18:01:50.976887</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.371584</td>\n",
       "      <td>0.979557</td>\n",
       "      <td>0.006575</td>\n",
       "      <td>0.006863</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.987512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Kmeans UnderSamplingn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 18:01:51.180607</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.114752</td>\n",
       "      <td>0.938324</td>\n",
       "      <td>0.007513</td>\n",
       "      <td>0.007795</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.961903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Kmeans UnderSamplingon balanced data</td>\n",
       "      <td>2023-05-07 18:01:51.343651</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.114752</td>\n",
       "      <td>0.938324</td>\n",
       "      <td>0.092764</td>\n",
       "      <td>0.096565</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.961903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model  \\\n",
       "0    DecisionTreeClassifier   \n",
       "1  Random Forest Classifier   \n",
       "2             XGBClassifier   \n",
       "\n",
       "                                                  Description  \\\n",
       "0  Kmeans UnderSamplingmax_leaf_nodes : 6 + with date columns   \n",
       "1             Kmeans UnderSamplingn_estimators : 36 + Entropy   \n",
       "2                        Kmeans UnderSamplingon balanced data   \n",
       "\n",
       "                        Date  Precision  Recall  F1-score   LogLoss       Mcc  \\\n",
       "0 2023-05-07 18:01:50.976887   0.980392    1.00  0.990099  0.371584  0.979557   \n",
       "1 2023-05-07 18:01:51.180607   0.979592    0.96  0.969697  1.114752  0.938324   \n",
       "2 2023-05-07 18:01:51.343651   0.979592    0.96  0.969697  1.114752  0.938324   \n",
       "\n",
       "   PublicScore  PrivateScore                           OldPublicScore  \\\n",
       "0     0.006575      0.006863  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1     0.007513      0.007795   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2     0.092764      0.096565  [0.677419354, 0.711864406, 0.092764378]   \n",
       "\n",
       "                           OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.987512  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.961903  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.961903  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans \n",
    "\n",
    "# K-means fait sur training set entier (et ensuite sur seuelement le train_X)\n",
    "def_feature = pd.read_csv(\"input/Xente_Variable_Definitions.csv\")\n",
    "raw_data = pd.read_csv(\"input/training.csv\")\n",
    "X_test = pd.read_csv(\"input/test.csv\")\n",
    "sample_submission = pd.read_csv(\"input/sample_submission.csv\")\n",
    "\n",
    "#attribut initialization\n",
    "cols_unique_value = [] #Will be droped\n",
    "for col in raw_data.columns : \n",
    "    if len(raw_data[col].unique()) == 1 :\n",
    "        cols_unique_value.append(col)\n",
    "\n",
    "medium_cardianlity_cols = [\"ProductId\"]\n",
    "\n",
    "#Data transformation\n",
    "raw_data['TransactionStartTime'] = pd.to_datetime(raw_data['TransactionStartTime'])\n",
    "X_test['TransactionStartTime'] = pd.to_datetime(X_test['TransactionStartTime'])\n",
    "\n",
    "#Data cleaning\n",
    "data = raw_data.copy()\n",
    "data = data.dropna(axis=0) #Drop observations/rows with missing values\n",
    "X_test=X_test.dropna(axis=0)\n",
    "data.drop(cols_unique_value, axis=1, inplace=True)\n",
    "X_test.drop(cols_unique_value, axis=1, inplace=True)\n",
    "\n",
    "#Prepare index for the submission\n",
    "index_val = list(X_test.TransactionId.values.tolist())\n",
    "\n",
    "#Set the df index to the Transction Id\n",
    "data = transactioId_to_index(data)\n",
    "X_test = transactioId_to_index(X_test)\n",
    "\n",
    "#Adding data\n",
    "data = adding_date_col(data, 'TransactionStartTime')\n",
    "X_test = adding_date_col(X_test, 'TransactionStartTime')\n",
    "\n",
    "\n",
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "low_cardinality_cols = [cname for cname in data.columns if data[cname].nunique() < 15 and \n",
    "                        data[cname].dtype == \"object\"]\n",
    "low_cardinality_cols.append('PricingStrategy')\n",
    "\n",
    "#transform columns BatchId_54 to number\n",
    "    #transform columns BatchId_54 to number\n",
    "id_cols = data.filter(like=\"Id\").columns.tolist()\n",
    "data[id_cols] = data[id_cols].astype(str).apply(lambda x: x.str.replace(x.name + \"_\", \"\")).astype(int)\n",
    "X_test[id_cols] = X_test[id_cols].astype(str).apply(lambda x: x.str.replace(x.name + \"_\", \"\")).astype(int)\n",
    "\n",
    "data['PricingStrategy'] = data['PricingStrategy'].astype('int')\n",
    "X_test['PricingStrategy'] = X_test['PricingStrategy'].astype('int')\n",
    "data['Value'] = data['Value'].astype('float')\n",
    "X_test['Value'] = X_test['Value'].astype('float')\n",
    "\n",
    "X_test['PricingStrategy'] = X_test['PricingStrategy'].astype('str')\n",
    "data['PricingStrategy'] = data['PricingStrategy'].astype('str')\n",
    "\n",
    "#Data splitting\n",
    "y = data.FraudResult #The target label\n",
    "X = data.copy()\n",
    "X.drop(['FraudResult'], axis=1, inplace=True) #Only the features data\n",
    "\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "OH_cols_X = pd.DataFrame(OH_encoder.fit_transform(X[low_cardinality_cols]))\n",
    "OH_cols_X.columns = OH_encoder.get_feature_names_out()\n",
    "OH_cols_test = pd.DataFrame(OH_encoder.transform(X_test[low_cardinality_cols]))\n",
    "OH_cols_test.columns = OH_encoder.get_feature_names_out()\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_X.index = X.index\n",
    "OH_cols_test.index = X_test.index\n",
    "\n",
    "OH_cols_X[list(OH_cols_X.columns)] = OH_cols_X[list(OH_cols_X.columns)].astype(int)\n",
    "OH_cols_test[list(OH_cols_test.columns)] = OH_cols_test[list(OH_cols_test.columns)].astype(int)\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X = X.drop(low_cardinality_cols, axis=1)\n",
    "num_X_test = X_test.drop(low_cardinality_cols, axis=1)\n",
    "\n",
    "OH_X = pd.concat([num_X, OH_cols_X], axis=1)\n",
    "OH_X_test = pd.concat([num_X_test, OH_cols_test], axis=1)\n",
    "\n",
    "# Problme de string\n",
    "OH_X.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_test.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X.columns = OH_X.columns.astype(str)\n",
    "OH_X_test.columns = OH_X_test.columns.astype(str)\n",
    "\n",
    "X = OH_X\n",
    "\n",
    "#####K-Means\n",
    "X_0 = X[y == 0] # instances avec FraudResult=0\n",
    "X_1 = X[y == 1] # instances avec FraudResult=1\n",
    "\n",
    "# Crer des \"centres\" pour KMeans\n",
    "n_clusters = 193\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(X_0)\n",
    "centers = kmeans.cluster_centers_\n",
    "\n",
    "# Trouver les indices des instances  garder dans la classe FraudResult=0\n",
    "labels = kmeans.predict(X_0)\n",
    "distances = np.sum((X_0 - centers[labels]) ** 2, axis=1)\n",
    "keep_indices = np.argsort(distances)[:n_clusters]\n",
    "\n",
    "df_filtr = X_0[X_0.index.isin(list(keep_indices.index))]\n",
    "\n",
    "# Combiner les instances sous-chantillonnes\n",
    "X_undersampled = pd.concat([df_filtr, X_1])\n",
    "y_undersampled = np.concatenate((np.zeros(n_clusters), np.ones(len(X_1))), axis=0)\n",
    "\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(X_undersampled, y_undersampled, random_state = 0)\n",
    "\n",
    "\n",
    "#train_X.drop(verylowMI, inplace=True, axis=1)\n",
    "#val_X.drop(verylowMI, inplace=True, axis=1)\n",
    "#test_X.drop(verylowMI, inplace=True, axis=1)\n",
    "#X_entier.drop(verylowMI, inplace=True, axis=1)\n",
    "\n",
    "kmeansundersampling = comparemodels(train_X, train_y, val_X, OH_X_test, \"Kmeans UnderSampling\", unbalanced = False)\n",
    "kmeansundersampling[\"PublicScore\"] = [0.006575486, 0.007513148, 0.092764378]\n",
    "kmeansundersampling[\"PrivateScore\"] = [0.006863327, 0.007794933, 0.096564531] ###Cest trop nulle \n",
    "kmeansundersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789ddb0c",
   "metadata": {},
   "source": [
    "## 2.4. SMOTE (Synthetic Minority Oversampling Technique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ed3fa295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>SMOTEmax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 18:02:19.908308</td>\n",
       "      <td>0.113372</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.203125</td>\n",
       "      <td>0.461171</td>\n",
       "      <td>0.330225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.405431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>SMOTEn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 18:02:26.204310</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.027128</td>\n",
       "      <td>0.804629</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.686567</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.806157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>SMOTEon balanced data</td>\n",
       "      <td>2023-05-07 18:02:32.552743</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.862324</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.376068</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.863034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model                                  Description  \\\n",
       "0    DecisionTreeClassifier  SMOTEmax_leaf_nodes : 6 + with date columns   \n",
       "1  Random Forest Classifier             SMOTEn_estimators : 36 + Entropy   \n",
       "2             XGBClassifier                        SMOTEon balanced data   \n",
       "\n",
       "                        Date  Precision  Recall  F1-score   LogLoss       Mcc  \\\n",
       "0 2023-05-07 18:02:19.908308   0.113372   0.975  0.203125  0.461171  0.330225   \n",
       "1 2023-05-07 18:02:26.204310   0.720000   0.900  0.800000  0.027128  0.804629   \n",
       "2 2023-05-07 18:02:32.552743   0.804348   0.925  0.860465  0.018085  0.862324   \n",
       "\n",
       "   PublicScore  PrivateScore                           OldPublicScore  \\\n",
       "0          NaN           NaN  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1     0.709677      0.686567   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2     0.358974      0.376068  [0.677419354, 0.711864406, 0.092764378]   \n",
       "\n",
       "                           OldPrivateScore  MeanOurMetrics  \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.405431  \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.806157  \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.863034  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SMOTE\n",
    "def_feature = pd.read_csv(\"input/Xente_Variable_Definitions.csv\")\n",
    "raw_data = pd.read_csv(\"input/training.csv\")\n",
    "X_test = pd.read_csv(\"input/test.csv\")\n",
    "sample_submission = pd.read_csv(\"input/sample_submission.csv\")\n",
    "\n",
    "#attribut initialization\n",
    "cols_unique_value = [] #Will be droped\n",
    "for col in raw_data.columns : \n",
    "    if len(raw_data[col].unique()) == 1 :\n",
    "        cols_unique_value.append(col)\n",
    "\n",
    "medium_cardianlity_cols = [\"ProductId\"]\n",
    "\n",
    "#Data transformation\n",
    "raw_data['TransactionStartTime'] = pd.to_datetime(raw_data['TransactionStartTime'])\n",
    "X_test['TransactionStartTime'] = pd.to_datetime(X_test['TransactionStartTime'])\n",
    "\n",
    "#Data cleaning\n",
    "data = raw_data.copy()\n",
    "data = data.dropna(axis=0) #Drop observations/rows with missing values\n",
    "X_test=X_test.dropna(axis=0)\n",
    "data.drop(cols_unique_value, axis=1, inplace=True)\n",
    "X_test.drop(cols_unique_value, axis=1, inplace=True)\n",
    "\n",
    "#Prepare index for the submission\n",
    "index_val = list(X_test.TransactionId.values.tolist())\n",
    "\n",
    "#Set the df index to the Transction Id\n",
    "data = transactioId_to_index(data)\n",
    "X_test = transactioId_to_index(X_test)\n",
    "\n",
    "#Adding data\n",
    "data = adding_date_col(data, 'TransactionStartTime')\n",
    "X_test = adding_date_col(X_test, 'TransactionStartTime')\n",
    "\n",
    "\n",
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "low_cardinality_cols = [cname for cname in data.columns if data[cname].nunique() < 15 and \n",
    "                        data[cname].dtype == \"object\"]\n",
    "low_cardinality_cols.append('PricingStrategy')\n",
    "\n",
    "#transform columns BatchId_54 to number\n",
    "    #transform columns BatchId_54 to number\n",
    "id_cols = data.filter(like=\"Id\").columns.tolist()\n",
    "data[id_cols] = data[id_cols].astype(str).apply(lambda x: x.str.replace(x.name + \"_\", \"\")).astype(int)\n",
    "X_test[id_cols] = X_test[id_cols].astype(str).apply(lambda x: x.str.replace(x.name + \"_\", \"\")).astype(int)\n",
    "\n",
    "data['PricingStrategy'] = data['PricingStrategy'].astype('int')\n",
    "X_test['PricingStrategy'] = X_test['PricingStrategy'].astype('int')\n",
    "data['Value'] = data['Value'].astype('float')\n",
    "X_test['Value'] = X_test['Value'].astype('float')\n",
    "\n",
    "X_test['PricingStrategy'] = X_test['PricingStrategy'].astype('str')\n",
    "data['PricingStrategy'] = data['PricingStrategy'].astype('str')\n",
    "\n",
    "#Data splitting\n",
    "y = data.FraudResult #The target label\n",
    "X = data.copy()\n",
    "X.drop(['FraudResult'], axis=1, inplace=True) #Only the features data\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "cat_cols = [col for col in X.columns if X[col].dtype == \"object\"]#liste of obejct columns\n",
    "cat_cols.append(\"PricingStrategy\")#pcq mm si c'est un chiffre il faut le considrer comme une catgorie\n",
    "\n",
    "\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(train_X[low_cardinality_cols]))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(val_X[low_cardinality_cols]))\n",
    "OH_cols_test = pd.DataFrame(OH_encoder.transform(X_test[low_cardinality_cols]))\n",
    "OH_cols_train.columns = OH_encoder.get_feature_names_out()\n",
    "OH_cols_valid.columns = OH_encoder.get_feature_names_out()\n",
    "OH_cols_test.columns = OH_encoder.get_feature_names_out()\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_train.index = train_X.index\n",
    "OH_cols_valid.index = val_X.index\n",
    "OH_cols_test.index = X_test.index\n",
    "\n",
    "OH_cols_train[list(OH_cols_train.columns)] = OH_cols_train[list(OH_cols_train.columns)].astype(int)\n",
    "OH_cols_valid[list(OH_cols_valid.columns)] = OH_cols_valid[list(OH_cols_valid.columns)].astype(int)\n",
    "OH_cols_test[list(OH_cols_test.columns)] = OH_cols_test[list(OH_cols_test.columns)].astype(int)\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train = train_X.drop(low_cardinality_cols, axis=1)\n",
    "num_X_valid = val_X.drop(low_cardinality_cols, axis=1)\n",
    "num_X_test = X_test.drop(low_cardinality_cols, axis=1)\n",
    "\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
    "OH_X_test = pd.concat([num_X_test, OH_cols_test], axis=1)\n",
    "\n",
    "# Problme de string\n",
    "OH_X_train.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_valid.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_test.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_train.columns = OH_X_train.columns.astype(str)\n",
    "OH_X_valid.columns = OH_X_valid.columns.astype(str)\n",
    "OH_X_test.columns = OH_X_test.columns.astype(str)\n",
    "\n",
    "train_X = OH_X_train\n",
    "val_X = OH_X_valid\n",
    "test_X = OH_X_test\n",
    "X_entier = pd.concat([train_X, val_X])\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(train_X, train_y)\n",
    "\n",
    "mi_scores = make_mi_scores(X_entier, y)\n",
    "\n",
    "verylowMI = list(mi_scores[mi_scores<0.0001].index)\n",
    "lowMI = list(mi_scores[(mi_scores>=0.0001)&(mi_scores<0.001)].index)\n",
    "mediumMI = list(mi_scores[(mi_scores>=0.001)&(mi_scores<0.01)].index)\n",
    "highMI = list(mi_scores[mi_scores>=0.01].index)\n",
    "\n",
    "\n",
    "#train_X.drop(verylowMI, inplace=True, axis=1)\n",
    "#val_X.drop(verylowMI, inplace=True, axis=1)\n",
    "#test_X.drop(verylowMI, inplace=True, axis=1)\n",
    "#X_entier.drop(verylowMI, inplace=True, axis=1)\n",
    "\n",
    "SMOTERes = comparemodels(X_res, y_res, val_X, test_X, \"SMOTE\", unbalanced = False)\n",
    "SMOTERes[\"PublicScore\"] = [np.nan, 0.709677419, 0.358974358] #ici voit que le RandomForest est mieux\n",
    "SMOTERes[\"PrivateScore\"] = [np.nan, 0.686567164, 0.376068376]  \n",
    "SMOTERes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6650c6",
   "metadata": {},
   "source": [
    "# 3. Compare result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "78eddab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>The referencemax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 17:56:40.979441</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>0.857566</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.661017</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.857900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>The referencen_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 17:56:42.813669</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.843373</td>\n",
       "      <td>0.019592</td>\n",
       "      <td>0.843655</td>\n",
       "      <td>0.690909</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.843995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>The referencescale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 17:56:45.360445</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>0.871874</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.676923</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.872421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest ClassifierWeighted500</td>\n",
       "      <td>The referencen_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 17:56:47.342506</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.862324</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>0.863034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest ClassifierWeighted22</td>\n",
       "      <td>The referencen_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 17:56:49.369181</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.862324</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.654867</td>\n",
       "      <td>[0.703703703]</td>\n",
       "      <td>[0.654867256]</td>\n",
       "      <td>0.863034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Delete only low + Niko Datasscale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 17:59:25.475257</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.867470</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>0.867303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.867491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest ClassifierWeighted500</td>\n",
       "      <td>Delete only low + Niko Datasn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 17:59:26.983833</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.024113</td>\n",
       "      <td>0.800671</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>0.801170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest ClassifierWeighted22</td>\n",
       "      <td>Delete only low + Niko Datasn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 17:59:28.807381</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.021099</td>\n",
       "      <td>0.822667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.703703703]</td>\n",
       "      <td>[0.654867256]</td>\n",
       "      <td>0.823493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>Delete only low + Niko Datasupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 17:59:32.539051</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.030142</td>\n",
       "      <td>0.761486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.761800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>Delete only low + Niko Datasundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 17:59:36.196091</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.030142</td>\n",
       "      <td>0.761486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.761800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Model  \\\n",
       "0                DecisionTreeClassifier   \n",
       "1              Random Forest Classifier   \n",
       "2                         XGBClassifier   \n",
       "3   Random Forest ClassifierWeighted500   \n",
       "4    Random Forest ClassifierWeighted22   \n",
       "..                                  ...   \n",
       "2                         XGBClassifier   \n",
       "3   Random Forest ClassifierWeighted500   \n",
       "4    Random Forest ClassifierWeighted22   \n",
       "5   RandomForestClassifierUpperSampling   \n",
       "6   RandomForestClassifierUnderSampling   \n",
       "\n",
       "                                                                       Description  \\\n",
       "0                              The referencemax_leaf_nodes : 6 + with date columns   \n",
       "1                                         The referencen_estimators : 36 + Entropy   \n",
       "2                                               The referencescale_pos_weight = 22   \n",
       "3                                         The referencen_estimators : 36 + Entropy   \n",
       "4                                         The referencen_estimators : 36 + Entropy   \n",
       "..                                                                             ...   \n",
       "2                                Delete only low + Niko Datasscale_pos_weight = 22   \n",
       "3                          Delete only low + Niko Datasn_estimators : 36 + Entropy   \n",
       "4                          Delete only low + Niko Datasn_estimators : 36 + Entropy   \n",
       "5      Delete only low + Niko Datasupsampled, n_estimators=36, criterion = entropy   \n",
       "6   Delete only low + Niko Datasundersampled, n_estimators=36, criterion = entropy   \n",
       "\n",
       "                         Date  Precision    Recall  F1-score   LogLoss  \\\n",
       "0  2023-05-07 17:56:40.979441   0.891892  0.825000  0.857143  0.016578   \n",
       "1  2023-05-07 17:56:42.813669   0.813953  0.875000  0.843373  0.019592   \n",
       "2  2023-05-07 17:56:45.360445   0.822222  0.925000  0.870588  0.016578   \n",
       "3  2023-05-07 17:56:47.342506   0.804348  0.925000  0.860465  0.018085   \n",
       "4  2023-05-07 17:56:49.369181   0.804348  0.925000  0.860465  0.018085   \n",
       "..                        ...        ...       ...       ...       ...   \n",
       "2  2023-05-07 17:59:25.475257   0.878049  0.857143  0.867470  0.016578   \n",
       "3  2023-05-07 17:59:26.983833   0.842105  0.761905  0.800000  0.024113   \n",
       "4  2023-05-07 17:59:28.807381   0.888889  0.761905  0.820513  0.021099   \n",
       "5  2023-05-07 17:59:32.539051   0.761905  0.761905  0.761905  0.030142   \n",
       "6  2023-05-07 17:59:36.196091   0.761905  0.761905  0.761905  0.030142   \n",
       "\n",
       "         Mcc  PublicScore  PrivateScore  \\\n",
       "0   0.857566     0.666667      0.661017   \n",
       "1   0.843655     0.690909      0.649123   \n",
       "2   0.871874     0.677419      0.676923   \n",
       "3   0.862324     0.678571      0.666667   \n",
       "4   0.862324     0.703704      0.654867   \n",
       "..       ...          ...           ...   \n",
       "2   0.867303          NaN           NaN   \n",
       "3   0.800671          NaN           NaN   \n",
       "4   0.822667          NaN           NaN   \n",
       "5   0.761486          NaN           NaN   \n",
       "6   0.761486          NaN           NaN   \n",
       "\n",
       "                             OldPublicScore  \\\n",
       "0   [0.666666666, 0.666666666, 0.006575486]   \n",
       "1    [0.69090909, 0.666666666, 0.007513148]   \n",
       "2   [0.677419354, 0.711864406, 0.092764378]   \n",
       "3                             [0.678571428]   \n",
       "4                             [0.703703703]   \n",
       "..                                      ...   \n",
       "2   [0.677419354, 0.711864406, 0.092764378]   \n",
       "3                             [0.678571428]   \n",
       "4                             [0.703703703]   \n",
       "5                [0.678571428, 0.642857142]   \n",
       "6                [0.549019607, 0.642857142]   \n",
       "\n",
       "                            OldPrivateScore  MeanOurMetrics  \n",
       "0   [0.661016949, 0.661016949, 0.006863327]        0.857900  \n",
       "1   [0.649122807, 0.649122807, 0.007794933]        0.843995  \n",
       "2   [0.676923076, 0.715447154, 0.096564531]        0.872421  \n",
       "3                             [0.666666666]        0.863034  \n",
       "4                             [0.654867256]        0.863034  \n",
       "..                                      ...             ...  \n",
       "2   [0.676923076, 0.715447154, 0.096564531]        0.867491  \n",
       "3                             [0.666666666]        0.801170  \n",
       "4                             [0.654867256]        0.823493  \n",
       "5                [0.637168141, 0.620689655]        0.761800  \n",
       "6                 [0.48076923, 0.620689655]        0.761800  \n",
       "\n",
       "[69 rows x 13 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfResult = pd.concat([referenceresult, withoutverylowMI, withoutlowMI, withoutmediumMI, kmeansundersampling, SMOTERes,\n",
    "                        result1, result2, result3, result4, result5])\n",
    "dfResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d7c6ddd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "      <th>DescCompl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Kmeans UnderSamplingmax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 18:01:50.976887</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.371584</td>\n",
       "      <td>0.979557</td>\n",
       "      <td>0.006575</td>\n",
       "      <td>0.006863</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.987512</td>\n",
       "      <td>DecisionTreeClassifierKmeans UnderSamplingmax_leaf_nodes : 6 + with date columns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Kmeans UnderSamplingn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 18:01:51.180607</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.114752</td>\n",
       "      <td>0.938324</td>\n",
       "      <td>0.007513</td>\n",
       "      <td>0.007795</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.961903</td>\n",
       "      <td>Random Forest ClassifierKmeans UnderSamplingn_estimators : 36 + Entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Kmeans UnderSamplingon balanced data</td>\n",
       "      <td>2023-05-07 18:01:51.343651</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.114752</td>\n",
       "      <td>0.938324</td>\n",
       "      <td>0.092764</td>\n",
       "      <td>0.096565</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.961903</td>\n",
       "      <td>XGBClassifierKmeans UnderSamplingon balanced data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest ClassifierWeighted500</td>\n",
       "      <td>With All Columnsn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 17:57:09.669936</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.873563</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>0.876185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>0.877065</td>\n",
       "      <td>Random Forest ClassifierWeighted500With All Columnsn_estimators : 36 + Entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest ClassifierWeighted22</td>\n",
       "      <td>The referencen_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 17:56:49.369181</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.862324</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.654867</td>\n",
       "      <td>[0.703703703]</td>\n",
       "      <td>[0.654867256]</td>\n",
       "      <td>0.863034</td>\n",
       "      <td>Random Forest ClassifierWeighted22The referencen_estimators : 36 + Entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>The referenceupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 17:56:53.301001</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.022606</td>\n",
       "      <td>0.824649</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.637168</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.825239</td>\n",
       "      <td>RandomForestClassifierUpperSamplingThe referenceupsampled, n_estimators=36, criterion = entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>The referenceundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 17:56:57.065217</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.022606</td>\n",
       "      <td>0.824649</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.825239</td>\n",
       "      <td>RandomForestClassifierUnderSamplingThe referenceundersampled, n_estimators=36, criterion = entropy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Model  \\\n",
       "0               DecisionTreeClassifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  Random Forest ClassifierWeighted500   \n",
       "4   Random Forest ClassifierWeighted22   \n",
       "5  RandomForestClassifierUpperSampling   \n",
       "6  RandomForestClassifierUnderSampling   \n",
       "\n",
       "                                                       Description  \\\n",
       "0       Kmeans UnderSamplingmax_leaf_nodes : 6 + with date columns   \n",
       "1                  Kmeans UnderSamplingn_estimators : 36 + Entropy   \n",
       "2                             Kmeans UnderSamplingon balanced data   \n",
       "3                      With All Columnsn_estimators : 36 + Entropy   \n",
       "4                         The referencen_estimators : 36 + Entropy   \n",
       "5     The referenceupsampled, n_estimators=36, criterion = entropy   \n",
       "6  The referenceundersampled, n_estimators=36, criterion = entropy   \n",
       "\n",
       "                        Date  Precision  Recall  F1-score   LogLoss       Mcc  \\\n",
       "0 2023-05-07 18:01:50.976887   0.980392   1.000  0.990099  0.371584  0.979557   \n",
       "1 2023-05-07 18:01:51.180607   0.979592   0.960  0.969697  1.114752  0.938324   \n",
       "2 2023-05-07 18:01:51.343651   0.979592   0.960  0.969697  1.114752  0.938324   \n",
       "3 2023-05-07 17:57:09.669936   0.808511   0.950  0.873563  0.016578  0.876185   \n",
       "4 2023-05-07 17:56:49.369181   0.804348   0.925  0.860465  0.018085  0.862324   \n",
       "5 2023-05-07 17:56:53.301001   0.777778   0.875  0.823529  0.022606  0.824649   \n",
       "6 2023-05-07 17:56:57.065217   0.777778   0.875  0.823529  0.022606  0.824649   \n",
       "\n",
       "   PublicScore  PrivateScore                           OldPublicScore  \\\n",
       "0     0.006575      0.006863  [0.666666666, 0.666666666, 0.006575486]   \n",
       "1     0.007513      0.007795   [0.69090909, 0.666666666, 0.007513148]   \n",
       "2     0.092764      0.096565  [0.677419354, 0.711864406, 0.092764378]   \n",
       "3          NaN           NaN                            [0.678571428]   \n",
       "4     0.703704      0.654867                            [0.703703703]   \n",
       "5     0.678571      0.637168               [0.678571428, 0.642857142]   \n",
       "6     0.549020      0.480769               [0.549019607, 0.642857142]   \n",
       "\n",
       "                           OldPrivateScore  MeanOurMetrics  \\\n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.987512   \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.961903   \n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.961903   \n",
       "3                            [0.666666666]        0.877065   \n",
       "4                            [0.654867256]        0.863034   \n",
       "5               [0.637168141, 0.620689655]        0.825239   \n",
       "6                [0.48076923, 0.620689655]        0.825239   \n",
       "\n",
       "                                                                                            DescCompl  \n",
       "0                    DecisionTreeClassifierKmeans UnderSamplingmax_leaf_nodes : 6 + with date columns  \n",
       "1                             Random Forest ClassifierKmeans UnderSamplingn_estimators : 36 + Entropy  \n",
       "2                                                   XGBClassifierKmeans UnderSamplingon balanced data  \n",
       "3                      Random Forest ClassifierWeighted500With All Columnsn_estimators : 36 + Entropy  \n",
       "4                          Random Forest ClassifierWeighted22The referencen_estimators : 36 + Entropy  \n",
       "5     RandomForestClassifierUpperSamplingThe referenceupsampled, n_estimators=36, criterion = entropy  \n",
       "6  RandomForestClassifierUnderSamplingThe referenceundersampled, n_estimators=36, criterion = entropy  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Les meilleur MeanOurMetrics\n",
    "idx = dfResult.groupby([\"Model\"])[\"MeanOurMetrics\"].transform(max) == dfResult[\"MeanOurMetrics\"]\n",
    "dfResult[idx].sort_values(by='MeanOurMetrics', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ea8ec134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "      <th>DescCompl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Delete very low MIscale_pos_weight = 22</td>\n",
       "      <td>2023-05-07 18:00:29.500942</td>\n",
       "      <td>0.465116</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.481928</td>\n",
       "      <td>0.064805</td>\n",
       "      <td>0.481344</td>\n",
       "      <td>0.711864</td>\n",
       "      <td>0.715447</td>\n",
       "      <td>[0.677419354, 0.711864406, 0.092764378]</td>\n",
       "      <td>[0.676923076, 0.715447154, 0.096564531]</td>\n",
       "      <td>0.482097</td>\n",
       "      <td>XGBClassifierDelete very low MIscale_pos_weight = 22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>SMOTEn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 18:02:26.204310</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.027128</td>\n",
       "      <td>0.804629</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.686567</td>\n",
       "      <td>[0.69090909, 0.666666666, 0.007513148]</td>\n",
       "      <td>[0.649122807, 0.649122807, 0.007794933]</td>\n",
       "      <td>0.806157</td>\n",
       "      <td>Random Forest ClassifierSMOTEn_estimators : 36 + Entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest ClassifierWeighted22</td>\n",
       "      <td>The referencen_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 17:56:49.369181</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.862324</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.654867</td>\n",
       "      <td>[0.703703703]</td>\n",
       "      <td>[0.654867256]</td>\n",
       "      <td>0.863034</td>\n",
       "      <td>Random Forest ClassifierWeighted22The referencen_estimators : 36 + Entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest ClassifierWeighted500</td>\n",
       "      <td>The referencen_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-07 17:56:47.342506</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.862324</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>0.863034</td>\n",
       "      <td>Random Forest ClassifierWeighted500The referencen_estimators : 36 + Entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>The referenceupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 17:56:53.301001</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.022606</td>\n",
       "      <td>0.824649</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.637168</td>\n",
       "      <td>[0.678571428, 0.642857142]</td>\n",
       "      <td>[0.637168141, 0.620689655]</td>\n",
       "      <td>0.825239</td>\n",
       "      <td>RandomForestClassifierUpperSamplingThe referenceupsampled, n_estimators=36, criterion = entropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>The referencemax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 17:56:40.979441</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>0.857566</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.661017</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.857900</td>\n",
       "      <td>DecisionTreeClassifierThe referencemax_leaf_nodes : 6 + with date columns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>Delete very low MImax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-07 18:00:23.002639</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.057270</td>\n",
       "      <td>0.257799</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.661017</td>\n",
       "      <td>[0.666666666, 0.666666666, 0.006575486]</td>\n",
       "      <td>[0.661016949, 0.661016949, 0.006863327]</td>\n",
       "      <td>0.299595</td>\n",
       "      <td>DecisionTreeClassifierDelete very low MImax_leaf_nodes : 6 + with date columns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>Delete very low MIundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-07 18:00:46.876165</td>\n",
       "      <td>0.459459</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.441558</td>\n",
       "      <td>0.064805</td>\n",
       "      <td>0.440995</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>[0.549019607, 0.642857142]</td>\n",
       "      <td>[0.48076923, 0.620689655]</td>\n",
       "      <td>0.441753</td>\n",
       "      <td>RandomForestClassifierUnderSamplingDelete very low MIundersampled, n_estimators=36, criterion = entropy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Model  \\\n",
       "2                        XGBClassifier   \n",
       "1             Random Forest Classifier   \n",
       "4   Random Forest ClassifierWeighted22   \n",
       "3  Random Forest ClassifierWeighted500   \n",
       "5  RandomForestClassifierUpperSampling   \n",
       "0               DecisionTreeClassifier   \n",
       "0               DecisionTreeClassifier   \n",
       "6  RandomForestClassifierUnderSampling   \n",
       "\n",
       "                                                            Description  \\\n",
       "2                               Delete very low MIscale_pos_weight = 22   \n",
       "1                                      SMOTEn_estimators : 36 + Entropy   \n",
       "4                              The referencen_estimators : 36 + Entropy   \n",
       "3                              The referencen_estimators : 36 + Entropy   \n",
       "5          The referenceupsampled, n_estimators=36, criterion = entropy   \n",
       "0                   The referencemax_leaf_nodes : 6 + with date columns   \n",
       "0              Delete very low MImax_leaf_nodes : 6 + with date columns   \n",
       "6  Delete very low MIundersampled, n_estimators=36, criterion = entropy   \n",
       "\n",
       "                        Date  Precision  Recall  F1-score   LogLoss       Mcc  \\\n",
       "2 2023-05-07 18:00:29.500942   0.465116   0.500  0.481928  0.064805  0.481344   \n",
       "1 2023-05-07 18:02:26.204310   0.720000   0.900  0.800000  0.027128  0.804629   \n",
       "4 2023-05-07 17:56:49.369181   0.804348   0.925  0.860465  0.018085  0.862324   \n",
       "3 2023-05-07 17:56:47.342506   0.804348   0.925  0.860465  0.018085  0.862324   \n",
       "5 2023-05-07 17:56:53.301001   0.777778   0.875  0.823529  0.022606  0.824649   \n",
       "0 2023-05-07 17:56:40.979441   0.891892   0.825  0.857143  0.016578  0.857566   \n",
       "0 2023-05-07 18:00:23.002639   0.666667   0.100  0.173913  0.057270  0.257799   \n",
       "6 2023-05-07 18:00:46.876165   0.459459   0.425  0.441558  0.064805  0.440995   \n",
       "\n",
       "   PublicScore  PrivateScore                           OldPublicScore  \\\n",
       "2     0.711864      0.715447  [0.677419354, 0.711864406, 0.092764378]   \n",
       "1     0.709677      0.686567   [0.69090909, 0.666666666, 0.007513148]   \n",
       "4     0.703704      0.654867                            [0.703703703]   \n",
       "3     0.678571      0.666667                            [0.678571428]   \n",
       "5     0.678571      0.637168               [0.678571428, 0.642857142]   \n",
       "0     0.666667      0.661017  [0.666666666, 0.666666666, 0.006575486]   \n",
       "0     0.666667      0.661017  [0.666666666, 0.666666666, 0.006575486]   \n",
       "6     0.642857      0.620690               [0.549019607, 0.642857142]   \n",
       "\n",
       "                           OldPrivateScore  MeanOurMetrics  \\\n",
       "2  [0.676923076, 0.715447154, 0.096564531]        0.482097   \n",
       "1  [0.649122807, 0.649122807, 0.007794933]        0.806157   \n",
       "4                            [0.654867256]        0.863034   \n",
       "3                            [0.666666666]        0.863034   \n",
       "5               [0.637168141, 0.620689655]        0.825239   \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.857900   \n",
       "0  [0.661016949, 0.661016949, 0.006863327]        0.299595   \n",
       "6                [0.48076923, 0.620689655]        0.441753   \n",
       "\n",
       "                                                                                                 DescCompl  \n",
       "2                                                     XGBClassifierDelete very low MIscale_pos_weight = 22  \n",
       "1                                                 Random Forest ClassifierSMOTEn_estimators : 36 + Entropy  \n",
       "4                               Random Forest ClassifierWeighted22The referencen_estimators : 36 + Entropy  \n",
       "3                              Random Forest ClassifierWeighted500The referencen_estimators : 36 + Entropy  \n",
       "5          RandomForestClassifierUpperSamplingThe referenceupsampled, n_estimators=36, criterion = entropy  \n",
       "0                                DecisionTreeClassifierThe referencemax_leaf_nodes : 6 + with date columns  \n",
       "0                           DecisionTreeClassifierDelete very low MImax_leaf_nodes : 6 + with date columns  \n",
       "6  RandomForestClassifierUnderSamplingDelete very low MIundersampled, n_estimators=36, criterion = entropy  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = dfResult.groupby([\"Model\"])[\"PublicScore\"].transform(max) == dfResult[\"PublicScore\"]\n",
    "dfResult[idx].sort_values(by='PublicScore', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71d0234",
   "metadata": {},
   "source": [
    "# Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a49624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les meilleurs rsultat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarah\\AppData\\Local\\Temp\\ipykernel_2988\\2367281751.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  dfresult.groupby(['Model'])['Precision','Recall','F1-score','LogLoss','MeanOurMetrics'].max()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classifier</th>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.882409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.980392</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.461171</td>\n",
       "      <td>0.987512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.114752</td>\n",
       "      <td>0.961903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest ClassifierWeighted</th>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.863034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest ClassifierWeighted22</th>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.863034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest ClassifierWeighted500</th>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.863034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifierUnderSampling</th>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>4.923675</td>\n",
       "      <td>0.839697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifierUpperSampling</th>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>4.923675</td>\n",
       "      <td>0.839697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>1.114752</td>\n",
       "      <td>0.961903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Precision  Recall  F1-score   LogLoss  \\\n",
       "Model                                                                        \n",
       "Decision Tree Classifier              0.942857   0.825  0.880000  0.060284   \n",
       "DecisionTreeClassifier                0.980392   1.000  0.990099  0.461171   \n",
       "Random Forest Classifier              0.979592   0.960  0.969697  1.114752   \n",
       "Random Forest ClassifierWeighted      0.804348   0.925  0.860465  0.018085   \n",
       "Random Forest ClassifierWeighted22    0.823529   0.925  0.860465  0.060284   \n",
       "Random Forest ClassifierWeighted500   0.804348   0.925  0.860465  0.060284   \n",
       "RandomForestClassifierUnderSampling   0.782609   0.900  0.837209  4.923675   \n",
       "RandomForestClassifierUpperSampling   0.782609   0.900  0.837209  4.923675   \n",
       "XGBClassifier                         0.979592   0.960  0.969697  1.114752   \n",
       "\n",
       "                                     MeanOurMetrics  \n",
       "Model                                                \n",
       "Decision Tree Classifier                   0.882409  \n",
       "DecisionTreeClassifier                     0.987512  \n",
       "Random Forest Classifier                   0.961903  \n",
       "Random Forest ClassifierWeighted           0.863034  \n",
       "Random Forest ClassifierWeighted22         0.863034  \n",
       "Random Forest ClassifierWeighted500        0.863034  \n",
       "RandomForestClassifierUnderSampling        0.839697  \n",
       "RandomForestClassifierUpperSampling        0.839697  \n",
       "XGBClassifier                              0.961903  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Les meilleurs rsultat\")\n",
    "dfresult.groupby(['Model'])['Precision','Recall','F1-score','LogLoss','MeanOurMetrics'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e794338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les pire rsultat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarah\\AppData\\Local\\Temp\\ipykernel_2988\\2101499374.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  dfresult.groupby(['Model'])['Precision','Recall','F1-score','LogLoss','MeanOurMetrics'].min()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classifier</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.013564</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.113372</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.013564</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.019592</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest ClassifierWeighted</th>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.863034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest ClassifierWeighted22</th>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest ClassifierWeighted500</th>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifierUnderSampling</th>\n",
       "      <td>0.010398</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.020544</td>\n",
       "      <td>0.021099</td>\n",
       "      <td>0.241480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifierUpperSampling</th>\n",
       "      <td>0.010398</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.020544</td>\n",
       "      <td>0.021099</td>\n",
       "      <td>0.241480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.162791</td>\n",
       "      <td>0.013564</td>\n",
       "      <td>0.162913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Precision  Recall  F1-score   LogLoss  \\\n",
       "Model                                                                        \n",
       "Decision Tree Classifier              0.500000   0.000  0.090909  0.013564   \n",
       "DecisionTreeClassifier                0.113372   0.000  0.090909  0.013564   \n",
       "Random Forest Classifier              0.566667   0.000  0.484848  0.019592   \n",
       "Random Forest ClassifierWeighted      0.804348   0.925  0.860465  0.018085   \n",
       "Random Forest ClassifierWeighted22    0.653846   0.000  0.491228  0.018085   \n",
       "Random Forest ClassifierWeighted500   0.629630   0.000  0.482759  0.018085   \n",
       "RandomForestClassifierUnderSampling   0.010398   0.400  0.020544  0.021099   \n",
       "RandomForestClassifierUpperSampling   0.010398   0.400  0.020544  0.021099   \n",
       "XGBClassifier                         0.152174   0.175  0.162791  0.013564   \n",
       "\n",
       "                                     MeanOurMetrics  \n",
       "Model                                                \n",
       "Decision Tree Classifier                   0.000000  \n",
       "DecisionTreeClassifier                     0.000000  \n",
       "Random Forest Classifier                   0.000000  \n",
       "Random Forest ClassifierWeighted           0.863034  \n",
       "Random Forest ClassifierWeighted22         0.000000  \n",
       "Random Forest ClassifierWeighted500        0.000000  \n",
       "RandomForestClassifierUnderSampling        0.241480  \n",
       "RandomForestClassifierUpperSampling        0.241480  \n",
       "XGBClassifier                              0.162913  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Les pire rsultat\")\n",
    "dfresult.groupby(['Model'])['Precision','Recall','F1-score','LogLoss','MeanOurMetrics'].min()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
