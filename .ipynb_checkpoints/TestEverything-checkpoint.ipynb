{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efcbf836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import resample\n",
    "import datetime as dt\n",
    "from math import ceil, sqrt\n",
    "from Utils import *\n",
    "pd.set_option('max_colwidth', None)\n",
    "from EvaluationMetric import *\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c99676e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mi_scores(X, y):\n",
    "    mi_scores = mutual_info_classif(X, y)\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eab429b",
   "metadata": {},
   "source": [
    "Put the data here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73a9d70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def_feature = pd.read_csv(\"input/Xente_Variable_Definitions.csv\")\n",
    "raw_data = pd.read_csv(\"input/training.csv\")\n",
    "X_test = pd.read_csv(\"input/test.csv\")\n",
    "sample_submission = pd.read_csv(\"input/sample_submission.csv\")\n",
    "\n",
    "#attribut initialization\n",
    "cols_unique_value = [] #Will be droped\n",
    "for col in raw_data.columns : \n",
    "    if len(raw_data[col].unique()) == 1 :\n",
    "        cols_unique_value.append(col)\n",
    "\n",
    "medium_cardianlity_cols = [\"ProductId\"]\n",
    "\n",
    "#Data transformation\n",
    "raw_data['TransactionStartTime'] = pd.to_datetime(raw_data['TransactionStartTime'])\n",
    "X_test['TransactionStartTime'] = pd.to_datetime(X_test['TransactionStartTime'])\n",
    "\n",
    "#Data cleaning\n",
    "data = raw_data.copy()\n",
    "data = data.dropna(axis=0) #Drop observations/rows with missing values\n",
    "X_test=X_test.dropna(axis=0)\n",
    "data.drop(cols_unique_value, axis=1, inplace=True)\n",
    "X_test.drop(cols_unique_value, axis=1, inplace=True)\n",
    "\n",
    "#Prepare index for the submission\n",
    "index_val = list(X_test.TransactionId.values.tolist())\n",
    "\n",
    "#Set the df index to the Transction Id\n",
    "data = transactioId_to_index(data)\n",
    "X_test = transactioId_to_index(X_test)\n",
    "\n",
    "#Adding data\n",
    "data = adding_date_col(data, 'TransactionStartTime')\n",
    "X_test = adding_date_col(X_test, 'TransactionStartTime')\n",
    "\n",
    "\n",
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "low_cardinality_cols = [cname for cname in data.columns if data[cname].nunique() < 15 and \n",
    "                        data[cname].dtype == \"object\"]\n",
    "low_cardinality_cols.append('PricingStrategy')\n",
    "\n",
    "#transform columns BatchId_54 to number\n",
    "\n",
    "l_col_str = [\"BatchId\", \"AccountId\", \"SubscriptionId\", \"CustomerId\", \"ProviderId\", \"ProductId\", \"ChannelId\"]\n",
    "for col in l_col_str:\n",
    "    data[['dc', 'new_col']] = data[col].str.split(\"_\", expand = True)\n",
    "    data.drop(['dc',col], inplace=True, axis=1)\n",
    "    data.rename(columns={\"new_col\": col}, inplace=True)\n",
    "    data[col] = data[col].astype('int')\n",
    "    X_test[['dc', 'new_col']] = X_test[col].str.split(\"_\", expand = True)\n",
    "    X_test.drop(['dc',col], inplace=True, axis=1)\n",
    "    X_test.rename(columns={\"new_col\": col}, inplace=True)\n",
    "    X_test[col] = X_test[col].astype('int')\n",
    "data['PricingStrategy'] = data['PricingStrategy'].astype('int')\n",
    "X_test['PricingStrategy'] = X_test['PricingStrategy'].astype('int')\n",
    "data['Value'] = data['Value'].astype('float')\n",
    "X_test['Value'] = X_test['Value'].astype('float')\n",
    "\n",
    "X_test['PricingStrategy'] = X_test['PricingStrategy'].astype('str')\n",
    "data['PricingStrategy'] = data['PricingStrategy'].astype('str')\n",
    "\n",
    "#Data splitting\n",
    "y = data.FraudResult #The target label\n",
    "X = data.copy()\n",
    "X.drop(['FraudResult'], axis=1, inplace=True) #Only the features data\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "cat_cols = [col for col in X.columns if X[col].dtype == \"object\"]#liste of obejct columns\n",
    "cat_cols.append(\"PricingStrategy\")#pcq mm si c'est un chiffre il faut le considérer comme une catégorie\n",
    "\n",
    "#print(describe)\n",
    "\n",
    "\n",
    "#low_cardinality_cols=[\"ProviderId\", \"ProductCategory\", \"ChannelId\", \"PricingStrategy\"] \n",
    "#train_X[low_cardinality_cols] = train_X[low_cardinality_cols].astype(str) \n",
    "#val_X[low_cardinality_cols] = val_X[low_cardinality_cols].astype(str) \n",
    "\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(train_X[low_cardinality_cols]))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(val_X[low_cardinality_cols]))\n",
    "OH_cols_test = pd.DataFrame(OH_encoder.transform(X_test[low_cardinality_cols]))\n",
    "OH_cols_train.columns = OH_encoder.get_feature_names_out()\n",
    "OH_cols_valid.columns = OH_encoder.get_feature_names_out()\n",
    "OH_cols_test.columns = OH_encoder.get_feature_names_out()\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_train.index = train_X.index\n",
    "OH_cols_valid.index = val_X.index\n",
    "OH_cols_test.index = X_test.index\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train = train_X.drop(low_cardinality_cols, axis=1)\n",
    "num_X_valid = val_X.drop(low_cardinality_cols, axis=1)\n",
    "num_X_test = X_test.drop(low_cardinality_cols, axis=1)\n",
    "\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
    "OH_X_test = pd.concat([num_X_test, OH_cols_test], axis=1)\n",
    "\n",
    "# Problème de string\n",
    "OH_X_train.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_valid.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_test.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_train.columns = OH_X_train.columns.astype(str)\n",
    "OH_X_valid.columns = OH_X_valid.columns.astype(str)\n",
    "OH_X_test.columns = OH_X_test.columns.astype(str)\n",
    "\n",
    "train_X = OH_X_train\n",
    "val_X = OH_X_valid\n",
    "test_X = OH_X_test\n",
    "X_entier = pd.concat([train_X, val_X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81e43b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>La basemax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-06 20:37:01.701978</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>0.857566</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>[0.661016949]</td>\n",
       "      <td>0.857900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>La basen_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-06 20:37:02.891559</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.019592</td>\n",
       "      <td>0.848262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909]</td>\n",
       "      <td>[0.649122807]</td>\n",
       "      <td>0.848830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>La basescale_pos_weight = 22</td>\n",
       "      <td>2023-05-06 20:37:04.316049</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.881747</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354]</td>\n",
       "      <td>[0.676923076]</td>\n",
       "      <td>0.882152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>La baseupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-06 20:37:06.774426</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.022606</td>\n",
       "      <td>0.829975</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.637168141]</td>\n",
       "      <td>0.830880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>La baseundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-06 20:37:09.025865</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.022606</td>\n",
       "      <td>0.829975</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.549019607]</td>\n",
       "      <td>[0.48076923]</td>\n",
       "      <td>0.830880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Model  \\\n",
       "0             Decision Tree Classifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  RandomForestClassifierUpperSampling   \n",
       "4  RandomForestClassifierUnderSampling   \n",
       "\n",
       "                                                 Description  \\\n",
       "0              La basemax_leaf_nodes : 6 + with date columns   \n",
       "1                         La basen_estimators : 36 + Entropy   \n",
       "2                               La basescale_pos_weight = 22   \n",
       "3     La baseupsampled, n_estimators=36, criterion = entropy   \n",
       "4  La baseundersampled, n_estimators=36, criterion = entropy   \n",
       "\n",
       "                        Date  Precision  Recall  F1-score   LogLoss       Mcc  \\\n",
       "0 2023-05-06 20:37:01.701978   0.891892   0.825  0.857143  0.016578  0.857566   \n",
       "1 2023-05-06 20:37:02.891559   0.800000   0.900  0.847059  0.019592  0.848262   \n",
       "2 2023-05-06 20:37:04.316049   0.840909   0.925  0.880952  0.015071  0.881747   \n",
       "3 2023-05-06 20:37:06.774426   0.765957   0.900  0.827586  0.022606  0.829975   \n",
       "4 2023-05-06 20:37:09.025865   0.765957   0.900  0.827586  0.022606  0.829975   \n",
       "\n",
       "   PublicScore  PrivateScore OldPublicScore OldPrivateScore  MeanOurMetrics  \n",
       "0          NaN           NaN  [0.666666666]   [0.661016949]        0.857900  \n",
       "1          NaN           NaN   [0.69090909]   [0.649122807]        0.848830  \n",
       "2          NaN           NaN  [0.677419354]   [0.676923076]        0.882152  \n",
       "3          NaN           NaN  [0.678571428]   [0.637168141]        0.830880  \n",
       "4          NaN           NaN  [0.549019607]    [0.48076923]        0.830880  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#descriptiontous = 'En suprimant les données avec le plus petit MI'\n",
    "descriptiontous = 'La base'\n",
    "\n",
    "res = []\n",
    "\n",
    "model1 = DecisionTreeClassifier(max_leaf_nodes= 6, random_state=1)\n",
    "model1.fit(train_X, train_y)\n",
    "preds_val1 = model1.predict(val_X)\n",
    "model_test1 = model1.predict(test_X)\n",
    "description = descriptiontous+\"max_leaf_nodes : 6 + with date columns\"\n",
    "metrics1 = listmetrics(val_y, preds_val1, \"Decision Tree Classifier\", description)\n",
    "m1Public = [0.666666666]\n",
    "m1Private = [0.661016949]\n",
    "res.append(metrics1)\n",
    "df1 = getscoreforcsv(index_val, model_test1, name_file = \"TreeClass5leaf.csv\")\n",
    "\n",
    "\n",
    "model2 = RandomForestClassifier(n_estimators=36, criterion = 'entropy', random_state=1)\n",
    "model2.fit(train_X, train_y)\n",
    "preds_val2 = model2.predict(val_X)\n",
    "model_test2 = model2.predict(test_X)\n",
    "description = descriptiontous+\"n_estimators : 36 + Entropy\"\n",
    "metrics2 = listmetrics(val_y, preds_val2, \"Random Forest Classifier\", description)\n",
    "m2Public = [0.690909090]\n",
    "m2Private = [0.649122807]\n",
    "res.append(metrics2)\n",
    "df2 = getscoreforcsv(index_val, model_test2, name_file = \"RandomForestN36Entropy.csv\")\n",
    "\n",
    "model2 = XGBClassifier(scale_pos_weight=22, random_state=1)\n",
    "model2.fit(train_X, train_y)\n",
    "preds_val2 = model2.predict(val_X)\n",
    "model_test2 = model2.predict(test_X)\n",
    "description = descriptiontous+\"scale_pos_weight = 22\"\n",
    "metrics2 = listmetrics(val_y, preds_val2, \"XGBClassifier\", description)\n",
    "m3Public = [0.677419354]\n",
    "m3Private = [0.676923076]\n",
    "res.append(metrics2)\n",
    "df2 = getscoreforcsv(index_val, model_test2, name_file = \"XGBClassifierW22.csv\")\n",
    "\n",
    "#oversamplesimple\n",
    "X_con = pd.concat([train_X, train_y], axis=1) \n",
    "not_fraud = X_con[X_con.FraudResult==0]\n",
    "fraud = X_con[X_con.FraudResult==1]\n",
    "fraud_upsampled = resample(fraud, replace=True, n_samples=len(not_fraud), # match number in majority class\n",
    "                          random_state=1) # reproducible results\n",
    "upsampled = pd.concat([not_fraud, fraud_upsampled])\n",
    "train_y_over_sampled = upsampled.FraudResult\n",
    "train_X_over_sampled = upsampled.drop('FraudResult', axis=1)\n",
    "upsampledmodel = RandomForestClassifier(n_estimators=36, criterion = 'entropy', random_state=1)\n",
    "upsampledmodel.fit(train_X_over_sampled, train_y_over_sampled)\n",
    "upsampled_pred = upsampledmodel.predict(val_X)\n",
    "model_test = upsampledmodel.predict(OH_X_test)\n",
    "description = descriptiontous+\"upsampled, n_estimators=36, criterion = entropy\"\n",
    "metrics = listmetrics(val_y, upsampled_pred, \"RandomForestClassifierUpperSampling\", description)\n",
    "m4Public = [0.678571428]\n",
    "m4Private = [0.637168141]\n",
    "res.append(metrics)\n",
    "df = getscoreforcsv(index_val, model_test, name_file = \"RandomForestClassifierUpSample.csv\")\n",
    "\n",
    "#Undersampling\n",
    "not_fraud_downsampled  = resample(not_fraud, replace=False, n_samples=len(fraud), # match number in minority  class\n",
    "                          random_state=1) # reproducible results\n",
    "downsampled  = pd.concat([not_fraud_downsampled , fraud])\n",
    "train_y_undersampled = downsampled.FraudResult\n",
    "train_X_undersampled = downsampled.drop('FraudResult', axis=1)\n",
    "undersampled = RandomForestClassifier(n_estimators=36, criterion = 'entropy', random_state=1)\n",
    "undersampled.fit(train_X_over_sampled, train_y_over_sampled)\n",
    "undersampled_pred = undersampled.predict(val_X)\n",
    "model_test = undersampled.predict(OH_X_test)\n",
    "description = descriptiontous+\"undersampled, n_estimators=36, criterion = entropy\"\n",
    "metrics = listmetrics(val_y, undersampled_pred, \"RandomForestClassifierUnderSampling\", description)\n",
    "m5Public = [0.549019607]\n",
    "m5Private = [0.480769230]\n",
    "res.append(metrics)\n",
    "df = getscoreforcsv(index_val, model_test, name_file = \"RandomForestClassifierUndersampled.csv\")\n",
    "\n",
    "\n",
    "dfres = listmetricsintodf(res)\n",
    "dfres[\"OldPublicScore\"] = [m1Public, m2Public, m3Public, m4Public, m5Public]\n",
    "dfres[\"OldPrivateScore\"] = [m1Private, m2Private, m3Private, m4Private, m5Private]\n",
    "dfres[\"MeanOurMetrics\"] = dfres[['Precision', 'Recall','F1-score','Mcc']].mean(axis=1)\n",
    "dfres.to_csv('output/resultatsTestEverything.csv', index=False) \n",
    "dfres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "46c1db32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supprimer les MI trop faible\n",
    "def_feature = pd.read_csv(\"input/Xente_Variable_Definitions.csv\")\n",
    "raw_data = pd.read_csv(\"input/training.csv\")\n",
    "X_test = pd.read_csv(\"input/test.csv\")\n",
    "sample_submission = pd.read_csv(\"input/sample_submission.csv\")\n",
    "\n",
    "#attribut initialization\n",
    "cols_unique_value = [] #Will be droped\n",
    "for col in raw_data.columns : \n",
    "    if len(raw_data[col].unique()) == 1 :\n",
    "        cols_unique_value.append(col)\n",
    "\n",
    "medium_cardianlity_cols = [\"ProductId\"]\n",
    "\n",
    "#Data transformation\n",
    "raw_data['TransactionStartTime'] = pd.to_datetime(raw_data['TransactionStartTime'])\n",
    "X_test['TransactionStartTime'] = pd.to_datetime(X_test['TransactionStartTime'])\n",
    "\n",
    "#Data cleaning\n",
    "data = raw_data.copy()\n",
    "data = data.dropna(axis=0) #Drop observations/rows with missing values\n",
    "X_test=X_test.dropna(axis=0)\n",
    "data.drop(cols_unique_value, axis=1, inplace=True)\n",
    "X_test.drop(cols_unique_value, axis=1, inplace=True)\n",
    "\n",
    "#Prepare index for the submission\n",
    "index_val = list(X_test.TransactionId.values.tolist())\n",
    "\n",
    "#Set the df index to the Transction Id\n",
    "data = transactioId_to_index(data)\n",
    "X_test = transactioId_to_index(X_test)\n",
    "\n",
    "#Adding data\n",
    "data = adding_date_col(data, 'TransactionStartTime')\n",
    "X_test = adding_date_col(X_test, 'TransactionStartTime')\n",
    "\n",
    "\n",
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "low_cardinality_cols = [cname for cname in data.columns if data[cname].nunique() < 15 and \n",
    "                        data[cname].dtype == \"object\"]\n",
    "low_cardinality_cols.append('PricingStrategy')\n",
    "\n",
    "#transform columns BatchId_54 to number\n",
    "\n",
    "l_col_str = [\"BatchId\", \"AccountId\", \"SubscriptionId\", \"CustomerId\", \"ProviderId\", \"ProductId\", \"ChannelId\"]\n",
    "for col in l_col_str:\n",
    "    data[['dc', 'new_col']] = data[col].str.split(\"_\", expand = True)\n",
    "    data.drop(['dc',col], inplace=True, axis=1)\n",
    "    data.rename(columns={\"new_col\": col}, inplace=True)\n",
    "    data[col] = data[col].astype('int')\n",
    "    X_test[['dc', 'new_col']] = X_test[col].str.split(\"_\", expand = True)\n",
    "    X_test.drop(['dc',col], inplace=True, axis=1)\n",
    "    X_test.rename(columns={\"new_col\": col}, inplace=True)\n",
    "    X_test[col] = X_test[col].astype('int')\n",
    "data['PricingStrategy'] = data['PricingStrategy'].astype('int')\n",
    "X_test['PricingStrategy'] = X_test['PricingStrategy'].astype('int')\n",
    "data['Value'] = data['Value'].astype('float')\n",
    "X_test['Value'] = X_test['Value'].astype('float')\n",
    "\n",
    "X_test['PricingStrategy'] = X_test['PricingStrategy'].astype('str')\n",
    "data['PricingStrategy'] = data['PricingStrategy'].astype('str')\n",
    "\n",
    "#Data splitting\n",
    "y = data.FraudResult #The target label\n",
    "X = data.copy()\n",
    "X.drop(['FraudResult'], axis=1, inplace=True) #Only the features data\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "cat_cols = [col for col in X.columns if X[col].dtype == \"object\"]#liste of obejct columns\n",
    "cat_cols.append(\"PricingStrategy\")#pcq mm si c'est un chiffre il faut le considérer comme une catégorie\n",
    "\n",
    "#print(describe)\n",
    "\n",
    "\n",
    "#low_cardinality_cols=[\"ProviderId\", \"ProductCategory\", \"ChannelId\", \"PricingStrategy\"] \n",
    "#train_X[low_cardinality_cols] = train_X[low_cardinality_cols].astype(str) \n",
    "#val_X[low_cardinality_cols] = val_X[low_cardinality_cols].astype(str) \n",
    "\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(train_X[low_cardinality_cols]))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(val_X[low_cardinality_cols]))\n",
    "OH_cols_test = pd.DataFrame(OH_encoder.transform(X_test[low_cardinality_cols]))\n",
    "OH_cols_train.columns = OH_encoder.get_feature_names_out()\n",
    "OH_cols_valid.columns = OH_encoder.get_feature_names_out()\n",
    "OH_cols_test.columns = OH_encoder.get_feature_names_out()\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_train.index = train_X.index\n",
    "OH_cols_valid.index = val_X.index\n",
    "OH_cols_test.index = X_test.index\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train = train_X.drop(low_cardinality_cols, axis=1)\n",
    "num_X_valid = val_X.drop(low_cardinality_cols, axis=1)\n",
    "num_X_test = X_test.drop(low_cardinality_cols, axis=1)\n",
    "\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
    "OH_X_test = pd.concat([num_X_test, OH_cols_test], axis=1)\n",
    "\n",
    "# Problème de string\n",
    "OH_X_train.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_valid.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_test.drop(['TransactionStartTime'], inplace=True, axis=1)\n",
    "OH_X_train.columns = OH_X_train.columns.astype(str)\n",
    "OH_X_valid.columns = OH_X_valid.columns.astype(str)\n",
    "OH_X_test.columns = OH_X_test.columns.astype(str)\n",
    "\n",
    "train_X = OH_X_train\n",
    "val_X = OH_X_valid\n",
    "test_X = OH_X_test\n",
    "X_entier = pd.concat([train_X, val_X])\n",
    "\n",
    "mi_scores = make_mi_scores(X_entier , y)\n",
    "\n",
    "verylowMI = list(mi_scores[mi_scores<0.0001].index)\n",
    "lowMI = list(mi_scores[(mi_scores>=0.0001)&(mi_scores<0.001)].index)\n",
    "mediumMI = list(mi_scores[(mi_scores>=0.001)&(mi_scores<0.01)].index)\n",
    "highMI = list(mi_scores[mi_scores>=0.01].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "df174abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>Sans veryLow MImax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-06 21:06:44.038023</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.013564</td>\n",
       "      <td>0.881780</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>[0.661016949]</td>\n",
       "      <td>0.882409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Sans veryLow MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-06 21:06:45.137578</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.864198</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>0.864033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909]</td>\n",
       "      <td>[0.649122807]</td>\n",
       "      <td>0.864222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Sans veryLow MIscale_pos_weight = 22</td>\n",
       "      <td>2023-05-06 21:06:46.430420</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.867470</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>0.867809</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354]</td>\n",
       "      <td>[0.676923076]</td>\n",
       "      <td>0.868122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>Sans veryLow MIupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-06 21:06:48.589144</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.857869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.637168141]</td>\n",
       "      <td>0.858298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>Sans veryLow MIundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-06 21:06:50.632936</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.857869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.549019607]</td>\n",
       "      <td>[0.48076923]</td>\n",
       "      <td>0.858298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Model  \\\n",
       "0             Decision Tree Classifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  RandomForestClassifierUpperSampling   \n",
       "4  RandomForestClassifierUnderSampling   \n",
       "\n",
       "                                                         Description  \\\n",
       "0              Sans veryLow MImax_leaf_nodes : 6 + with date columns   \n",
       "1                         Sans veryLow MIn_estimators : 36 + Entropy   \n",
       "2                               Sans veryLow MIscale_pos_weight = 22   \n",
       "3     Sans veryLow MIupsampled, n_estimators=36, criterion = entropy   \n",
       "4  Sans veryLow MIundersampled, n_estimators=36, criterion = entropy   \n",
       "\n",
       "                        Date  Precision  Recall  F1-score   LogLoss       Mcc  \\\n",
       "0 2023-05-06 21:06:44.038023   0.942857   0.825  0.880000  0.013564  0.881780   \n",
       "1 2023-05-06 21:06:45.137578   0.853659   0.875  0.864198  0.016578  0.864033   \n",
       "2 2023-05-06 21:06:46.430420   0.837209   0.900  0.867470  0.016578  0.867809   \n",
       "3 2023-05-06 21:06:48.589144   0.818182   0.900  0.857143  0.018085  0.857869   \n",
       "4 2023-05-06 21:06:50.632936   0.818182   0.900  0.857143  0.018085  0.857869   \n",
       "\n",
       "   PublicScore  PrivateScore OldPublicScore OldPrivateScore  MeanOurMetrics  \n",
       "0          NaN           NaN  [0.666666666]   [0.661016949]        0.882409  \n",
       "1          NaN           NaN   [0.69090909]   [0.649122807]        0.864222  \n",
       "2          NaN           NaN  [0.677419354]   [0.676923076]        0.868122  \n",
       "3          NaN           NaN  [0.678571428]   [0.637168141]        0.858298  \n",
       "4          NaN           NaN  [0.549019607]    [0.48076923]        0.858298  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptiontous = 'Sans veryLow MI'\n",
    "\n",
    "train_X.drop(verylowMI, inplace=True, axis=1)\n",
    "val_X.drop(verylowMI, inplace=True, axis=1)\n",
    "test_X.drop(verylowMI, inplace=True, axis=1)\n",
    "X_entier.drop(verylowMI, inplace=True, axis=1)\n",
    "res = []\n",
    "\n",
    "model1 = DecisionTreeClassifier(max_leaf_nodes= 6, random_state=1)\n",
    "model1.fit(train_X, train_y)\n",
    "preds_val1 = model1.predict(val_X)\n",
    "model_test1 = model1.predict(test_X)\n",
    "description = descriptiontous+\"max_leaf_nodes : 6 + with date columns\"\n",
    "metrics1 = listmetrics(val_y, preds_val1, \"Decision Tree Classifier\", description)\n",
    "m1Public = [0.666666666, 0.666666666]\n",
    "m1Private = [0.661016949, 0.661016949]\n",
    "res.append(metrics1)\n",
    "df1 = getscoreforcsv(index_val, model_test1, name_file = \"TreeClass5leaf.csv\")\n",
    "\n",
    "\n",
    "model2 = RandomForestClassifier(n_estimators=36, criterion = 'entropy', random_state=1)\n",
    "model2.fit(train_X, train_y)\n",
    "preds_val2 = model2.predict(val_X)\n",
    "model_test2 = model2.predict(test_X)\n",
    "description = descriptiontous+\"n_estimators : 36 + Entropy\"\n",
    "metrics2 = listmetrics(val_y, preds_val2, \"Random Forest Classifier\", description)\n",
    "m2Public = [0.690909090, 0.666666666]\n",
    "m2Private = [0.649122807, 0.649122807\n",
    "]\n",
    "res.append(metrics2)\n",
    "df2 = getscoreforcsv(index_val, model_test2, name_file = \"RandomForestN36Entropy.csv\")\n",
    "\n",
    "##################ICi donne un 0.71 de scrore !!! mtn comprendre pq en diminuant les feature si bon score mais que pour lui !############\n",
    "\n",
    "model2 = XGBClassifier(scale_pos_weight=22, random_state=1)\n",
    "model2.fit(train_X, train_y)\n",
    "preds_val2 = model2.predict(val_X)\n",
    "model_test2 = model2.predict(test_X)\n",
    "description = descriptiontous+\"scale_pos_weight = 22\"\n",
    "metrics2 = listmetrics(val_y, preds_val2, \"XGBClassifier\", description)\n",
    "m3Public = [0.677419354, 0.711864406]\n",
    "m3Private = [0.676923076,  0.715447154]\n",
    "res.append(metrics2)\n",
    "df2 = getscoreforcsv(index_val, model_test2, name_file = \"XGBClassifierW22.csv\")\n",
    "\n",
    "#oversamplesimple\n",
    "X_con = pd.concat([train_X, train_y], axis=1) \n",
    "not_fraud = X_con[X_con.FraudResult==0]\n",
    "fraud = X_con[X_con.FraudResult==1]\n",
    "fraud_upsampled = resample(fraud, replace=True, n_samples=len(not_fraud), # match number in majority class\n",
    "                          random_state=1) # reproducible results\n",
    "upsampled = pd.concat([not_fraud, fraud_upsampled])\n",
    "train_y_over_sampled = upsampled.FraudResult\n",
    "train_X_over_sampled = upsampled.drop('FraudResult', axis=1)\n",
    "upsampledmodel = RandomForestClassifier(n_estimators=36, criterion = 'entropy', random_state=1)\n",
    "upsampledmodel.fit(train_X_over_sampled, train_y_over_sampled)\n",
    "upsampled_pred = upsampledmodel.predict(val_X)\n",
    "model_test = upsampledmodel.predict(OH_X_test)\n",
    "description = descriptiontous+\"upsampled, n_estimators=36, criterion = entropy\"\n",
    "metrics = listmetrics(val_y, upsampled_pred, \"RandomForestClassifierUpperSampling\", description)\n",
    "m4Public = [0.678571428, 0.642857142]\n",
    "m4Private = [0.637168141, 0.620689655]\n",
    "res.append(metrics)\n",
    "df = getscoreforcsv(index_val, model_test, name_file = \"RandomForestClassifierUpSample.csv\")\n",
    "\n",
    "#Undersampling\n",
    "not_fraud_downsampled  = resample(not_fraud, replace=False, n_samples=len(fraud), # match number in minority  class\n",
    "                          random_state=1) # reproducible results\n",
    "downsampled  = pd.concat([not_fraud_downsampled , fraud])\n",
    "train_y_undersampled = downsampled.FraudResult\n",
    "train_X_undersampled = downsampled.drop('FraudResult', axis=1)\n",
    "undersampled = RandomForestClassifier(n_estimators=36, criterion = 'entropy', random_state=1)\n",
    "undersampled.fit(train_X_over_sampled, train_y_over_sampled)\n",
    "undersampled_pred = undersampled.predict(val_X)\n",
    "model_test = undersampled.predict(OH_X_test)\n",
    "description = descriptiontous+\"undersampled, n_estimators=36, criterion = entropy\"\n",
    "metrics = listmetrics(val_y, undersampled_pred, \"RandomForestClassifierUnderSampling\", description)\n",
    "m5Public = [0.549019607, 0.642857142]\n",
    "m5Private = [0.480769230, 0.620689655]\n",
    "res.append(metrics)\n",
    "df = getscoreforcsv(index_val, model_test, name_file = \"RandomForestClassifierUndersampled.csv\")\n",
    "\n",
    "\n",
    "dfres = listmetricsintodf(res)\n",
    "dfres[\"OldPublicScore\"] = [m1Public, m2Public, m3Public, m4Public, m5Public]\n",
    "dfres[\"OldPrivateScore\"] = [m1Private, m2Private, m3Private, m4Private, m5Private]\n",
    "dfres[\"MeanOurMetrics\"] = dfres[['Precision', 'Recall','F1-score','Mcc']].mean(axis=1)\n",
    "dfres.to_csv('output/resultatsTestEverything.csv', mode='a',index=False,header = False) \n",
    "dfres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0235a795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>Sans Low MImax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-06 20:51:23.078874</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.157730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>[0.661016949]</td>\n",
       "      <td>0.199660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Sans Low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-06 20:51:24.053805</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>0.054255</td>\n",
       "      <td>0.490016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909]</td>\n",
       "      <td>[0.649122807]</td>\n",
       "      <td>0.491849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Sans Low MIscale_pos_weight = 22</td>\n",
       "      <td>2023-05-06 20:51:24.981709</td>\n",
       "      <td>0.397059</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.081383</td>\n",
       "      <td>0.516687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354]</td>\n",
       "      <td>[0.676923076]</td>\n",
       "      <td>0.522187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>Sans Low MIupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-06 20:51:27.254243</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.436364</td>\n",
       "      <td>0.093440</td>\n",
       "      <td>0.452385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.637168141]</td>\n",
       "      <td>0.457902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>Sans Low MIundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-06 20:51:29.419018</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.436364</td>\n",
       "      <td>0.093440</td>\n",
       "      <td>0.452385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.549019607]</td>\n",
       "      <td>[0.48076923]</td>\n",
       "      <td>0.457902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Model  \\\n",
       "0             Decision Tree Classifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  RandomForestClassifierUpperSampling   \n",
       "4  RandomForestClassifierUnderSampling   \n",
       "\n",
       "                                                     Description  \\\n",
       "0              Sans Low MImax_leaf_nodes : 6 + with date columns   \n",
       "1                         Sans Low MIn_estimators : 36 + Entropy   \n",
       "2                               Sans Low MIscale_pos_weight = 22   \n",
       "3     Sans Low MIupsampled, n_estimators=36, criterion = entropy   \n",
       "4  Sans Low MIundersampled, n_estimators=36, criterion = entropy   \n",
       "\n",
       "                        Date  Precision  Recall  F1-score   LogLoss       Mcc  \\\n",
       "0 2023-05-06 20:51:23.078874   0.500000   0.050  0.090909  0.060284  0.157730   \n",
       "1 2023-05-06 20:51:24.053805   0.566667   0.425  0.485714  0.054255  0.490016   \n",
       "2 2023-05-06 20:51:24.981709   0.397059   0.675  0.500000  0.081383  0.516687   \n",
       "3 2023-05-06 20:51:27.254243   0.342857   0.600  0.436364  0.093440  0.452385   \n",
       "4 2023-05-06 20:51:29.419018   0.342857   0.600  0.436364  0.093440  0.452385   \n",
       "\n",
       "   PublicScore  PrivateScore OldPublicScore OldPrivateScore  MeanOurMetrics  \n",
       "0          NaN           NaN  [0.666666666]   [0.661016949]        0.199660  \n",
       "1          NaN           NaN   [0.69090909]   [0.649122807]        0.491849  \n",
       "2          NaN           NaN  [0.677419354]   [0.676923076]        0.522187  \n",
       "3          NaN           NaN  [0.678571428]   [0.637168141]        0.457902  \n",
       "4          NaN           NaN  [0.549019607]    [0.48076923]        0.457902  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptiontous = 'Sans Low MI'\n",
    "\n",
    "train_X.drop(lowMI, inplace=True, axis=1)\n",
    "val_X.drop(lowMI, inplace=True, axis=1)\n",
    "test_X.drop(lowMI, inplace=True, axis=1)\n",
    "X_entier.drop(lowMI, inplace=True, axis=1)\n",
    "res = []\n",
    "\n",
    "model1 = DecisionTreeClassifier(max_leaf_nodes= 6, random_state=1)\n",
    "model1.fit(train_X, train_y)\n",
    "preds_val1 = model1.predict(val_X)\n",
    "model_test1 = model1.predict(test_X)\n",
    "description = descriptiontous+\"max_leaf_nodes : 6 + with date columns\"\n",
    "metrics1 = listmetrics(val_y, preds_val1, \"Decision Tree Classifier\", description)\n",
    "m1Public = [0.666666666]\n",
    "m1Private = [0.661016949]\n",
    "res.append(metrics1)\n",
    "df1 = getscoreforcsv(index_val, model_test1, name_file = \"TreeClass5leaf.csv\")\n",
    "\n",
    "\n",
    "model2 = RandomForestClassifier(n_estimators=36, criterion = 'entropy', random_state=1)\n",
    "model2.fit(train_X, train_y)\n",
    "preds_val2 = model2.predict(val_X)\n",
    "model_test2 = model2.predict(test_X)\n",
    "description = descriptiontous+\"n_estimators : 36 + Entropy\"\n",
    "metrics2 = listmetrics(val_y, preds_val2, \"Random Forest Classifier\", description)\n",
    "m2Public = [0.690909090]\n",
    "m2Private = [0.649122807]\n",
    "res.append(metrics2)\n",
    "df2 = getscoreforcsv(index_val, model_test2, name_file = \"RandomForestN36Entropy.csv\")\n",
    "\n",
    "model2 = XGBClassifier(scale_pos_weight=22, random_state=1)\n",
    "model2.fit(train_X, train_y)\n",
    "preds_val2 = model2.predict(val_X)\n",
    "model_test2 = model2.predict(test_X)\n",
    "description = descriptiontous+\"scale_pos_weight = 22\"\n",
    "metrics2 = listmetrics(val_y, preds_val2, \"XGBClassifier\", description)\n",
    "m3Public = [0.677419354]\n",
    "m3Private = [0.676923076]\n",
    "res.append(metrics2)\n",
    "df2 = getscoreforcsv(index_val, model_test2, name_file = \"XGBClassifierW22.csv\")\n",
    "\n",
    "#oversamplesimple\n",
    "X_con = pd.concat([train_X, train_y], axis=1) \n",
    "not_fraud = X_con[X_con.FraudResult==0]\n",
    "fraud = X_con[X_con.FraudResult==1]\n",
    "fraud_upsampled = resample(fraud, replace=True, n_samples=len(not_fraud), # match number in majority class\n",
    "                          random_state=1) # reproducible results\n",
    "upsampled = pd.concat([not_fraud, fraud_upsampled])\n",
    "train_y_over_sampled = upsampled.FraudResult\n",
    "train_X_over_sampled = upsampled.drop('FraudResult', axis=1)\n",
    "upsampledmodel = RandomForestClassifier(n_estimators=36, criterion = 'entropy', random_state=1)\n",
    "upsampledmodel.fit(train_X_over_sampled, train_y_over_sampled)\n",
    "upsampled_pred = upsampledmodel.predict(val_X)\n",
    "model_test = upsampledmodel.predict(OH_X_test)\n",
    "description = descriptiontous+\"upsampled, n_estimators=36, criterion = entropy\"\n",
    "metrics = listmetrics(val_y, upsampled_pred, \"RandomForestClassifierUpperSampling\", description)\n",
    "m4Public = [0.678571428]\n",
    "m4Private = [0.637168141]\n",
    "res.append(metrics)\n",
    "df = getscoreforcsv(index_val, model_test, name_file = \"RandomForestClassifierUpSample.csv\")\n",
    "\n",
    "#Undersampling\n",
    "not_fraud_downsampled  = resample(not_fraud, replace=False, n_samples=len(fraud), # match number in minority  class\n",
    "                          random_state=1) # reproducible results\n",
    "downsampled  = pd.concat([not_fraud_downsampled , fraud])\n",
    "train_y_undersampled = downsampled.FraudResult\n",
    "train_X_undersampled = downsampled.drop('FraudResult', axis=1)\n",
    "undersampled = RandomForestClassifier(n_estimators=36, criterion = 'entropy', random_state=1)\n",
    "undersampled.fit(train_X_over_sampled, train_y_over_sampled)\n",
    "undersampled_pred = undersampled.predict(val_X)\n",
    "model_test = undersampled.predict(OH_X_test)\n",
    "description = descriptiontous+\"undersampled, n_estimators=36, criterion = entropy\"\n",
    "metrics = listmetrics(val_y, undersampled_pred, \"RandomForestClassifierUnderSampling\", description)\n",
    "m5Public = [0.549019607]\n",
    "m5Private = [0.480769230]\n",
    "res.append(metrics)\n",
    "df = getscoreforcsv(index_val, model_test, name_file = \"RandomForestClassifierUndersampled.csv\")\n",
    "\n",
    "\n",
    "dfres = listmetricsintodf(res)\n",
    "dfres[\"OldPublicScore\"] = [m1Public, m2Public, m3Public, m4Public, m5Public]\n",
    "dfres[\"OldPrivateScore\"] = [m1Private, m2Private, m3Private, m4Private, m5Private]\n",
    "dfres[\"MeanOurMetrics\"] = dfres[['Precision', 'Recall','F1-score','Mcc']].mean(axis=1)\n",
    "dfres.to_csv('output/resultatsTestEverything.csv', mode='a',index=False,header = False) \n",
    "dfres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "463dd25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarah\\Documents\\ECAM_non_One_Drive\\Interligence artificiel\\Projet Niko\\AI5L_AILab_FraudDetection\\EvaluationMetric.py:8: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  metric = tp / (tp+fp)\n",
      "C:\\Users\\sarah\\Documents\\ECAM_non_One_Drive\\Interligence artificiel\\Projet Niko\\AI5L_AILab_FraudDetection\\EvaluationMetric.py:20: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = tp / (tp+fp)\n",
      "C:\\Users\\sarah\\Documents\\ECAM_non_One_Drive\\Interligence artificiel\\Projet Niko\\AI5L_AILab_FraudDetection\\EvaluationMetric.py:8: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  metric = tp / (tp+fp)\n",
      "C:\\Users\\sarah\\Documents\\ECAM_non_One_Drive\\Interligence artificiel\\Projet Niko\\AI5L_AILab_FraudDetection\\EvaluationMetric.py:20: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  precision = tp / (tp+fp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n",
      "done\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>Sans mediumMI MImax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-06 20:51:29.534162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>[0.661016949]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Sans mediumMI MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-06 20:51:29.969941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909]</td>\n",
       "      <td>[0.649122807]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Sans mediumMI MIscale_pos_weight = 22</td>\n",
       "      <td>2023-05-06 20:51:30.439168</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.162791</td>\n",
       "      <td>0.108511</td>\n",
       "      <td>0.161685</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354]</td>\n",
       "      <td>[0.676923076]</td>\n",
       "      <td>0.162913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>Sans mediumMI MIupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-06 20:51:31.381130</td>\n",
       "      <td>0.010616</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.020977</td>\n",
       "      <td>4.923675</td>\n",
       "      <td>0.087518</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.637168141]</td>\n",
       "      <td>0.248528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>Sans mediumMI MIundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-06 20:51:32.149516</td>\n",
       "      <td>0.010616</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.020977</td>\n",
       "      <td>4.923675</td>\n",
       "      <td>0.087518</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.549019607]</td>\n",
       "      <td>[0.48076923]</td>\n",
       "      <td>0.248528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Model  \\\n",
       "0             Decision Tree Classifier   \n",
       "1             Random Forest Classifier   \n",
       "2                        XGBClassifier   \n",
       "3  RandomForestClassifierUpperSampling   \n",
       "4  RandomForestClassifierUnderSampling   \n",
       "\n",
       "                                                          Description  \\\n",
       "0              Sans mediumMI MImax_leaf_nodes : 6 + with date columns   \n",
       "1                         Sans mediumMI MIn_estimators : 36 + Entropy   \n",
       "2                               Sans mediumMI MIscale_pos_weight = 22   \n",
       "3     Sans mediumMI MIupsampled, n_estimators=36, criterion = entropy   \n",
       "4  Sans mediumMI MIundersampled, n_estimators=36, criterion = entropy   \n",
       "\n",
       "                        Date  Precision  Recall  F1-score   LogLoss       Mcc  \\\n",
       "0 2023-05-06 20:51:29.534162        NaN   0.000       NaN  0.060284  0.000000   \n",
       "1 2023-05-06 20:51:29.969941        NaN   0.000       NaN  0.060284  0.000000   \n",
       "2 2023-05-06 20:51:30.439168   0.152174   0.175  0.162791  0.108511  0.161685   \n",
       "3 2023-05-06 20:51:31.381130   0.010616   0.875  0.020977  4.923675  0.087518   \n",
       "4 2023-05-06 20:51:32.149516   0.010616   0.875  0.020977  4.923675  0.087518   \n",
       "\n",
       "   PublicScore  PrivateScore OldPublicScore OldPrivateScore  MeanOurMetrics  \n",
       "0          NaN           NaN  [0.666666666]   [0.661016949]        0.000000  \n",
       "1          NaN           NaN   [0.69090909]   [0.649122807]        0.000000  \n",
       "2          NaN           NaN  [0.677419354]   [0.676923076]        0.162913  \n",
       "3          NaN           NaN  [0.678571428]   [0.637168141]        0.248528  \n",
       "4          NaN           NaN  [0.549019607]    [0.48076923]        0.248528  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptiontous = 'Sans mediumMI MI'\n",
    "\n",
    "train_X.drop(mediumMI, inplace=True, axis=1)\n",
    "val_X.drop(mediumMI, inplace=True, axis=1)\n",
    "test_X.drop(mediumMI, inplace=True, axis=1)\n",
    "X_entier.drop(mediumMI, inplace=True, axis=1)\n",
    "res = []\n",
    "\n",
    "model1 = DecisionTreeClassifier(max_leaf_nodes= 6, random_state=1)\n",
    "model1.fit(train_X, train_y)\n",
    "preds_val1 = model1.predict(val_X)\n",
    "model_test1 = model1.predict(test_X)\n",
    "description = descriptiontous+\"max_leaf_nodes : 6 + with date columns\"\n",
    "metrics1 = listmetrics(val_y, preds_val1, \"Decision Tree Classifier\", description)\n",
    "m1Public = [0.666666666]\n",
    "m1Private = [0.661016949]\n",
    "res.append(metrics1)\n",
    "df1 = getscoreforcsv(index_val, model_test1, name_file = \"TreeClass5leaf.csv\")\n",
    "\n",
    "\n",
    "model2 = RandomForestClassifier(n_estimators=36, criterion = 'entropy', random_state=1)\n",
    "model2.fit(train_X, train_y)\n",
    "preds_val2 = model2.predict(val_X)\n",
    "model_test2 = model2.predict(test_X)\n",
    "description = descriptiontous+\"n_estimators : 36 + Entropy\"\n",
    "metrics2 = listmetrics(val_y, preds_val2, \"Random Forest Classifier\", description)\n",
    "m2Public = [0.690909090]\n",
    "m2Private = [0.649122807]\n",
    "res.append(metrics2)\n",
    "df2 = getscoreforcsv(index_val, model_test2, name_file = \"RandomForestN36Entropy.csv\")\n",
    "\n",
    "model2 = XGBClassifier(scale_pos_weight=22, random_state=1)\n",
    "model2.fit(train_X, train_y)\n",
    "preds_val2 = model2.predict(val_X)\n",
    "model_test2 = model2.predict(test_X)\n",
    "description = descriptiontous+\"scale_pos_weight = 22\"\n",
    "metrics2 = listmetrics(val_y, preds_val2, \"XGBClassifier\", description)\n",
    "m3Public = [0.677419354]\n",
    "m3Private = [0.676923076]\n",
    "res.append(metrics2)\n",
    "df2 = getscoreforcsv(index_val, model_test2, name_file = \"XGBClassifierW22.csv\")\n",
    "\n",
    "#oversamplesimple\n",
    "X_con = pd.concat([train_X, train_y], axis=1) \n",
    "not_fraud = X_con[X_con.FraudResult==0]\n",
    "fraud = X_con[X_con.FraudResult==1]\n",
    "fraud_upsampled = resample(fraud, replace=True, n_samples=len(not_fraud), # match number in majority class\n",
    "                          random_state=1) # reproducible results\n",
    "upsampled = pd.concat([not_fraud, fraud_upsampled])\n",
    "train_y_over_sampled = upsampled.FraudResult\n",
    "train_X_over_sampled = upsampled.drop('FraudResult', axis=1)\n",
    "upsampledmodel = RandomForestClassifier(n_estimators=36, criterion = 'entropy', random_state=1)\n",
    "upsampledmodel.fit(train_X_over_sampled, train_y_over_sampled)\n",
    "upsampled_pred = upsampledmodel.predict(val_X)\n",
    "model_test = upsampledmodel.predict(OH_X_test)\n",
    "description = descriptiontous+\"upsampled, n_estimators=36, criterion = entropy\"\n",
    "metrics = listmetrics(val_y, upsampled_pred, \"RandomForestClassifierUpperSampling\", description)\n",
    "m4Public = [0.678571428]\n",
    "m4Private = [0.637168141]\n",
    "res.append(metrics)\n",
    "df = getscoreforcsv(index_val, model_test, name_file = \"RandomForestClassifierUpSample.csv\")\n",
    "\n",
    "#Undersampling\n",
    "not_fraud_downsampled  = resample(not_fraud, replace=False, n_samples=len(fraud), # match number in minority  class\n",
    "                          random_state=1) # reproducible results\n",
    "downsampled  = pd.concat([not_fraud_downsampled , fraud])\n",
    "train_y_undersampled = downsampled.FraudResult\n",
    "train_X_undersampled = downsampled.drop('FraudResult', axis=1)\n",
    "undersampled = RandomForestClassifier(n_estimators=36, criterion = 'entropy', random_state=1)\n",
    "undersampled.fit(train_X_over_sampled, train_y_over_sampled)\n",
    "undersampled_pred = undersampled.predict(val_X)\n",
    "model_test = undersampled.predict(OH_X_test)\n",
    "description = descriptiontous+\"undersampled, n_estimators=36, criterion = entropy\"\n",
    "metrics = listmetrics(val_y, undersampled_pred, \"RandomForestClassifierUnderSampling\", description)\n",
    "m5Public = [0.549019607]\n",
    "m5Private = [0.480769230]\n",
    "res.append(metrics)\n",
    "df = getscoreforcsv(index_val, model_test, name_file = \"RandomForestClassifierUndersampled.csv\")\n",
    "\n",
    "\n",
    "dfres = listmetricsintodf(res)\n",
    "dfres[\"OldPublicScore\"] = [m1Public, m2Public, m3Public, m4Public, m5Public]\n",
    "dfres[\"OldPrivateScore\"] = [m1Private, m2Private, m3Private, m4Private, m5Private]\n",
    "dfres[\"MeanOurMetrics\"] = dfres[['Precision', 'Recall','F1-score','Mcc']].mean(axis=1)\n",
    "dfres.to_csv('output/resultatsTestEverything.csv', mode='a',index=False,header = False) \n",
    "dfres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ba35bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Date</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>PublicScore</th>\n",
       "      <th>PrivateScore</th>\n",
       "      <th>OldPublicScore</th>\n",
       "      <th>OldPrivateScore</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>La basemax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-06 20:37:01.701978</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>0.857566</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>[0.661016949]</td>\n",
       "      <td>0.857900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>La basen_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-06 20:37:02.891559</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.019592</td>\n",
       "      <td>0.848262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909]</td>\n",
       "      <td>[0.649122807]</td>\n",
       "      <td>0.848830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>La basescale_pos_weight = 22</td>\n",
       "      <td>2023-05-06 20:37:04.316049</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.881747</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354]</td>\n",
       "      <td>[0.676923076]</td>\n",
       "      <td>0.882152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>La baseupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-06 20:37:06.774426</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.022606</td>\n",
       "      <td>0.829975</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.637168141]</td>\n",
       "      <td>0.830880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>La baseundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-06 20:37:09.025865</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.022606</td>\n",
       "      <td>0.829975</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.549019607]</td>\n",
       "      <td>[0.48076923]</td>\n",
       "      <td>0.830880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>Sans veryLow MImax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-06 20:51:15.706650</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.013564</td>\n",
       "      <td>0.881780</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>[0.661016949]</td>\n",
       "      <td>0.882409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Sans veryLow MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-06 20:51:16.916077</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.025621</td>\n",
       "      <td>0.801037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909]</td>\n",
       "      <td>[0.649122807]</td>\n",
       "      <td>0.801648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Sans veryLow MIscale_pos_weight = 22</td>\n",
       "      <td>2023-05-06 20:51:18.180099</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.891566</td>\n",
       "      <td>0.013564</td>\n",
       "      <td>0.891963</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354]</td>\n",
       "      <td>[0.676923076]</td>\n",
       "      <td>0.892249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>Sans veryLow MIupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-06 20:51:20.658177</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.021099</td>\n",
       "      <td>0.838969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.637168141]</td>\n",
       "      <td>0.839697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>Sans veryLow MIundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-06 20:51:22.937609</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.021099</td>\n",
       "      <td>0.838969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.549019607]</td>\n",
       "      <td>[0.48076923]</td>\n",
       "      <td>0.839697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>Sans Low MImax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-06 20:51:23.078874</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.157730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>[0.661016949]</td>\n",
       "      <td>0.199660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Sans Low MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-06 20:51:24.053805</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>0.054255</td>\n",
       "      <td>0.490016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909]</td>\n",
       "      <td>[0.649122807]</td>\n",
       "      <td>0.491849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Sans Low MIscale_pos_weight = 22</td>\n",
       "      <td>2023-05-06 20:51:24.981709</td>\n",
       "      <td>0.397059</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.081383</td>\n",
       "      <td>0.516687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354]</td>\n",
       "      <td>[0.676923076]</td>\n",
       "      <td>0.522187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>Sans Low MIupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-06 20:51:27.254243</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.436364</td>\n",
       "      <td>0.093440</td>\n",
       "      <td>0.452385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.637168141]</td>\n",
       "      <td>0.457902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>Sans Low MIundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-06 20:51:29.419018</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.436364</td>\n",
       "      <td>0.093440</td>\n",
       "      <td>0.452385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.549019607]</td>\n",
       "      <td>[0.48076923]</td>\n",
       "      <td>0.457902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>Sans mediumMI MImax_leaf_nodes : 6 + with date columns</td>\n",
       "      <td>2023-05-06 20:51:29.534162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.666666666]</td>\n",
       "      <td>[0.661016949]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>Sans mediumMI MIn_estimators : 36 + Entropy</td>\n",
       "      <td>2023-05-06 20:51:29.969941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.69090909]</td>\n",
       "      <td>[0.649122807]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>Sans mediumMI MIscale_pos_weight = 22</td>\n",
       "      <td>2023-05-06 20:51:30.439168</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.162791</td>\n",
       "      <td>0.108511</td>\n",
       "      <td>0.161685</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.677419354]</td>\n",
       "      <td>[0.676923076]</td>\n",
       "      <td>0.162913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RandomForestClassifierUpperSampling</td>\n",
       "      <td>Sans mediumMI MIupsampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-06 20:51:31.381130</td>\n",
       "      <td>0.010616</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.020977</td>\n",
       "      <td>4.923675</td>\n",
       "      <td>0.087518</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.678571428]</td>\n",
       "      <td>[0.637168141]</td>\n",
       "      <td>0.248528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RandomForestClassifierUnderSampling</td>\n",
       "      <td>Sans mediumMI MIundersampled, n_estimators=36, criterion = entropy</td>\n",
       "      <td>2023-05-06 20:51:32.149516</td>\n",
       "      <td>0.010616</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.020977</td>\n",
       "      <td>4.923675</td>\n",
       "      <td>0.087518</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.549019607]</td>\n",
       "      <td>[0.48076923]</td>\n",
       "      <td>0.248528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Model  \\\n",
       "0              Decision Tree Classifier   \n",
       "1              Random Forest Classifier   \n",
       "2                         XGBClassifier   \n",
       "3   RandomForestClassifierUpperSampling   \n",
       "4   RandomForestClassifierUnderSampling   \n",
       "5              Decision Tree Classifier   \n",
       "6              Random Forest Classifier   \n",
       "7                         XGBClassifier   \n",
       "8   RandomForestClassifierUpperSampling   \n",
       "9   RandomForestClassifierUnderSampling   \n",
       "10             Decision Tree Classifier   \n",
       "11             Random Forest Classifier   \n",
       "12                        XGBClassifier   \n",
       "13  RandomForestClassifierUpperSampling   \n",
       "14  RandomForestClassifierUnderSampling   \n",
       "15             Decision Tree Classifier   \n",
       "16             Random Forest Classifier   \n",
       "17                        XGBClassifier   \n",
       "18  RandomForestClassifierUpperSampling   \n",
       "19  RandomForestClassifierUnderSampling   \n",
       "\n",
       "                                                           Description  \\\n",
       "0                        La basemax_leaf_nodes : 6 + with date columns   \n",
       "1                                   La basen_estimators : 36 + Entropy   \n",
       "2                                         La basescale_pos_weight = 22   \n",
       "3               La baseupsampled, n_estimators=36, criterion = entropy   \n",
       "4            La baseundersampled, n_estimators=36, criterion = entropy   \n",
       "5                Sans veryLow MImax_leaf_nodes : 6 + with date columns   \n",
       "6                           Sans veryLow MIn_estimators : 36 + Entropy   \n",
       "7                                 Sans veryLow MIscale_pos_weight = 22   \n",
       "8       Sans veryLow MIupsampled, n_estimators=36, criterion = entropy   \n",
       "9    Sans veryLow MIundersampled, n_estimators=36, criterion = entropy   \n",
       "10                   Sans Low MImax_leaf_nodes : 6 + with date columns   \n",
       "11                              Sans Low MIn_estimators : 36 + Entropy   \n",
       "12                                    Sans Low MIscale_pos_weight = 22   \n",
       "13          Sans Low MIupsampled, n_estimators=36, criterion = entropy   \n",
       "14       Sans Low MIundersampled, n_estimators=36, criterion = entropy   \n",
       "15              Sans mediumMI MImax_leaf_nodes : 6 + with date columns   \n",
       "16                         Sans mediumMI MIn_estimators : 36 + Entropy   \n",
       "17                               Sans mediumMI MIscale_pos_weight = 22   \n",
       "18     Sans mediumMI MIupsampled, n_estimators=36, criterion = entropy   \n",
       "19  Sans mediumMI MIundersampled, n_estimators=36, criterion = entropy   \n",
       "\n",
       "                          Date  Precision  Recall  F1-score   LogLoss  \\\n",
       "0   2023-05-06 20:37:01.701978   0.891892   0.825  0.857143  0.016578   \n",
       "1   2023-05-06 20:37:02.891559   0.800000   0.900  0.847059  0.019592   \n",
       "2   2023-05-06 20:37:04.316049   0.840909   0.925  0.880952  0.015071   \n",
       "3   2023-05-06 20:37:06.774426   0.765957   0.900  0.827586  0.022606   \n",
       "4   2023-05-06 20:37:09.025865   0.765957   0.900  0.827586  0.022606   \n",
       "5   2023-05-06 20:51:15.706650   0.942857   0.825  0.880000  0.013564   \n",
       "6   2023-05-06 20:51:16.916077   0.755556   0.850  0.800000  0.025621   \n",
       "7   2023-05-06 20:51:18.180099   0.860465   0.925  0.891566  0.013564   \n",
       "8   2023-05-06 20:51:20.658177   0.782609   0.900  0.837209  0.021099   \n",
       "9   2023-05-06 20:51:22.937609   0.782609   0.900  0.837209  0.021099   \n",
       "10  2023-05-06 20:51:23.078874   0.500000   0.050  0.090909  0.060284   \n",
       "11  2023-05-06 20:51:24.053805   0.566667   0.425  0.485714  0.054255   \n",
       "12  2023-05-06 20:51:24.981709   0.397059   0.675  0.500000  0.081383   \n",
       "13  2023-05-06 20:51:27.254243   0.342857   0.600  0.436364  0.093440   \n",
       "14  2023-05-06 20:51:29.419018   0.342857   0.600  0.436364  0.093440   \n",
       "15  2023-05-06 20:51:29.534162        NaN   0.000       NaN  0.060284   \n",
       "16  2023-05-06 20:51:29.969941        NaN   0.000       NaN  0.060284   \n",
       "17  2023-05-06 20:51:30.439168   0.152174   0.175  0.162791  0.108511   \n",
       "18  2023-05-06 20:51:31.381130   0.010616   0.875  0.020977  4.923675   \n",
       "19  2023-05-06 20:51:32.149516   0.010616   0.875  0.020977  4.923675   \n",
       "\n",
       "         Mcc  PublicScore  PrivateScore OldPublicScore OldPrivateScore  \\\n",
       "0   0.857566          NaN           NaN  [0.666666666]   [0.661016949]   \n",
       "1   0.848262          NaN           NaN   [0.69090909]   [0.649122807]   \n",
       "2   0.881747          NaN           NaN  [0.677419354]   [0.676923076]   \n",
       "3   0.829975          NaN           NaN  [0.678571428]   [0.637168141]   \n",
       "4   0.829975          NaN           NaN  [0.549019607]    [0.48076923]   \n",
       "5   0.881780          NaN           NaN  [0.666666666]   [0.661016949]   \n",
       "6   0.801037          NaN           NaN   [0.69090909]   [0.649122807]   \n",
       "7   0.891963          NaN           NaN  [0.677419354]   [0.676923076]   \n",
       "8   0.838969          NaN           NaN  [0.678571428]   [0.637168141]   \n",
       "9   0.838969          NaN           NaN  [0.549019607]    [0.48076923]   \n",
       "10  0.157730          NaN           NaN  [0.666666666]   [0.661016949]   \n",
       "11  0.490016          NaN           NaN   [0.69090909]   [0.649122807]   \n",
       "12  0.516687          NaN           NaN  [0.677419354]   [0.676923076]   \n",
       "13  0.452385          NaN           NaN  [0.678571428]   [0.637168141]   \n",
       "14  0.452385          NaN           NaN  [0.549019607]    [0.48076923]   \n",
       "15  0.000000          NaN           NaN  [0.666666666]   [0.661016949]   \n",
       "16  0.000000          NaN           NaN   [0.69090909]   [0.649122807]   \n",
       "17  0.161685          NaN           NaN  [0.677419354]   [0.676923076]   \n",
       "18  0.087518          NaN           NaN  [0.678571428]   [0.637168141]   \n",
       "19  0.087518          NaN           NaN  [0.549019607]    [0.48076923]   \n",
       "\n",
       "    MeanOurMetrics  \n",
       "0         0.857900  \n",
       "1         0.848830  \n",
       "2         0.882152  \n",
       "3         0.830880  \n",
       "4         0.830880  \n",
       "5         0.882409  \n",
       "6         0.801648  \n",
       "7         0.892249  \n",
       "8         0.839697  \n",
       "9         0.839697  \n",
       "10        0.199660  \n",
       "11        0.491849  \n",
       "12        0.522187  \n",
       "13        0.457902  \n",
       "14        0.457902  \n",
       "15        0.000000  \n",
       "16        0.000000  \n",
       "17        0.162913  \n",
       "18        0.248528  \n",
       "19        0.248528  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfresult  = pd.read_csv(\"output/resultatsTestEverything.csv\")\n",
    "dfresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b9a49624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les meilleurs résultat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarah\\AppData\\Local\\Temp\\ipykernel_18636\\2367281751.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  dfresult.groupby(['Model'])['Precision','Recall','F1-score','LogLoss','MeanOurMetrics'].max()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classifier</th>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.882409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.848830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifierUnderSampling</th>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>4.923675</td>\n",
       "      <td>0.839697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifierUpperSampling</th>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>4.923675</td>\n",
       "      <td>0.839697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.891566</td>\n",
       "      <td>0.108511</td>\n",
       "      <td>0.892249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Precision  Recall  F1-score   LogLoss  \\\n",
       "Model                                                                        \n",
       "Decision Tree Classifier              0.942857   0.825  0.880000  0.060284   \n",
       "Random Forest Classifier              0.800000   0.900  0.847059  0.060284   \n",
       "RandomForestClassifierUnderSampling   0.782609   0.900  0.837209  4.923675   \n",
       "RandomForestClassifierUpperSampling   0.782609   0.900  0.837209  4.923675   \n",
       "XGBClassifier                         0.860465   0.925  0.891566  0.108511   \n",
       "\n",
       "                                     MeanOurMetrics  \n",
       "Model                                                \n",
       "Decision Tree Classifier                   0.882409  \n",
       "Random Forest Classifier                   0.848830  \n",
       "RandomForestClassifierUnderSampling        0.839697  \n",
       "RandomForestClassifierUpperSampling        0.839697  \n",
       "XGBClassifier                              0.892249  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Les meilleurs résultat\")\n",
    "dfresult.groupby(['Model'])['Precision','Recall','F1-score','LogLoss','MeanOurMetrics'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e794338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les pire résultat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarah\\AppData\\Local\\Temp\\ipykernel_18636\\2101499374.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  dfresult.groupby(['Model'])['Precision','Recall','F1-score','LogLoss','MeanOurMetrics'].min()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>LogLoss</th>\n",
       "      <th>MeanOurMetrics</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classifier</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.013564</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>0.019592</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifierUnderSampling</th>\n",
       "      <td>0.010616</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.020977</td>\n",
       "      <td>0.021099</td>\n",
       "      <td>0.248528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifierUpperSampling</th>\n",
       "      <td>0.010616</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.020977</td>\n",
       "      <td>0.021099</td>\n",
       "      <td>0.248528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBClassifier</th>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.162791</td>\n",
       "      <td>0.013564</td>\n",
       "      <td>0.162913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Precision  Recall  F1-score   LogLoss  \\\n",
       "Model                                                                        \n",
       "Decision Tree Classifier              0.500000   0.000  0.090909  0.013564   \n",
       "Random Forest Classifier              0.566667   0.000  0.485714  0.019592   \n",
       "RandomForestClassifierUnderSampling   0.010616   0.600  0.020977  0.021099   \n",
       "RandomForestClassifierUpperSampling   0.010616   0.600  0.020977  0.021099   \n",
       "XGBClassifier                         0.152174   0.175  0.162791  0.013564   \n",
       "\n",
       "                                     MeanOurMetrics  \n",
       "Model                                                \n",
       "Decision Tree Classifier                   0.000000  \n",
       "Random Forest Classifier                   0.000000  \n",
       "RandomForestClassifierUnderSampling        0.248528  \n",
       "RandomForestClassifierUpperSampling        0.248528  \n",
       "XGBClassifier                              0.162913  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Les pire résultat\")\n",
    "dfresult.groupby(['Model'])['Precision','Recall','F1-score','LogLoss','MeanOurMetrics'].min()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
