{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from datetime import datetime\n",
    "\n",
    "from Utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_feature = pd.read_csv(\"input/Xente_Variable_Definitions.csv\")\n",
    "df = pd.read_csv(\"input/training.csv\")\n",
    "# data = df.drop(\"FraudResult\", axis=1)\n",
    "data = df.copy()\n",
    "y_train = df[\"FraudResult\"]\n",
    "X_test = pd.read_csv(\"input/test.csv\")\n",
    "X_valid = X_test.copy()\n",
    "sample_submission = pd.read_csv(\"input/sample_submission.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping column with one unique values:  ['CurrencyCode', 'CountryCode']\n",
      "Converting columns with Id:  ['TransactionId', 'BatchId', 'AccountId', 'SubscriptionId', 'CustomerId', 'ProviderId', 'ProductId', 'ChannelId']\n"
     ]
    }
   ],
   "source": [
    "# Count the number of unique entries in each column\n",
    "unique_counts = data.nunique()\n",
    "\n",
    "# Select only columns with more than one unique entry\n",
    "drop_cols = unique_counts[unique_counts == 1].index.tolist()\n",
    "print(\"Dropping column with one unique values: \", drop_cols)\n",
    "\n",
    "# Drop the selected columns\n",
    "data = data.drop(columns=drop_cols)\n",
    "X_test = X_test.drop(columns=drop_cols)\n",
    "\n",
    "# Get a list of column names that contain the string \"id\" in their name\n",
    "id_cols = data.filter(like=\"Id\").columns.tolist()\n",
    "\n",
    "# Print the list of column names\n",
    "print(\"Converting columns with Id: \", id_cols)\n",
    "\n",
    "# Remove column name prefix and convert to integer data type\n",
    "data[id_cols] = (\n",
    "    data[id_cols]\n",
    "    .astype(str)\n",
    "    .apply(lambda x: x.str.replace(x.name + \"_\", \"\"))\n",
    "    .astype(int)\n",
    ")\n",
    "X_test[id_cols] = (\n",
    "    X_test[id_cols]\n",
    "    .astype(str)\n",
    "    .apply(lambda x: x.str.replace(x.name + \"_\", \"\"))\n",
    "    .astype(int)\n",
    ")\n",
    "\n",
    "# convert TransactionStartTime column to datetime format\n",
    "data[\"TransactionStartTime\"] = pd.to_datetime(\n",
    "    df[\"TransactionStartTime\"], format=\"%Y-%m-%dT%H:%M:%SZ\"\n",
    ")\n",
    "X_test[\"TransactionStartTime\"] = pd.to_datetime(\n",
    "    X_test[\"TransactionStartTime\"], format=\"%Y-%m-%dT%H:%M:%SZ\"\n",
    ")\n",
    "\n",
    "# extract date and time features\n",
    "data[\"TransactionDayOfWeek\"] = data[\"TransactionStartTime\"].dt.dayofweek\n",
    "data[\"TransactionDayOfMonth\"] = data[\"TransactionStartTime\"].dt.day\n",
    "data[\"TransactionHour\"] = data[\"TransactionStartTime\"].dt.hour\n",
    "data[\"TransactionMinute\"] = data[\"TransactionStartTime\"].dt.minute\n",
    "\n",
    "X_test[\"TransactionDayOfWeek\"] = X_test[\"TransactionStartTime\"].dt.dayofweek\n",
    "X_test[\"TransactionDayOfMonth\"] = X_test[\"TransactionStartTime\"].dt.day\n",
    "X_test[\"TransactionHour\"] = X_test[\"TransactionStartTime\"].dt.hour\n",
    "X_test[\"TransactionMinute\"] = X_test[\"TransactionStartTime\"].dt.minute\n",
    "\n",
    "# drop TransactionStartTime\n",
    "data = data.drop(\"TransactionStartTime\", axis=1)\n",
    "X_test = X_test.drop(\"TransactionStartTime\", axis=1)\n",
    "\n",
    "# Factorize the \"ProductCategory\" column\n",
    "data[\"ProductCategory\"] = pd.factorize(data[\"ProductCategory\"])[0] + 1\n",
    "X_test[\"ProductCategory\"] = pd.factorize(X_test[\"ProductCategory\"])[0] + 1\n",
    "# Convert the \"ProductCategory\" column to integer data type\n",
    "data[\"ProductCategory\"] = data[\"ProductCategory\"].astype(int)\n",
    "X_test[\"ProductCategory\"] = X_test[\"ProductCategory\"].astype(int)\n",
    "\n",
    "# Removing redundant data\n",
    "data[\"Expense\"] = data[\"Amount\"] < 0\n",
    "data.Expense = data.Expense.astype(int)\n",
    "data = data.drop(\"Amount\", axis=1)\n",
    "\n",
    "X_test[\"Expense\"] = X_test[\"Amount\"] < 0\n",
    "X_test.Expense = X_test.Expense.astype(int)\n",
    "X_test = X_test.drop(\"Amount\", axis=1)\n",
    "\n",
    "# Continous value should be float\n",
    "data[\"Value\"] = data[\"Value\"].astype(float)\n",
    "X_test[\"Value\"] = X_test[\"Value\"].astype(float)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario 1: With All columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate data (drop FraudResult before)\n",
    "# data.drop(\"FraudResult\", inplace=True, axis=1)\n",
    "# mi_score = make_mi_scores(data, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario 2: Dropping Unique ID columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropping_cols = [\n",
    "    \"TransactionId\",\n",
    "    \"BatchId\",\n",
    "    \"AccountId\",\n",
    "    \"CustomerId\",\n",
    "    \"SubscriptionId\",\n",
    "]\n",
    "\n",
    "for col in dropping_cols:\n",
    "    data = data.drop(col, axis=1)\n",
    "    X_test = X_test.drop(col, axis=1)\n",
    "\n",
    "# Evaluate data (drop FraudResult before)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario 3: Adding new features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing features that impact in Fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_col = [\"ProviderId\", \"ProductCategory\", \"ChannelId\", \"PricingStrategy\"]\n",
    "mean_std_col = [\n",
    "    \"ProductId\",\n",
    "    \"Value\",\n",
    "    \"Expense\",\n",
    "    \"ProviderId\",\n",
    "    \"ProductCategory\",\n",
    "    \"ChannelId\",\n",
    "    \"PricingStrategy\",\n",
    "]\n",
    "\n",
    "# Compute mean and standard deviation for specific features\n",
    "for feature in mean_std_col:\n",
    "    # Compute the mean and standard deviation of transactions for each feature\n",
    "    feature_avg_values = data.groupby(feature)[\"Value\"].mean()\n",
    "    feature_std_values = data.groupby(feature)[\"Value\"].std()\n",
    "    data[f\"{feature}_mean_amount\"] = data[feature].apply(\n",
    "        lambda x: feature_avg_values[x]\n",
    "    )\n",
    "    data[f\"{feature}_std_amount\"] = data[feature].apply(lambda x: feature_std_values[x])\n",
    "\n",
    "for feature in mean_std_col:\n",
    "    # Compute the mean and standard deviation of transactions for each feature\n",
    "    feature_avg_values = X_test.groupby(feature)[\"Value\"].mean()\n",
    "    feature_std_values = X_test.groupby(feature)[\"Value\"].std()\n",
    "    X_test[f\"{feature}_mean_amount\"] = X_test[feature].apply(\n",
    "        lambda x: feature_avg_values[x]\n",
    "    )\n",
    "    X_test[f\"{feature}_std_amount\"] = X_test[feature].apply(\n",
    "        lambda x: feature_std_values[x]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHot Encode categorical features\n",
    "data = pd.get_dummies(data, columns=categorical_col)\n",
    "# Adding missing col\n",
    "data[\"ChannelId_4\"] = False\n",
    "data[\"PricingStrategy_3\"] = False\n",
    "X_test = pd.get_dummies(X_test, columns=categorical_col)\n",
    "# Adding missing col\n",
    "X_test[\"PricingStrategy_3\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the boolean columns to integer columns\n",
    "bool_cols = data.select_dtypes(include=bool).columns.tolist()\n",
    "data[bool_cols] = data[bool_cols].astype(int)\n",
    "\n",
    "bool_cols = X_test.select_dtypes(include=bool).columns.tolist()\n",
    "X_test[bool_cols] = X_test[bool_cols].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95662, 47)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI5L",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
